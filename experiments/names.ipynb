{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\dgl\\dgl.dll\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d09bfb7b5434e30936c4d1842a5a085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad4341fd93d4df79a99f64bb978456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1073 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916c38c13e534e54bd324b4f055f159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05648cfc6b2459591c48f81e343ff53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3c50fde8c341b489a2d376babc2d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1b9210870d4979ba90d3c27e14dcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tucore_gcn_bert_train import TUCOREGCNDialogREDataset\n",
    "tucore_dataset = TUCOREGCNDialogREDataset()\n",
    "tucore_dataset.download_and_prepare()\n",
    "tucore_data = tucore_dataset.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tucore_data['train'] = tucore_data['train'].shuffle()\n",
    "tucore_data['test'] = tucore_data['test'].shuffle()\n",
    "tucore_data['validation'] = tucore_data['validation'].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90de394b0ccc4e9799644a9f949cc3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0835bcfbb7b4b35ba35cebecfb2368a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aff7f1c27ad4844abf379a141bddae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tucore_data.save_to_disk(\"../datasets/DialogRE/data_final/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\dgl\\dgl.dll\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TUCOREGCN_BertForSequenceClassification(\n",
       "  (tucoregcn_bert): TUCOREGCN_Bert(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (speaker_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (turnAttention): MultiHeadAttention(\n",
       "      (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (GCN_layers): ModuleList(\n",
       "      (0-1): 2 x RelGraphConvLayer(\n",
       "        (activation): ReLU()\n",
       "        (conv): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (speaker): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (dialog): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (entity): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.6, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (LSTM_layers): ModuleList(\n",
       "      (0-1): 2 x TurnLevelLSTM(\n",
       "        (lstm): LSTM(768, 768, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "        (bilstm2hiddnesize): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=6912, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tucore_gcn_bert_modelling import TUCOREGCN_BertForSequenceClassification, TUCOREGCN_BertConfig\n",
    "m = TUCOREGCN_BertForSequenceClassification(TUCOREGCN_BertConfig.from_json_file(\"../tucore_gcn_transformers/tucore_gcn_bert_mlc.json\"))\n",
    "m.load_state_dict(torch.load(open(\"../tucore_gcn_bert_test2/1.pt\", 'rb')))\n",
    "m.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "tucore_data = datasets.load_from_disk(\"../datasets/DialogRE/real_arrow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens 512\n",
      "label_ids 36\n",
      "input_ids 512\n",
      "input_mask 512\n",
      "segment_ids 512\n",
      "speaker_ids 512\n",
      "mention_ids 512\n",
      "turn_masks 512\n",
      "graph 5927\n"
     ]
    }
   ],
   "source": [
    "entry = tucore_data['train'][537]\n",
    "for key in entry.keys():\n",
    "\tprint(key, len(entry[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '{entity_1}', ':', 'where', 'is', 'emily', '?', '{speaker_2}', ':', 'u', '##gh', ',', 'she', '’', 's', 'saying', 'good', '-', 'bye', 'to', 'her', 'uncle', '.', '{entity_1}', ':', '{entity_2}', ',', 'didn', '’', 't', 'she', 'like', 'just', 'get', 'here', '?', '{speaker_2}', ':', 'yeah', '!', '!', 'yeah', '!', '{entity_1}', ':', 'easy', 'tiger', '.', '{speaker_2}', ':', 'i', 'just', ',', 'i', 'hate', 'this', 'so', 'much', '!', 'i', 'mean', ',', 'every', 'time', 'i', 'go', 'pick', 'her', 'up', 'at', 'the', 'airport', ',', 'it', '’', 's', '-', 'it', '’', 's', 'so', 'great', '.', 'but', 'at', 'the', 'same', 'time', 'i', '’', 'm', 'thinking', ',', '\"', 'well', ',', 'i', '’', 'm', 'gonna', 'be', 'right', 'back', 'there', 'in', 'a', 'couple', 'of', 'days', ',', 'dropping', 'her', 'off', '.', '\"', '{entity_1}', ':', 'so', 'what', 'are', 'you', 'going', 'to', 'do', '?', '{speaker_2}', ':', 'nothing', '!', 'there', '’', 's', 'nothing', 'to', 'do', '!', 'i', 'mean', ',', 'she', 'lives', 'there', ',', 'i', 'live', 'here', '.', 'i', 'mean', ',', 'she', '-', 'she', '’', 'd', 'have', 'to', 'uh', ',', 'move', 'here', '.', 'she', 'should', 'move', 'here', '!', '{speaker_3}', ':', 'what', '?', '{speaker_2}', ':', 'i', 'could', 'ask', 'her', 'to', 'live', 'with', 'me', '!', '{entity_1}', ':', 'are', 'you', 'serious', '?', '{speaker_2}', ':', 'i', 'mean', ',', 'why', 'not', '!', 'i', 'mean', ',', 'i', 'mean', 'why', 'not', '?', '!', '{entity_1}', ':', 'because', 'you', '’', 've', 'only', 'known', 'her', 'for', 'six', 'weeks', '!', 'okay', ',', 'i', '’', 've', 'got', 'a', 'cart', '##on', 'of', 'milk', 'in', 'my', 'fridge', 'i', '’', 've', 'had', 'a', 'longer', 'relationship', 'with', '!', '{speaker_2}', ':', 'look', 'guys', ',', 'when', 'i', '’', 'm', 'with', 'her', 'it', '’', 's', '-', 'it', '’', 's', '-', 'it', '’', 's', 'like', 'she', 'brings', 'this', '-', 'this', '-', 'this', 'great', 'side', 'out', 'of', 'me', '.', 'i', 'mean', 'i', '-', 'i', '-', 'i', 'love', 'her', ',', 'y', '’', 'know', '?', '{entity_1}', ':', 'and', 'i', 'love', 'the', 'milk', '!', 'but', ',', 'i', '’', 'm', 'not', 'gonna', 'some', 'british', 'girl', 'to', 'move', 'in', 'with', 'me', '!', 'joey', ',', 'you', 'say', 'things', 'now', '.', '{speaker_3}', ':', 'all', 'right', 'look', ',', 'ross', ',', 'he', '’', 's', 'right', '.', 'emily', '’', 's', 'great', ',', 'she', '’', 's', 'great', '!', 'but', 'this', 'way', 'too', 'soon', ',', 'you', '’', 're', 'only', 'gonna', 'scare', 'her', '!', '{speaker_2}', ':', 'i', 'don', '’', 't', 'want', 'to', 'do', 'that', '.', '{speaker_3}', ':', 'no', '!', 'you', 'don', '’', 't', 'want', 'to', 'wreck', 'it', ',', 'you', 'don', '’', 't', 'want', 'to', 'go', 'to', 'fast', '!', '{speaker_2}', ':', 'yeah', ',', 'no', ',', 'you', '’', 're', 'right', ',', 'i', 'know', ',', 'you', '’', 're', 'right', ',', 'i', '’', 'm', 'not', ',', 'i', '’', 'm', 'not', 'gonna', 'do', 'it', '.', 'all', 'right', ',', 'thanks', 'guys', '.', '{entity_1}', ':', 'okay', ',', 'no', 'problem', ',', 'just', 'remember', 'to', 'wake', 'us', 'up', 'before', 'you', 'go', '-', 'go', '.', '[SEP]', '{entity_1}', '[SEP]', '{entity_2}', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(tucore_data['train'][537]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 3, 3, 3, 3, 3, 3, 3, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 11, 11, 11, 11, 11, 11, 11, 11, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tucore_data['train'][536]['speaker_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tucore_data['train'][3]['turn_masks'][179][207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entry[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\dgl\\dgl.dll\n"
     ]
    }
   ],
   "source": [
    "dev = pickle.load(open(\"../datasets/DialogRE/dev_BERT.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '{entity_2}', ':', 'hey', '!', '{speaker_2}', ':', 'hey', '.', '{speaker_3}', ':', 'hey', ',', 'man', '.', 'what', \"'\", 's', 'up', '?', '{entity_2}', ':', 'maybe', 'you', 'can', 'tell', 'me', '.', 'my', 'agent', 'would', 'like', 'to', 'know', 'why', 'i', 'didn', \"'\", 't', 'show', 'up', 'at', 'the', 'audition', 'i', 'didn', \"'\", 't', 'know', 'i', 'had', 'today', '.', 'the', 'first', 'good', 'thing', 'she', 'gets', 'me', 'in', 'weeks', '.', 'how', 'could', 'you', 'not', 'give', 'me', 'the', 'message', '?', '!', '{speaker_3}', ':', 'well', ',', 'i', \"'\", 'll', 'tell', 'ya', 'i', 'do', 'enjoy', 'guilt', ',', 'but', ',', 'ah', ',', 'it', 'wasn', \"'\", 't', 'me', '.', '{speaker_2}', ':', 'yes', ',', 'it', 'was', '!', 'it', 'was', 'him', '!', 'uh', 'huh', '!', 'okay', ',', 'it', 'was', 'me', '!', '{entity_2}', ':', 'how', 'is', 'it', 'you', '?', '{speaker_2}', ':', 'well', ',', 'it', 'was', 'just', ',', 'it', 'was', 'all', 'so', 'crazy', ',', 'you', 'know', '.', 'i', 'mean', ',', 'chandler', 'was', 'in', 'the', 'closet', ',', 'counting', 'to', '10', ',', 'and', 'he', 'was', 'up', 'to', '7', 'and', 'i', 'hadn', \"'\", 't', 'found', 'a', 'place', 'to', 'hide', 'yet', '.', 'i', '-', 'i', '-', 'i', 'meant', 'to', 'tell', 'you', ',', 'and', 'i', 'wrote', 'it', 'all', 'down', 'on', 'my', 'hand', '.', 'see', ',', 'all', 'of', 'it', '.', '{entity_2}', ':', 'yep', ',', 'that', \"'\", 's', 'my', 'audition', '.', '{speaker_4}', ':', 'see', ',', 'now', 'this', 'is', 'why', 'i', 'keep', 'note', '##pad', '##s', 'everywhere', '.', '{speaker_2}', ':', 'yep', ',', 'and', 'that', \"'\", 's', 'why', 'we', 'don', \"'\", 't', 'invite', 'you', 'to', 'play', '.', '{speaker_5}', ':', 'what', 'is', 'the', 'great', 'tragedy', 'here', '?', 'you', 'go', 'get', 'yourself', 'another', 'appointment', '.', '{entity_2}', ':', 'well', ',', '{entity_1}', 'tried', ',', 'you', 'know', '.', 'the', 'casting', 'director', 'told', 'her', 'that', 'i', 'missed', 'my', 'chance', '.', '{speaker_2}', ':', 'that', 'is', 'unfair', '.', 'i', \"'\", 'll', 'call', 'her', 'and', 'tell', 'her', 'it', 'was', 'totally', 'my', 'fault', '.', '{entity_2}', ':', 'ph', '##ee', '##bs', ',', 'you', 'can', \"'\", 't', 'do', 'that', '.', 'the', 'casting', 'director', 'doesn', \"'\", 't', 'talk', 'to', 'friends', ',', 'she', 'only', 'talks', 'to', 'agents', '.', '{speaker_2}', ':', 'what', 'a', 'sad', 'little', 'life', 'she', 'must', 'lead', '.', 'okay', ',', 'o', '##oh', '.', '{entity_2}', ':', 'what', ',', 'what', 'are', 'you', 'doing', '?', 'what', 'are', 'you', 'doing', '?', '{speaker_2}', ':', 'no', ',', 'no', ',', 'no', ',', 'i', 'know', ',', 'i', 'know', ',', 'o', '##oh', '.', \"'\", 'hi', ',', 'this', 'is', 'kate', '##lynn', ',', 'from', 'phoebe', 'buff', '##ay', \"'\", 's', 'office', '.', 'um', ',', 'is', 'um', ',', 'ann', 'there', 'for', 'phoebe', ',', 'she', \"'\", 'll', 'know', 'what', 'it', \"'\", 's', 'about', '.', \"'\", '{entity_2}', ':', 'hang', 'up', ',', 'hang', 'up', '.', '{speaker_2}', ':', \"'\", 'annie', '!', 'hi', '.', 'listen', 'we', 'got', 'a', 'problem', 'with', 'joey', 'tri', '##bb', '##iani', ',', 'apparently', 'he', 'missed', 'his', 'audition', '.', 'who', 'did', 'you', 'speak', 'to', 'in', 'my', 'office', '?', '{', 'entity', '_', '1', '}', ',', 'no', ',', 'i', 'don', \"'\", 't', 'know', 'what', 'i', \"'\", 'm', 'going', 'to', 'do', 'with', 'her', '.', 'no', '.', 'all', 'right', ',', 'so', 'your', 'husband', 'leaves', 'and', 'burns', 'down', 'the', 'apartment', ',', 'the', 'world', 'does', 'not', 'stop', '.', \"'\", '{speaker_3}', ':', 'is', 'anybody', 'else', 'scared', '?', '[SEP]', '{entity_1}', '[SEP]', '{entity_2}', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[101, 12, 1024, 4931, 999, 2, 1024, 4931, 1012, 3, 1024, 4931, 1010, 2158, 1012, 2054, 1005, 1055, 2039, 1029, 12, 1024, 2672, 2017, 2064, 2425, 2033, 1012, 2026, 4005, 2052, 2066, 2000, 2113, 2339, 1045, 2134, 1005, 1056, 2265, 2039, 2012, 1996, 14597, 1045, 2134, 1005, 1056, 2113, 1045, 2018, 2651, 1012, 1996, 2034, 2204, 2518, 2016, 4152, 2033, 1999, 3134, 1012, 2129, 2071, 2017, 2025, 2507, 2033, 1996, 4471, 1029, 999, 3, 1024, 2092, 1010, 1045, 1005, 2222, 2425, 8038, 1045, 2079, 5959, 8056, 1010, 2021, 1010, 6289, 1010, 2009, 2347, 1005, 1056, 2033, 1012, 2, 1024, 2748, 1010, 2009, 2001, 999, 2009, 2001, 2032, 999, 7910, 9616, 999, 3100, 1010, 2009, 2001, 2033, 999, 12, 1024, 2129, 2003, 2009, 2017, 1029, 2, 1024, 2092, 1010, 2009, 2001, 2074, 1010, 2009, 2001, 2035, 2061, 4689, 1010, 2017, 2113, 1012, 1045, 2812, 1010, 13814, 2001, 1999, 1996, 9346, 1010, 10320, 2000, 2184, 1010, 1998, 2002, 2001, 2039, 2000, 1021, 1998, 1045, 2910, 1005, 1056, 2179, 1037, 2173, 2000, 5342, 2664, 1012, 1045, 1011, 1045, 1011, 1045, 3214, 2000, 2425, 2017, 1010, 1998, 1045, 2626, 2009, 2035, 2091, 2006, 2026, 2192, 1012, 2156, 1010, 2035, 1997, 2009, 1012, 12, 1024, 15624, 1010, 2008, 1005, 1055, 2026, 14597, 1012, 4, 1024, 2156, 1010, 2085, 2023, 2003, 2339, 1045, 2562, 3602, 15455, 2015, 7249, 1012, 2, 1024, 15624, 1010, 1998, 2008, 1005, 1055, 2339, 2057, 2123, 1005, 1056, 13260, 2017, 2000, 2377, 1012, 5, 1024, 2054, 2003, 1996, 2307, 10576, 2182, 1029, 2017, 2175, 2131, 4426, 2178, 6098, 1012, 12, 1024, 2092, 1010, 11, 2699, 1010, 2017, 2113, 1012, 1996, 9179, 2472, 2409, 2014, 2008, 1045, 4771, 2026, 3382, 1012, 2, 1024, 2008, 2003, 15571, 1012, 1045, 1005, 2222, 2655, 2014, 1998, 2425, 2014, 2009, 2001, 6135, 2026, 6346, 1012, 12, 1024, 6887, 4402, 5910, 1010, 2017, 2064, 1005, 1056, 2079, 2008, 1012, 1996, 9179, 2472, 2987, 1005, 1056, 2831, 2000, 2814, 1010, 2016, 2069, 7566, 2000, 6074, 1012, 2, 1024, 2054, 1037, 6517, 2210, 2166, 2016, 2442, 2599, 1012, 3100, 1010, 1051, 11631, 1012, 12, 1024, 2054, 1010, 2054, 2024, 2017, 2725, 1029, 2054, 2024, 2017, 2725, 1029, 2, 1024, 2053, 1010, 2053, 1010, 2053, 1010, 1045, 2113, 1010, 1045, 2113, 1010, 1051, 11631, 1012, 1005, 7632, 1010, 2023, 2003, 5736, 27610, 1010, 2013, 18188, 23176, 4710, 1005, 1055, 2436, 1012, 8529, 1010, 2003, 8529, 1010, 5754, 2045, 2005, 18188, 1010, 2016, 1005, 2222, 2113, 2054, 2009, 1005, 1055, 2055, 1012, 1005, 12, 1024, 6865, 2039, 1010, 6865, 2039, 1012, 2, 1024, 1005, 8194, 999, 7632, 1012, 4952, 2057, 2288, 1037, 3291, 2007, 9558, 13012, 10322, 25443, 1010, 4593, 2002, 4771, 2010, 14597, 1012, 2040, 2106, 2017, 3713, 2000, 1999, 2026, 2436, 1029, 1063, 9178, 1035, 1015, 1065, 1010, 2053, 1010, 1045, 2123, 1005, 1056, 2113, 2054, 1045, 1005, 1049, 2183, 2000, 2079, 2007, 2014, 1012, 2053, 1012, 2035, 2157, 1010, 2061, 2115, 3129, 3727, 1998, 7641, 2091, 1996, 4545, 1010, 1996, 2088, 2515, 2025, 2644, 1012, 1005, 3, 1024, 2003, 10334, 2842, 6015, 1029, 102, 11, 102, 12, 102, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from tucore_gcn_bert_train import get_logits4eval\n",
    "dataset = tucore_dataset['validation']\n",
    "batch_size = 32\n",
    "savefile = \"../temp_testing/\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "logits_all = []\n",
    "n_batches = len(dataset) // batch_size\n",
    "label_ids = dataset[0][\"label_ids\"]\n",
    "input_ids = dataset[0][\"input_ids\"]\n",
    "segment_ids = dataset[0][\"segment_ids\"]\n",
    "input_masks = dataset[0][\"input_mask\"]\n",
    "mention_ids = dataset[0][\"mention_ids\"]\n",
    "speaker_ids = dataset[0][\"speaker_ids\"]\n",
    "turn_mask = dataset[0][\"turn_masks\"]\n",
    "# forgot to flatten the list 1\n",
    "graphs = pickle.loads(dataset[0][\"graph\"])[0].to(device)\n",
    "print(dataset[0][\"tokens\"])\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1828612"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = open('test.txt', 'w')\n",
    "a.write(str(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12761"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = open('test2.txt', 'w')\n",
    "b.write(str(dev['data'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "tk = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'hey',\n",
       " '!',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'hey',\n",
       " '.',\n",
       " 'speaker',\n",
       " '3',\n",
       " ':',\n",
       " 'hey',\n",
       " ',',\n",
       " 'man',\n",
       " '.',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'up',\n",
       " '?',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'maybe',\n",
       " 'you',\n",
       " 'can',\n",
       " 'tell',\n",
       " 'me',\n",
       " '.',\n",
       " 'my',\n",
       " 'agent',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'why',\n",
       " 'i',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'show',\n",
       " 'up',\n",
       " 'at',\n",
       " 'the',\n",
       " 'audition',\n",
       " 'i',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'i',\n",
       " 'had',\n",
       " 'today',\n",
       " '.',\n",
       " 'the',\n",
       " 'first',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'she',\n",
       " 'gets',\n",
       " 'me',\n",
       " 'in',\n",
       " 'weeks',\n",
       " '.',\n",
       " 'how',\n",
       " 'could',\n",
       " 'you',\n",
       " 'not',\n",
       " 'give',\n",
       " 'me',\n",
       " 'the',\n",
       " 'message',\n",
       " '?',\n",
       " '!',\n",
       " 'speaker',\n",
       " '3',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'tell',\n",
       " 'ya',\n",
       " 'i',\n",
       " 'do',\n",
       " 'enjoy',\n",
       " 'guilt',\n",
       " ',',\n",
       " 'but',\n",
       " ',',\n",
       " 'ah',\n",
       " ',',\n",
       " 'it',\n",
       " 'wasn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'me',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'yes',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " '!',\n",
       " 'it',\n",
       " 'was',\n",
       " 'him',\n",
       " '!',\n",
       " 'uh',\n",
       " 'huh',\n",
       " '!',\n",
       " 'okay',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'me',\n",
       " '!',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'how',\n",
       " 'is',\n",
       " 'it',\n",
       " 'you',\n",
       " '?',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'so',\n",
       " 'crazy',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " '.',\n",
       " 'i',\n",
       " 'mean',\n",
       " ',',\n",
       " 'chandler',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'closet',\n",
       " ',',\n",
       " 'counting',\n",
       " 'to',\n",
       " '10',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'up',\n",
       " 'to',\n",
       " '7',\n",
       " 'and',\n",
       " 'i',\n",
       " 'hadn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'found',\n",
       " 'a',\n",
       " 'place',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'yet',\n",
       " '.',\n",
       " 'i',\n",
       " '-',\n",
       " 'i',\n",
       " '-',\n",
       " 'i',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " ',',\n",
       " 'and',\n",
       " 'i',\n",
       " 'wrote',\n",
       " 'it',\n",
       " 'all',\n",
       " 'down',\n",
       " 'on',\n",
       " 'my',\n",
       " 'hand',\n",
       " '.',\n",
       " 'see',\n",
       " ',',\n",
       " 'all',\n",
       " 'of',\n",
       " 'it',\n",
       " '.',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'yep',\n",
       " ',',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'my',\n",
       " 'audition',\n",
       " '.',\n",
       " 'speaker',\n",
       " '4',\n",
       " ':',\n",
       " 'see',\n",
       " ',',\n",
       " 'now',\n",
       " 'this',\n",
       " 'is',\n",
       " 'why',\n",
       " 'i',\n",
       " 'keep',\n",
       " 'note',\n",
       " '##pad',\n",
       " '##s',\n",
       " 'everywhere',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'yep',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'why',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'invite',\n",
       " 'you',\n",
       " 'to',\n",
       " 'play',\n",
       " '.',\n",
       " 'speaker',\n",
       " '5',\n",
       " ':',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'great',\n",
       " 'tragedy',\n",
       " 'here',\n",
       " '?',\n",
       " 'you',\n",
       " 'go',\n",
       " 'get',\n",
       " 'yourself',\n",
       " 'another',\n",
       " 'appointment',\n",
       " '.',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'este',\n",
       " '##lle',\n",
       " 'tried',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " '.',\n",
       " 'the',\n",
       " 'casting',\n",
       " 'director',\n",
       " 'told',\n",
       " 'her',\n",
       " 'that',\n",
       " 'i',\n",
       " 'missed',\n",
       " 'my',\n",
       " 'chance',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'that',\n",
       " 'is',\n",
       " 'unfair',\n",
       " '.',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'call',\n",
       " 'her',\n",
       " 'and',\n",
       " 'tell',\n",
       " 'her',\n",
       " 'it',\n",
       " 'was',\n",
       " 'totally',\n",
       " 'my',\n",
       " 'fault',\n",
       " '.',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'ph',\n",
       " '##ee',\n",
       " '##bs',\n",
       " ',',\n",
       " 'you',\n",
       " 'can',\n",
       " \"'\",\n",
       " 't',\n",
       " 'do',\n",
       " 'that',\n",
       " '.',\n",
       " 'the',\n",
       " 'casting',\n",
       " 'director',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'friends',\n",
       " ',',\n",
       " 'she',\n",
       " 'only',\n",
       " 'talks',\n",
       " 'to',\n",
       " 'agents',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'what',\n",
       " 'a',\n",
       " 'sad',\n",
       " 'little',\n",
       " 'life',\n",
       " 'she',\n",
       " 'must',\n",
       " 'lead',\n",
       " '.',\n",
       " 'okay',\n",
       " ',',\n",
       " 'o',\n",
       " '##oh',\n",
       " '.',\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'what',\n",
       " ',',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'no',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'i',\n",
       " 'know',\n",
       " ',',\n",
       " 'i',\n",
       " 'know',\n",
       " ',',\n",
       " 'o',\n",
       " '##oh',\n",
       " '.',\n",
       " \"'\",\n",
       " 'hi',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'kate',\n",
       " '##lynn',\n",
       " ',',\n",
       " 'from',\n",
       " 'phoebe',\n",
       " 'buff',\n",
       " '##ay',\n",
       " \"'\",\n",
       " 's',\n",
       " 'office',\n",
       " '.',\n",
       " 'um',\n",
       " ',',\n",
       " 'is',\n",
       " 'um',\n",
       " ',',\n",
       " 'ann',\n",
       " 'there',\n",
       " 'for',\n",
       " 'phoebe',\n",
       " ',',\n",
       " 'she',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'know',\n",
       " 'what',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'about',\n",
       " '.',\n",
       " \"'\",\n",
       " '[unused2]',\n",
       " ':',\n",
       " 'hang',\n",
       " 'up',\n",
       " ',',\n",
       " 'hang',\n",
       " 'up',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " \"'\",\n",
       " 'annie',\n",
       " '!',\n",
       " 'hi',\n",
       " '.',\n",
       " 'listen',\n",
       " 'we',\n",
       " 'got',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'joey',\n",
       " 'tri',\n",
       " '##bb',\n",
       " '##iani',\n",
       " ',',\n",
       " 'apparently',\n",
       " 'he',\n",
       " 'missed',\n",
       " 'his',\n",
       " 'audition',\n",
       " '.',\n",
       " 'who',\n",
       " 'did',\n",
       " 'you',\n",
       " 'speak',\n",
       " 'to',\n",
       " 'in',\n",
       " 'my',\n",
       " 'office',\n",
       " '?',\n",
       " 'este',\n",
       " '##lle',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'i',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'what',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'her',\n",
       " '.',\n",
       " 'no',\n",
       " '.',\n",
       " 'all',\n",
       " 'right',\n",
       " ',',\n",
       " 'so',\n",
       " 'your',\n",
       " 'husband',\n",
       " 'leaves',\n",
       " 'and',\n",
       " 'burns',\n",
       " 'down',\n",
       " 'the',\n",
       " 'apartment',\n",
       " ',',\n",
       " 'the',\n",
       " 'world',\n",
       " 'does',\n",
       " 'not',\n",
       " 'stop',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'este',\n",
       " '##lle',\n",
       " '[SEP]',\n",
       " '[unused2]',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.convert_ids_to_tokens(dev['data'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 12\n",
      "5 5882 2\n",
      "6 1016 1024\n",
      "7 1024 4931\n",
      "8 4931 1012\n",
      "9 1012 3\n",
      "10 5882 1024\n",
      "11 1017 4931\n",
      "12 1024 1010\n",
      "13 4931 2158\n",
      "14 1010 1012\n",
      "15 2158 2054\n",
      "16 1012 1005\n",
      "17 2054 1055\n",
      "18 1005 2039\n",
      "19 1055 1029\n",
      "20 2039 12\n",
      "21 1029 1024\n",
      "22 3 2672\n",
      "23 1024 2017\n",
      "24 2672 2064\n",
      "25 2017 2425\n",
      "26 2064 2033\n",
      "27 2425 1012\n",
      "28 2033 2026\n",
      "29 1012 4005\n",
      "30 2026 2052\n",
      "31 4005 2066\n",
      "32 2052 2000\n",
      "33 2066 2113\n",
      "34 2000 2339\n",
      "35 2113 1045\n",
      "36 2339 2134\n",
      "37 1045 1005\n",
      "38 2134 1056\n",
      "39 1005 2265\n",
      "40 1056 2039\n",
      "41 2265 2012\n",
      "42 2039 1996\n",
      "43 2012 14597\n",
      "44 1996 1045\n",
      "45 14597 2134\n",
      "46 1045 1005\n",
      "47 2134 1056\n",
      "48 1005 2113\n",
      "49 1056 1045\n",
      "50 2113 2018\n",
      "51 1045 2651\n",
      "52 2018 1012\n",
      "53 2651 1996\n",
      "54 1012 2034\n",
      "55 1996 2204\n",
      "56 2034 2518\n",
      "57 2204 2016\n",
      "58 2518 4152\n",
      "59 2016 2033\n",
      "60 4152 1999\n",
      "61 2033 3134\n",
      "62 1999 1012\n",
      "63 3134 2129\n",
      "64 1012 2071\n",
      "65 2129 2017\n",
      "66 2071 2025\n",
      "67 2017 2507\n",
      "68 2025 2033\n",
      "69 2507 1996\n",
      "70 2033 4471\n",
      "71 1996 1029\n",
      "72 4471 999\n",
      "73 1029 3\n",
      "74 999 1024\n",
      "75 5882 2092\n",
      "76 1017 1010\n",
      "77 1024 1045\n",
      "78 2092 1005\n",
      "79 1010 2222\n",
      "80 1045 2425\n",
      "81 1005 8038\n",
      "82 2222 1045\n",
      "83 2425 2079\n",
      "84 8038 5959\n",
      "85 1045 8056\n",
      "86 2079 1010\n",
      "87 5959 2021\n",
      "88 8056 1010\n",
      "89 1010 6289\n",
      "90 2021 1010\n",
      "91 1010 2009\n",
      "92 6289 2347\n",
      "93 1010 1005\n",
      "94 2009 1056\n",
      "95 2347 2033\n",
      "96 1005 1012\n",
      "97 1056 2\n",
      "98 2033 1024\n",
      "99 1012 2748\n",
      "100 5882 1010\n",
      "101 1016 2009\n",
      "102 1024 2001\n",
      "103 2748 999\n",
      "104 1010 2009\n",
      "105 2009 2001\n",
      "106 2001 2032\n",
      "108 2009 7910\n",
      "109 2001 9616\n",
      "110 2032 999\n",
      "111 999 3100\n",
      "112 7910 1010\n",
      "113 9616 2009\n",
      "114 999 2001\n",
      "115 3100 2033\n",
      "116 1010 999\n",
      "117 2009 12\n",
      "118 2001 1024\n",
      "119 2033 2129\n",
      "120 999 2003\n",
      "121 3 2009\n",
      "122 1024 2017\n",
      "123 2129 1029\n",
      "124 2003 2\n",
      "125 2009 1024\n",
      "126 2017 2092\n",
      "127 1029 1010\n",
      "128 5882 2009\n",
      "129 1016 2001\n",
      "130 1024 2074\n",
      "131 2092 1010\n",
      "132 1010 2009\n",
      "133 2009 2001\n",
      "134 2001 2035\n",
      "135 2074 2061\n",
      "136 1010 4689\n",
      "137 2009 1010\n",
      "138 2001 2017\n",
      "139 2035 2113\n",
      "140 2061 1012\n",
      "141 4689 1045\n",
      "142 1010 2812\n",
      "143 2017 1010\n",
      "144 2113 13814\n",
      "145 1012 2001\n",
      "146 1045 1999\n",
      "147 2812 1996\n",
      "148 1010 9346\n",
      "149 13814 1010\n",
      "150 2001 10320\n",
      "151 1999 2000\n",
      "152 1996 2184\n",
      "153 9346 1010\n",
      "154 1010 1998\n",
      "155 10320 2002\n",
      "156 2000 2001\n",
      "157 2184 2039\n",
      "158 1010 2000\n",
      "159 1998 1021\n",
      "160 2002 1998\n",
      "161 2001 1045\n",
      "162 2039 2910\n",
      "163 2000 1005\n",
      "164 1021 1056\n",
      "165 1998 2179\n",
      "166 1045 1037\n",
      "167 2910 2173\n",
      "168 1005 2000\n",
      "169 1056 5342\n",
      "170 2179 2664\n",
      "171 1037 1012\n",
      "172 2173 1045\n",
      "173 2000 1011\n",
      "174 5342 1045\n",
      "175 2664 1011\n",
      "176 1012 1045\n",
      "177 1045 3214\n",
      "178 1011 2000\n",
      "179 1045 2425\n",
      "180 1011 2017\n",
      "181 1045 1010\n",
      "182 3214 1998\n",
      "183 2000 1045\n",
      "184 2425 2626\n",
      "185 2017 2009\n",
      "186 1010 2035\n",
      "187 1998 2091\n",
      "188 1045 2006\n",
      "189 2626 2026\n",
      "190 2009 2192\n",
      "191 2035 1012\n",
      "192 2091 2156\n",
      "193 2006 1010\n",
      "194 2026 2035\n",
      "195 2192 1997\n",
      "196 1012 2009\n",
      "197 2156 1012\n",
      "198 1010 12\n",
      "199 2035 1024\n",
      "200 1997 15624\n",
      "201 2009 1010\n",
      "202 1012 2008\n",
      "203 3 1005\n",
      "204 1024 1055\n",
      "205 15624 2026\n",
      "206 1010 14597\n",
      "207 2008 1012\n",
      "208 1005 4\n",
      "209 1055 1024\n",
      "210 2026 2156\n",
      "211 14597 1010\n",
      "212 1012 2085\n",
      "213 5882 2023\n",
      "214 1018 2003\n",
      "215 1024 2339\n",
      "216 2156 1045\n",
      "217 1010 2562\n",
      "218 2085 3602\n",
      "219 2023 15455\n",
      "220 2003 2015\n",
      "221 2339 7249\n",
      "222 1045 1012\n",
      "223 2562 2\n",
      "224 3602 1024\n",
      "225 15455 15624\n",
      "226 2015 1010\n",
      "227 7249 1998\n",
      "228 1012 2008\n",
      "229 5882 1005\n",
      "230 1016 1055\n",
      "231 1024 2339\n",
      "232 15624 2057\n",
      "233 1010 2123\n",
      "234 1998 1005\n",
      "235 2008 1056\n",
      "236 1005 13260\n",
      "237 1055 2017\n",
      "238 2339 2000\n",
      "239 2057 2377\n",
      "240 2123 1012\n",
      "241 1005 5\n",
      "242 1056 1024\n",
      "243 13260 2054\n",
      "244 2017 2003\n",
      "245 2000 1996\n",
      "246 2377 2307\n",
      "247 1012 10576\n",
      "248 5882 2182\n",
      "249 1019 1029\n",
      "250 1024 2017\n",
      "251 2054 2175\n",
      "252 2003 2131\n",
      "253 1996 4426\n",
      "254 2307 2178\n",
      "255 10576 6098\n",
      "256 2182 1012\n",
      "257 1029 12\n",
      "258 2017 1024\n",
      "259 2175 2092\n",
      "260 2131 1010\n",
      "261 4426 11\n",
      "262 2178 2699\n",
      "263 6098 1010\n",
      "264 1012 2017\n",
      "265 3 2113\n",
      "266 1024 1012\n",
      "267 2092 1996\n",
      "268 1010 9179\n",
      "269 28517 2472\n",
      "270 6216 2409\n",
      "271 2699 2014\n",
      "272 1010 2008\n",
      "273 2017 1045\n",
      "274 2113 4771\n",
      "275 1012 2026\n",
      "276 1996 3382\n",
      "277 9179 1012\n",
      "278 2472 2\n",
      "279 2409 1024\n",
      "280 2014 2008\n",
      "281 2008 2003\n",
      "282 1045 15571\n",
      "283 4771 1012\n",
      "284 2026 1045\n",
      "285 3382 1005\n",
      "286 1012 2222\n",
      "287 5882 2655\n",
      "288 1016 2014\n",
      "289 1024 1998\n",
      "290 2008 2425\n",
      "291 2003 2014\n",
      "292 15571 2009\n",
      "293 1012 2001\n",
      "294 1045 6135\n",
      "295 1005 2026\n",
      "296 2222 6346\n",
      "297 2655 1012\n",
      "298 2014 12\n",
      "299 1998 1024\n",
      "300 2425 6887\n",
      "301 2014 4402\n",
      "302 2009 5910\n",
      "303 2001 1010\n",
      "304 6135 2017\n",
      "305 2026 2064\n",
      "306 6346 1005\n",
      "307 1012 1056\n",
      "308 3 2079\n",
      "309 1024 2008\n",
      "310 6887 1012\n",
      "311 4402 1996\n",
      "312 5910 9179\n",
      "313 1010 2472\n",
      "314 2017 2987\n",
      "315 2064 1005\n",
      "316 1005 1056\n",
      "317 1056 2831\n",
      "318 2079 2000\n",
      "319 2008 2814\n",
      "320 1012 1010\n",
      "321 1996 2016\n",
      "322 9179 2069\n",
      "323 2472 7566\n",
      "324 2987 2000\n",
      "325 1005 6074\n",
      "326 1056 1012\n",
      "327 2831 2\n",
      "328 2000 1024\n",
      "329 2814 2054\n",
      "330 1010 1037\n",
      "331 2016 6517\n",
      "332 2069 2210\n",
      "333 7566 2166\n",
      "334 2000 2016\n",
      "335 6074 2442\n",
      "336 1012 2599\n",
      "337 5882 1012\n",
      "338 1016 3100\n",
      "339 1024 1010\n",
      "340 2054 1051\n",
      "341 1037 11631\n",
      "342 6517 1012\n",
      "343 2210 12\n",
      "344 2166 1024\n",
      "345 2016 2054\n",
      "346 2442 1010\n",
      "347 2599 2054\n",
      "348 1012 2024\n",
      "349 3100 2017\n",
      "350 1010 2725\n",
      "351 1051 1029\n",
      "352 11631 2054\n",
      "353 1012 2024\n",
      "354 3 2017\n",
      "355 1024 2725\n",
      "356 2054 1029\n",
      "357 1010 2\n",
      "358 2054 1024\n",
      "359 2024 2053\n",
      "360 2017 1010\n",
      "361 2725 2053\n",
      "362 1029 1010\n",
      "363 2054 2053\n",
      "364 2024 1010\n",
      "365 2017 1045\n",
      "366 2725 2113\n",
      "367 1029 1010\n",
      "368 5882 1045\n",
      "369 1016 2113\n",
      "370 1024 1010\n",
      "371 2053 1051\n",
      "372 1010 11631\n",
      "373 2053 1012\n",
      "374 1010 1005\n",
      "375 2053 7632\n",
      "377 1045 2023\n",
      "378 2113 2003\n",
      "379 1010 5736\n",
      "380 1045 27610\n",
      "381 2113 1010\n",
      "382 1010 2013\n",
      "383 1051 18188\n",
      "384 11631 23176\n",
      "385 1012 4710\n",
      "387 7632 1055\n",
      "388 1010 2436\n",
      "389 2023 1012\n",
      "390 2003 8529\n",
      "391 5736 1010\n",
      "392 27610 2003\n",
      "393 1010 8529\n",
      "394 2013 1010\n",
      "395 18188 5754\n",
      "396 23176 2045\n",
      "397 4710 2005\n",
      "398 1005 18188\n",
      "399 1055 1010\n",
      "400 2436 2016\n",
      "401 1012 1005\n",
      "402 8529 2222\n",
      "403 1010 2113\n",
      "404 2003 2054\n",
      "405 8529 2009\n",
      "406 1010 1005\n",
      "407 5754 1055\n",
      "408 2045 2055\n",
      "409 2005 1012\n",
      "410 18188 1005\n",
      "411 1010 12\n",
      "412 2016 1024\n",
      "413 1005 6865\n",
      "414 2222 2039\n",
      "415 2113 1010\n",
      "416 2054 6865\n",
      "417 2009 2039\n",
      "418 1005 1012\n",
      "419 1055 2\n",
      "420 2055 1024\n",
      "421 1012 1005\n",
      "422 1005 8194\n",
      "423 3 999\n",
      "424 1024 7632\n",
      "425 6865 1012\n",
      "426 2039 4952\n",
      "427 1010 2057\n",
      "428 6865 2288\n",
      "429 2039 1037\n",
      "430 1012 3291\n",
      "431 5882 2007\n",
      "432 1016 9558\n",
      "433 1024 13012\n",
      "434 1005 10322\n",
      "435 8194 25443\n",
      "436 999 1010\n",
      "437 7632 4593\n",
      "438 1012 2002\n",
      "439 4952 4771\n",
      "440 2057 2010\n",
      "441 2288 14597\n",
      "442 1037 1012\n",
      "443 3291 2040\n",
      "444 2007 2106\n",
      "445 9558 2017\n",
      "446 13012 3713\n",
      "447 10322 2000\n",
      "448 25443 1999\n",
      "449 1010 2026\n",
      "450 4593 2436\n",
      "451 2002 1029\n",
      "452 4771 1063\n",
      "453 2010 9178\n",
      "454 14597 1035\n",
      "455 1012 1015\n",
      "456 2040 1065\n",
      "457 2106 1010\n",
      "458 2017 2053\n",
      "459 3713 1010\n",
      "460 2000 1045\n",
      "461 1999 2123\n",
      "462 2026 1005\n",
      "463 2436 1056\n",
      "464 1029 2113\n",
      "465 28517 2054\n",
      "466 6216 1045\n",
      "467 1010 1005\n",
      "468 2053 1049\n",
      "469 1010 2183\n",
      "470 1045 2000\n",
      "471 2123 2079\n",
      "472 1005 2007\n",
      "473 1056 2014\n",
      "474 2113 1012\n",
      "475 2054 2053\n",
      "476 1045 1012\n",
      "477 1005 2035\n",
      "478 1049 2157\n",
      "479 2183 1010\n",
      "480 2000 2061\n",
      "481 2079 2115\n",
      "482 2007 3129\n",
      "483 2014 3727\n",
      "484 1012 1998\n",
      "485 2053 7641\n",
      "486 1012 2091\n",
      "487 2035 1996\n",
      "488 2157 4545\n",
      "490 2061 1996\n",
      "491 2115 2088\n",
      "492 3129 2515\n",
      "493 3727 2025\n",
      "494 1998 2644\n",
      "495 7641 1012\n",
      "496 2091 1005\n",
      "497 1996 3\n",
      "498 4545 1024\n",
      "499 1010 2003\n",
      "500 1996 10334\n",
      "501 2088 2842\n",
      "502 2515 6015\n",
      "503 2025 1029\n",
      "504 2644 102\n",
      "505 1012 11\n",
      "507 28517 12\n",
      "508 6216 102\n",
      "509 102 0\n",
      "510 3 0\n",
      "511 102 0\n"
     ]
    }
   ],
   "source": [
    "a = dev['data'][0]['']\n",
    "for i in range(len(a)):\n",
    "\tif (a[i]!=input_ids[i]):\n",
    "\t\tprint(i, a[i], input_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/59 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Iteration: 100%|██████████| 59/59 [09:52<00:00, 10.05s/it]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../temp_testing/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(logits)):\n\u001b[0;32m     28\u001b[0m \t\tlogits_all \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [logits[i]]\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msavefile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     31\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(logits_all)):\n\u001b[0;32m     32\u001b[0m \t\t\u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(logits_all[i])):\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../temp_testing/'"
     ]
    }
   ],
   "source": [
    "from tucore_gcn_bert_train import get_logits4eval\n",
    "model = m\n",
    "dataset = tucore_dataset['validation']\n",
    "batch_size = 32\n",
    "savefile = \"../temp_testing/\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.eval()\n",
    "logits_all = []\n",
    "n_batches = len(dataset) // batch_size\n",
    "for step in tqdm(range(n_batches), desc=\"Iteration\"):\n",
    "\tshard = dataset.shard(num_shards=n_batches, index=step)\n",
    "\tlabel_ids = torch.LongTensor(shard[\"label_ids\"]).contiguous().to(device).float()\n",
    "\tinput_ids = torch.LongTensor(shard[\"input_ids\"]).contiguous().to(device)\n",
    "\tsegment_ids = torch.LongTensor(shard[\"segment_ids\"]).contiguous().to(device)\n",
    "\tinput_masks = torch.LongTensor(shard[\"input_mask\"]).contiguous().to(device)\n",
    "\tmention_ids = torch.LongTensor(shard[\"mention_ids\"]).contiguous().to(device)\n",
    "\tspeaker_ids = torch.LongTensor(shard[\"speaker_ids\"]).contiguous().to(device)\n",
    "\tturn_mask = torch.LongTensor(shard[\"turn_masks\"]).contiguous().to(device)\n",
    "\t# forgot to flatten the list 1\n",
    "\tgraphs = [pickle.loads(g)[0].to(device) for g in shard[\"graph\"]]\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_masks, speaker_ids=speaker_ids, graphs=graphs, mention_ids=mention_ids, labels=label_ids, turn_mask=turn_mask)\n",
    "\t\tlogits = output.logits\n",
    "\n",
    "\tlogits = logits.detach().cpu().numpy()\n",
    "\tfor i in range(len(logits)):\n",
    "\t\tlogits_all += [logits[i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = \"../temp_testing/logits_dev.txt\"\n",
    "with open(savefile, \"w\") as f:\n",
    "\tfor i in range(len(logits_all)):\n",
    "\t\tfor j in range(len(logits_all[i])):\n",
    "\t\t\tf.write(str(logits_all[i][j]))\n",
    "\t\t\tif j == len(logits_all[i])-1:\n",
    "\t\t\t\tf.write(\"\\n\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tf.write(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getresult(fn):\n",
    "    result = []\n",
    "    with open(fn, \"r\") as f:\n",
    "        l = f.readline()\n",
    "        while l:\n",
    "            l = l.strip().split()\n",
    "            for i in range(len(l)):\n",
    "                l[i] = float(l[i])\n",
    "            result += [l]\n",
    "            l = f.readline()\n",
    "    result = np.asarray(result)\n",
    "    return list(1 / (1 + np.exp(-result)))\n",
    "\n",
    "def getpredict(result, T1 = 0.5, T2 = 0.4):\n",
    "    for i in range(len(result)):\n",
    "        r = []\n",
    "        maxl, maxj = -1, -1\n",
    "        for j in range(len(result[i])):\n",
    "            if result[i][j] > T1:\n",
    "                r += [j]\n",
    "            if result[i][j] > maxl:\n",
    "                maxl = result[i][j]\n",
    "                maxj = j\n",
    "        if len(r) == 0:\n",
    "            if maxl <= T2:\n",
    "                r = [36]\n",
    "            else:\n",
    "                r += [maxj]\n",
    "        result[i] = r\n",
    "    return result\n",
    "\n",
    "def evaluate(devp, data):\n",
    "    index = 0\n",
    "    correct_sys, all_sys = 0, 0\n",
    "    correct_gt = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i][1])):\n",
    "            for id in data[i][1][j][\"rid\"]:\n",
    "                if id != 36:\n",
    "                    correct_gt += 1\n",
    "                    if id in devp[index]:\n",
    "                        correct_sys += 1\n",
    "            for id in devp[index]:\n",
    "                if id != 36:\n",
    "                    all_sys += 1\n",
    "            index += 1\n",
    "\n",
    "    precision = correct_sys/all_sys if all_sys != 0 else 1\n",
    "    recall = correct_sys/correct_gt if correct_gt != 0 else 0\n",
    "    f_1 = 2*precision*recall/(precision+recall) if precision+recall != 0 else 0\n",
    "\n",
    "    return precision, recall, f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1dev = \"../TUCOREGCN_BERT_DialogRE/logits_dev.txt\"\n",
    "import json\n",
    "with open(\"../datasets/DialogRE/dev.json\", \"r\", encoding='utf8') as f:\n",
    "    datadev = json.load(f)\n",
    "for i in range(len(datadev)):\n",
    "    for j in range(len(datadev[i][1])):\n",
    "        for k in range(len(datadev[i][1][j][\"rid\"])):\n",
    "            datadev[i][1][j][\"rid\"][k] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "bestT2 = bestf_1 = 0\n",
    "for T2 in range(51):\n",
    "\tdev = getresult(f1dev)\n",
    "\tdevp = getpredict(dev, T2=T2/100.)\n",
    "\tprecision, recall, f_1 = evaluate(devp, datadev)\n",
    "\tif f_1 > bestf_1:\n",
    "\t\tbestf_1 = f_1\n",
    "\t\tbestT2 = T2/100.\n",
    "\tprint(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev (P R F1) 0.5371127995324372 0.5754539762053851 0.5556227327690447\n"
     ]
    }
   ],
   "source": [
    "dev = getresult(f1dev)\n",
    "devp = getpredict(dev, T2=bestT2)\n",
    "precision, recall, f_1 = evaluate(devp, datadev)\n",
    "print(\"dev (P R F1)\", precision, recall, f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tucore_dataset['validation']['label_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 28,\n",
       " 28,\n",
       " 16,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 16,\n",
       " 29,\n",
       " 16,\n",
       " 28,\n",
       " 16,\n",
       " 36,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 29,\n",
       " 12,\n",
       " 12,\n",
       " 29,\n",
       " 36,\n",
       " 14,\n",
       " 36,\n",
       " 36,\n",
       " 12,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 29,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 14,\n",
       " 24,\n",
       " 15,\n",
       " 29,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 28,\n",
       " 21,\n",
       " 34,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 28,\n",
       " 0,\n",
       " 36,\n",
       " 5,\n",
       " 0,\n",
       " 15,\n",
       " 28,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 19,\n",
       " 19,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 24,\n",
       " 13,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 28,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 13,\n",
       " 12,\n",
       " 0,\n",
       " 28,\n",
       " 30,\n",
       " 21,\n",
       " 29,\n",
       " 0,\n",
       " 34,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 20,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 19,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 19,\n",
       " 8,\n",
       " 33,\n",
       " 33,\n",
       " 8,\n",
       " 36,\n",
       " 28,\n",
       " 6,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 14,\n",
       " 12,\n",
       " 29,\n",
       " 23,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 9,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 23,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 27,\n",
       " 19,\n",
       " 29,\n",
       " 33,\n",
       " 34,\n",
       " 8,\n",
       " 36,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 15,\n",
       " 6,\n",
       " 15,\n",
       " 28,\n",
       " 29,\n",
       " 15,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 12,\n",
       " 0,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 0,\n",
       " 14,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 36,\n",
       " 28,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 36,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 19,\n",
       " 16,\n",
       " 33,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 0,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 13,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 27,\n",
       " 8,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 15,\n",
       " 19,\n",
       " 29,\n",
       " 29,\n",
       " 17,\n",
       " 15,\n",
       " 29,\n",
       " 33,\n",
       " 33,\n",
       " 15,\n",
       " 15,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 15,\n",
       " 29,\n",
       " 15,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 6,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 29,\n",
       " 27,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 14,\n",
       " 12,\n",
       " 29,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 13,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 8,\n",
       " 6,\n",
       " 36,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 36,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 36,\n",
       " 36,\n",
       " 8,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 21,\n",
       " 34,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 15,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 15,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 23,\n",
       " 21,\n",
       " 29,\n",
       " 34,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 30,\n",
       " 29,\n",
       " 29,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 15,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 1,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 15,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 12,\n",
       " 36,\n",
       " 15,\n",
       " 29,\n",
       " 36,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 6,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 36,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 27,\n",
       " 0,\n",
       " 27,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 28,\n",
       " 29,\n",
       " 0,\n",
       " 27,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 1,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 16,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 17,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 14,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 29,\n",
       " 14,\n",
       " 14,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 28,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 15,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 15,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 28,\n",
       " 29,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 31,\n",
       " 31,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 12,\n",
       " 29,\n",
       " 28,\n",
       " 28,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 11,\n",
       " 0,\n",
       " 29,\n",
       " 11,\n",
       " 8,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 8,\n",
       " 1,\n",
       " 15,\n",
       " 29,\n",
       " 15,\n",
       " 36,\n",
       " 0,\n",
       " 28,\n",
       " 0,\n",
       " 28,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 19,\n",
       " 29,\n",
       " 29,\n",
       " 19,\n",
       " 33,\n",
       " 33,\n",
       " 16,\n",
       " 16,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 15,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 16,\n",
       " 29,\n",
       " 16,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 8,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 16,\n",
       " 29,\n",
       " 16,\n",
       " 29,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 36,\n",
       " 28,\n",
       " 5,\n",
       " 29,\n",
       " 28,\n",
       " 36,\n",
       " 29,\n",
       " 5,\n",
       " 0,\n",
       " 14,\n",
       " 15,\n",
       " 0,\n",
       " 36,\n",
       " 9,\n",
       " 15,\n",
       " 36,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 15,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 16,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 24,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 24,\n",
       " 0,\n",
       " 12,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 28,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 31,\n",
       " 33,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 36,\n",
       " 9,\n",
       " 36,\n",
       " 36,\n",
       " 29,\n",
       " 1,\n",
       " 29,\n",
       " 11,\n",
       " 29,\n",
       " 11,\n",
       " 29,\n",
       " 15,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 15,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 12,\n",
       " 29,\n",
       " 29,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 14,\n",
       " 36,\n",
       " 15,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 12,\n",
       " 9,\n",
       " 29,\n",
       " 36,\n",
       " 16,\n",
       " 0,\n",
       " 34,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 36,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 36,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 16,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 15,\n",
       " 15,\n",
       " 29,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 36,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 8,\n",
       " 36,\n",
       " 0,\n",
       " 8,\n",
       " 36,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 29,\n",
       " 29,\n",
       " 27,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 8,\n",
       " 34,\n",
       " 8,\n",
       " 29,\n",
       " 11,\n",
       " 29,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v[0] for v in devp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 36,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 36,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 36,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 36,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 36,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 36,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 36,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 29,\n",
       " 0,\n",
       " 9,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 29,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 29,\n",
       " 29,\n",
       " 9,\n",
       " 9,\n",
       " 29,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v[0] for v in devp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    1228\n",
       "8      336\n",
       "9      254\n",
       "0       93\n",
       "14       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([v[0]-1 for v in devp]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "from tucore_gcn_bert_tokenizer import SpeakerBertTokenizer\n",
    "from tucore_gcn_bert_pipeline import ConversationalSequenceClassificationPipeline\n",
    "from tucore_gcn_bert_modelling import TUCOREGCN_BertForSequenceClassification, TUCOREGCN_BertConfig\n",
    "import os\n",
    "PIPELINE_REGISTRY.register_pipeline(\n",
    "    \"conversational-sequence-classification\",\n",
    "    pipeline_class=ConversationalSequenceClassificationPipeline\n",
    ")\n",
    "speaker_tokenizer = SpeakerBertTokenizer.from_pretrained('bert-base-uncased')\n",
    "m.cuda()\n",
    "classifier = pipeline(\"conversational-sequence-classification\", model=m, tokenizer=speaker_tokenizer, device=\"cuda:0\", n_class=36, max_seq_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LABEL_9'] [0.2906779944896698]\n"
     ]
    }
   ],
   "source": [
    "from tucore_gcn_bert_processor import SpeakerRelation, Conversation, Message\n",
    "\n",
    "c = Conversation(\n",
    "\tmessages=[\n",
    "\t\tMessage(\"Speaker 1\", \"Howdy! I'm Flowey, Flowey the Flower!\"),\n",
    "\t\tMessage(\"Speaker 2\", \"Hello Flowey. I'm your very best friend!\"),\n",
    "\t\tMessage(\"Speaker 2\", \"You're new to the underground, aren'tcha?\"),\n",
    "\t],\n",
    "\tspeaker_relations=[\n",
    "\t\tSpeakerRelation(\"Speaker 1\", \"Speaker 2\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "labels, scores, logits = classifier(c).values()\n",
    "print(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapshot = pickle.load(open(\"../sapshot.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(sapshot, open(\"sapshot.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path[0] = \"d:\\\\projects\\\\affect\\\\TUCORE-GCN\\\\\"\n",
    "sys.path\n",
    "if __name__==\"main\": print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../datasets/DialogRE/.\n",
      "load preprocessed data from ../datasets/DialogRE/train_BERT.pkl.\n"
     ]
    }
   ],
   "source": [
    "from data import TUCOREGCNDataloader, TUCOREGCNDataset\n",
    "from models.BERT import tokenization\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=\"../pre-trained_model/BERT/vocab.txt\", do_lower_case=True)\n",
    "train_set = TUCOREGCNDataset(src_file=\"../datasets/DialogRE/\", save_file=\"../datasets/DialogRE/train_BERT.pkl\", max_seq_length=512, tokenizer=tokenizer, n_class=36, encoder_type=\"BERT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'hey',\n",
       " ',',\n",
       " 'sophie',\n",
       " '!',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'hey',\n",
       " ',',\n",
       " 'ra',\n",
       " '##ch',\n",
       " '!',\n",
       " '[unused1]',\n",
       " ':',\n",
       " 'hey',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'hey',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'lunch',\n",
       " ',',\n",
       " 'chandler',\n",
       " '.',\n",
       " 'y',\n",
       " \"'\",\n",
       " 'know',\n",
       " ',',\n",
       " 'you',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'have',\n",
       " 'to',\n",
       " 'walk',\n",
       " 'me',\n",
       " 'all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'back',\n",
       " 'up',\n",
       " 'here',\n",
       " '.',\n",
       " '[unused1]',\n",
       " ':',\n",
       " 'oh',\n",
       " ',',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " '-',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'okay',\n",
       " ',',\n",
       " 'no',\n",
       " 'problem',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'honey',\n",
       " 'um',\n",
       " ',',\n",
       " 'honey',\n",
       " ',',\n",
       " 'you',\n",
       " 'do',\n",
       " 'realise',\n",
       " 'that',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'women',\n",
       " \"'\",\n",
       " 's',\n",
       " 'linger',\n",
       " '##ie',\n",
       " 'here',\n",
       " 'in',\n",
       " 'the',\n",
       " 'office',\n",
       " '?',\n",
       " '[unused1]',\n",
       " ':',\n",
       " 'yes',\n",
       " ',',\n",
       " 'i',\n",
       " 'realise',\n",
       " 'that',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'summer',\n",
       " 'catalogue',\n",
       " '!',\n",
       " '[unused1]',\n",
       " ':',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'the',\n",
       " 'stuff',\n",
       " '!',\n",
       " '[SEP]',\n",
       " '[unused1]',\n",
       " '[SEP]',\n",
       " 'honey',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(train_set.data[2]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(enumerate(dev_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,    3, 1024,  ...,  102,    3,  102],\n",
       "         [ 101, 5882, 1015,  ...,  102, 4005,  102],\n",
       "         [ 101, 5882, 1015,  ..., 9179, 2472,  102],\n",
       "         ...,\n",
       "         [ 101,    3, 1024,  ...,  102,    3,  102],\n",
       "         [ 101, 5882, 1015,  ..., 9179, 2472,  102],\n",
       "         [ 101, 5882, 1015,  ...,  102, 8194,  102]], device='cuda:0'),\n",
       " 'segment_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'),\n",
       " 'input_masks': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'),\n",
       " 'mention_ids': tensor([[ 0,  1,  1,  ...,  0, 22,  0],\n",
       "         [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "         [ 0,  1,  1,  ..., 22, 22,  0],\n",
       "         ...,\n",
       "         [ 0,  1,  1,  ...,  0, 23,  0],\n",
       "         [ 0,  1,  1,  ..., 22, 22,  0],\n",
       "         [ 0,  1,  1,  ...,  0, 22,  0]], device='cuda:0'),\n",
       " 'speaker_ids': tensor([[ 0, 12, 12,  ...,  0, 12,  0],\n",
       "         [ 0,  1,  1,  ...,  0,  0,  0],\n",
       "         [ 0,  1,  1,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0, 12, 12,  ...,  0, 12,  0],\n",
       "         [ 0,  1,  1,  ...,  0,  0,  0],\n",
       "         [ 0,  1,  1,  ...,  0,  0,  0]], device='cuda:0'),\n",
       " 'label_ids': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "        device='cuda:0'),\n",
       " 'turn_masks': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 1, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 1, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 1]]], device='cuda:0'),\n",
       " 'graphs': [Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 24, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 10, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 10, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 24},\n",
       "        num_edges={('node', 'dialog', 'node'): 42, ('node', 'entity', 'node'): 36, ('node', 'speaker', 'node'): 118},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 22, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 22, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 22, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 22, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 22, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 24},\n",
       "        num_edges={('node', 'dialog', 'node'): 42, ('node', 'entity', 'node'): 36, ('node', 'speaker', 'node'): 118},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 10, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 8, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')])]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 5991\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 1862\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 1914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "tucore_dataset = datasets.load_from_disk(\"../datasets/DialogRE/fixed_arrow/\")\n",
    "tucore_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467042"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = open('test3.txt', 'w')\n",
    "b.write(str(tucore_dataset['train'][112]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613629387086872"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5997/(5997+1862+1914)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19052491558375115"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1862/(5997+1862+1914)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19584569732937684"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1914/(5997+1862+1914)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "token_df = pd.Series(tucore_data['train']['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     3215\n",
       "False    2782\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(token_df.str.join(' ').str.replace(\" [PAD]\", \"\").str.split(' ').str.len()>256).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(tucore_data['train'][0]['graph'])[0].is_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 5983\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 1862\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'label_ids', 'input_ids', 'input_mask', 'segment_ids', 'speaker_ids', 'mention_ids', 'turn_masks', 'graph'],\n",
       "        num_rows: 1914\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "datasets.load_from_disk(\"../datasets/DialogRE/real_arrow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tucore_data['train'])//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tucore_data.load_from_disk(\"../datasets/DialogRE/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37580603e713491fa6f80ed2aaad79ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d83edd0024288996ea5335af1797d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78172fc32f6a4d5f83ea06a694f8af13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tucore_data.save_to_disk(\"../datasets/DialogRE/arrow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tucoregcn_bert.bert.embeddings.word_embeddings.weight',\n",
       " 'tucoregcn_bert.bert.embeddings.position_embeddings.weight',\n",
       " 'tucoregcn_bert.bert.embeddings.token_type_embeddings.weight',\n",
       " 'tucoregcn_bert.bert.embeddings.speaker_embeddings.weight',\n",
       " 'tucoregcn_bert.bert.embeddings.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.embeddings.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.query.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.query.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.key.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.key.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.value.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.self.value.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.output.dense.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.output.dense.bias',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.weight',\n",
       " 'tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.bias',\n",
       " 'tucoregcn_bert.bert.pooler.dense.weight',\n",
       " 'tucoregcn_bert.bert.pooler.dense.bias',\n",
       " 'tucoregcn_bert.turnAttention.w_qs.weight',\n",
       " 'tucoregcn_bert.turnAttention.w_ks.weight',\n",
       " 'tucoregcn_bert.turnAttention.w_vs.weight',\n",
       " 'tucoregcn_bert.turnAttention.out_lin.weight',\n",
       " 'tucoregcn_bert.turnAttention.layer_norm.weight',\n",
       " 'tucoregcn_bert.turnAttention.layer_norm.bias',\n",
       " 'tucoregcn_bert.GCN_layers.0.weight',\n",
       " 'tucoregcn_bert.GCN_layers.0.h_bias',\n",
       " 'tucoregcn_bert.GCN_layers.0.loop_weight',\n",
       " 'tucoregcn_bert.GCN_layers.1.weight',\n",
       " 'tucoregcn_bert.GCN_layers.1.h_bias',\n",
       " 'tucoregcn_bert.GCN_layers.1.loop_weight',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.weight',\n",
       " 'tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.bias',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1_reverse',\n",
       " 'tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.weight',\n",
       " 'tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.bias',\n",
       " 'classifier.weight',\n",
       " 'classifier.bias']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tucore_gcn_transformers.tucore_gcn_bert_modelling import TUCOREGCN_BertForSequenceClassification, TUCOREGCN_BertConfig\n",
    "model = TUCOREGCN_BertForSequenceClassification(config=TUCOREGCN_BertConfig.from_json_file(\"../tucore_gcn_transformers/tucore_gcn_bert_mlc.json\"))\n",
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "Dataset.save_to_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes={'node': 12},\n",
       "       num_edges={('node', 'dialog', 'node'): 18, ('node', 'entity', 'node'): 6, ('node', 'speaker', 'node'): 24},\n",
       "       metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(tucore_data['train'][0]['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tucore_dataset._generate_examples('../datasets/DialogRE/dev.json', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60445c0e9df2403188339e1539eeaf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'tokens': ['[CLS]',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'all',\n",
       "   'right',\n",
       "   '!',\n",
       "   'westminster',\n",
       "   'abbey',\n",
       "   '!',\n",
       "   'hands',\n",
       "   'down',\n",
       "   ',',\n",
       "   'best',\n",
       "   'abbey',\n",
       "   'i',\n",
       "   '’',\n",
       "   've',\n",
       "   'ever',\n",
       "   'seen',\n",
       "   '.',\n",
       "   'hey',\n",
       "   '!',\n",
       "   'okay',\n",
       "   '.',\n",
       "   'what',\n",
       "   'do',\n",
       "   'you',\n",
       "   'think',\n",
       "   'of',\n",
       "   'the',\n",
       "   'abbey',\n",
       "   ',',\n",
       "   'chandler',\n",
       "   '?',\n",
       "   '{entity_1}',\n",
       "   ':',\n",
       "   'i',\n",
       "   'think',\n",
       "   'it',\n",
       "   '’',\n",
       "   's',\n",
       "   'great',\n",
       "   '.',\n",
       "   'it',\n",
       "   '’',\n",
       "   's',\n",
       "   'great',\n",
       "   '.',\n",
       "   'y',\n",
       "   '’',\n",
       "   'know',\n",
       "   ',',\n",
       "   'they',\n",
       "   '’',\n",
       "   're',\n",
       "   'thinking',\n",
       "   'of',\n",
       "   'changing',\n",
       "   'the',\n",
       "   'name',\n",
       "   'of',\n",
       "   'this',\n",
       "   'place',\n",
       "   '.',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'really',\n",
       "   '?',\n",
       "   'to',\n",
       "   'what',\n",
       "   '?',\n",
       "   '{entity_1}',\n",
       "   ':',\n",
       "   'to',\n",
       "   'put',\n",
       "   'the',\n",
       "   'camera',\n",
       "   'away',\n",
       "   '!',\n",
       "   '!',\n",
       "   '!',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'man',\n",
       "   ',',\n",
       "   'you',\n",
       "   'are',\n",
       "   '{',\n",
       "   'entity',\n",
       "   '_',\n",
       "   '2',\n",
       "   '}',\n",
       "   '.',\n",
       "   '[SEP]',\n",
       "   '{entity_1}',\n",
       "   '[SEP]',\n",
       "   '{entity_2}',\n",
       "   '[SEP]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]'],\n",
       "  'input_ids': array([  101,     1,  1024,  2035,  2157,   999,  9434,  6103,   999,\n",
       "          2398,  2091,  1010,  2190,  6103,  1045,  1521,  2310,  2412,\n",
       "          2464,  1012,  4931,   999,  3100,  1012,  2054,  2079,  2017,\n",
       "          2228,  1997,  1996,  6103,  1010, 13814,  1029,    11,  1024,\n",
       "          1045,  2228,  2009,  1521,  1055,  2307,  1012,  2009,  1521,\n",
       "          1055,  2307,  1012,  1061,  1521,  2113,  1010,  2027,  1521,\n",
       "          2128,  3241,  1997,  5278,  1996,  2171,  1997,  2023,  2173,\n",
       "          1012,     1,  1024,  2428,  1029,  2000,  2054,  1029,    11,\n",
       "          1024,  2000,  2404,  1996,  4950,  2185,   999,   999,   999,\n",
       "             1,  1024,  2158,  1010,  2017,  2024,  1063,  9178,  1035,\n",
       "          1016,  1065,  1012,   102,    11,   102,    12,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'input_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       "  'segment_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       "  'speaker_ids': array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  1,  1,  1,  1,\n",
       "          1,  1,  1, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  0, 11,  0, 12,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]),\n",
       "  'mention_ids': array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "         3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 0, 6, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       "  'turn_masks': array([[ True, False, False, ..., False, False, False],\n",
       "         [False,  True,  True, ..., False, False, False],\n",
       "         [False,  True,  True, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ...,  True, False, False],\n",
       "         [False, False, False, ..., False,  True, False],\n",
       "         [False, False, False, ..., False, False,  True]]),\n",
       "  'graph': b\"\\x80\\x04\\x95|\\x0c\\x00\\x00\\x00\\x00\\x00\\x00]\\x94\\x8c\\x0fdgl.heterograph\\x94\\x8c\\x08DGLGraph\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x06_graph\\x94\\x8c\\x0fdgl._ffi.object\\x94\\x8c\\x0b_new_object\\x94\\x93\\x94\\x8c\\x15dgl.heterograph_index\\x94\\x8c\\x10HeteroGraphIndex\\x94\\x93\\x94\\x85\\x94R\\x94h\\th\\n\\x8c\\x12HeteroPickleStates\\x94\\x93\\x94\\x85\\x94R\\x94K\\x02\\x8c\\x08builtins\\x94\\x8c\\tbytearray\\x94\\x93\\x94B\\x14\\x01\\x00\\x00\\xbfj\\x04 \\xfe_<\\xdd'\\xf1\\xdf\\x05\\x12\\xd3l\\xdd\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\xa1\\xb4\\x96\\xf0@^\\xdd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x01\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\xa1\\xb4\\x96\\xf0@^\\xdd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x01\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00?\\xa1\\xb4\\x96\\xf0@^\\xdd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x01\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94]\\x94(\\x8c\\x0ctorch._utils\\x94\\x8c\\x12_rebuild_tensor_v2\\x94\\x93\\x94(\\x8c\\rtorch.storage\\x94\\x8c\\x10_load_from_bytes\\x94\\x93\\x94BH\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679929968q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\nNtq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679929968q\\x01a.\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\n\\x85\\x94K\\x01\\x85\\x94\\x89\\x8c\\x0bcollections\\x94\\x8c\\x0bOrderedDict\\x94\\x93\\x94)R\\x94t\\x94R\\x94h\\x1c(h\\x1fBH\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679927088q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\nNtq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679927088q\\x01a.\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\n\\x85\\x94K\\x01\\x85\\x94\\x89h')R\\x94t\\x94R\\x94h\\x1c(h\\x1fB8\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679926704q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\x08Ntq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679926704q\\x01a.\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\x08\\x85\\x94K\\x01\\x85\\x94\\x89h')R\\x94t\\x94R\\x94h\\x1c(h\\x1fB8\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679928240q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\x08Ntq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679928240q\\x01a.\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\x08\\x85\\x94K\\x01\\x85\\x94\\x89h')R\\x94t\\x94R\\x94h\\x1c(h\\x1fB8\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679930064q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\x08Ntq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679930064q\\x01a.\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\x08\\x85\\x94K\\x01\\x85\\x94\\x89h')R\\x94t\\x94R\\x94h\\x1c(h\\x1fB8\\x01\\x00\\x00\\x80\\x02\\x8a\\nl\\xfc\\x9cF\\xf9 j\\xa8P\\x19.\\x80\\x02M\\xe9\\x03.\\x80\\x02}q\\x00(X\\x10\\x00\\x00\\x00protocol_versionq\\x01M\\xe9\\x03X\\r\\x00\\x00\\x00little_endianq\\x02\\x88X\\n\\x00\\x00\\x00type_sizesq\\x03}q\\x04(X\\x05\\x00\\x00\\x00shortq\\x05K\\x02X\\x03\\x00\\x00\\x00intq\\x06K\\x04X\\x04\\x00\\x00\\x00longq\\x07K\\x04uu.\\x80\\x02(X\\x07\\x00\\x00\\x00storageq\\x00ctorch\\nLongStorage\\nq\\x01X\\r\\x00\\x00\\x002843679930448q\\x02X\\x03\\x00\\x00\\x00cpuq\\x03K\\x08Ntq\\x04Q.\\x80\\x02]q\\x00X\\r\\x00\\x00\\x002843679930448q\\x01a.\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x85\\x94R\\x94K\\x00K\\x08\\x85\\x94K\\x01\\x85\\x94\\x89h')R\\x94t\\x94R\\x94e\\x87\\x94bb\\x8c\\x11_canonical_etypes\\x94]\\x94(\\x8c\\x04node\\x94\\x8c\\x06dialog\\x94hV\\x87\\x94hV\\x8c\\x06entity\\x94hV\\x87\\x94hV\\x8c\\x07speaker\\x94hV\\x87\\x94e\\x8c\\x10_batch_num_nodes\\x94N\\x8c\\x10_batch_num_edges\\x94N\\x8c\\x07_ntypes\\x94]\\x94hVa\\x8c\\x10_is_unibipartite\\x94\\x89\\x8c\\x10_srctypes_invmap\\x94}\\x94hVK\\x00s\\x8c\\x10_dsttypes_invmap\\x94hc\\x8c\\x07_etypes\\x94]\\x94(hWhYh[e\\x8c\\x10_etype2canonical\\x94}\\x94(hWhXhYhZh[h\\\\u\\x8c\\x0e_etypes_invmap\\x94}\\x94(hXK\\x00hZK\\x01h\\\\K\\x02u\\x8c\\x0c_node_frames\\x94]\\x94\\x8c\\tdgl.frame\\x94\\x8c\\x05Frame\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x08_columns\\x94}\\x94\\x8c\\t_num_rows\\x94K\\x08\\x8c\\r_initializers\\x94}\\x94\\x8c\\x14_default_initializer\\x94Nuba\\x8c\\x0c_edge_frames\\x94]\\x94(ho)\\x81\\x94}\\x94(hr}\\x94htK\\nhu}\\x94hwNubho)\\x81\\x94}\\x94(hr}\\x94htK\\x08hu}\\x94hwNubho)\\x81\\x94}\\x94(hr}\\x94htK\\x08hu}\\x94hwNubeuba.\"})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\dgl\\dgl.dll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'SpeakerBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9474d8e4bcb49faad36e474c5e240ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ec4a1078e4216a062c64b68e1ca95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da7a023bb9b4a82a32c91b439e89b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1914 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tucore_gcn_transformers.tucore_gcn_bert_train import build_inputs_from_dialogre\n",
    "split = build_inputs_from_dialogre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{speaker_1} : hey, by any chance did either of pick uh {entity_1} for your secret santa, ‘cause i wanna trade for her.\\n{speaker_2} : i picked her! oh thank god you want her! ooh!\\n{speaker_1} : wow! why do you want to get rid of her so badly?\\n{speaker_2} : because she exchanges every gift she ever gets, it’s like impossible to get her something she likes. come on, let’s trade!\\n{speaker_1} : oh that’s not true! that’s not true! i got her that backpack and she loved it! i remember how much she was crying the day when that big dog ran off with it… oh, there was no big dog. all right this sucks! i already got her this briefcase, and i had {entity_2} put on it… her initials…\\n{speaker_2} : ohh.\\n{speaker_3} : well, maybe you could give to somebody else. ooh, like ross geller.\\n{speaker_1} : op, y'know what though, it’s kind’ve a girlie briefcase.\\n{speaker_3} : who cares? he works in a museum!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['train'][0]['dialog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '{speaker_1}', ':', 'hey', ',', 'by', 'any', 'chance', 'did', 'either', 'of', 'pick', 'uh', '{entity_1}', 'for', 'your', 'secret', 'santa', ',', '‘', 'cause', 'i', 'wanna', 'trade', 'for', 'her', '.', '{speaker_2}', ':', 'i', 'picked', 'her', '!', 'oh', 'thank', 'god', 'you', 'want', 'her', '!', 'o', '##oh', '!', '{speaker_1}', ':', 'wow', '!', 'why', 'do', 'you', 'want', 'to', 'get', 'rid', 'of', 'her', 'so', 'badly', '?', '{speaker_2}', ':', 'because', 'she', 'exchanges', 'every', 'gift', 'she', 'ever', 'gets', ',', 'it', '’', 's', 'like', 'impossible', 'to', 'get', 'her', 'something', 'she', 'likes', '.', 'come', 'on', ',', 'let', '’', 's', 'trade', '!', '{speaker_1}', ':', 'oh', 'that', '’', 's', 'not', 'true', '!', 'that', '’', 's', 'not', 'true', '!', 'i', 'got', 'her', 'that', 'backpack', 'and', 'she', 'loved', 'it', '!', 'i', 'remember', 'how', 'much', 'she', 'was', 'crying', 'the', 'day', 'when', 'that', 'big', 'dog', 'ran', 'off', 'with', 'it', '…', 'oh', ',', 'there', 'was', 'no', 'big', 'dog', '.', 'all', 'right', 'this', 'sucks', '!', 'i', 'already', 'got', 'her', 'this', 'briefcase', ',', 'and', 'i', 'had', '{entity_2}', 'put', 'on', 'it', '…', 'her', 'initials', '…', '{speaker_2}', ':', 'oh', '##h', '.', '{speaker_3}', ':', 'well', ',', 'maybe', 'you', 'could', 'give', 'to', 'somebody', 'else', '.', 'o', '##oh', ',', 'like', 'ross', 'gel', '##ler', '.', '{speaker_1}', ':', 'op', ',', 'y', \"'\", 'know', 'what', 'though', ',', 'it', '’', 's', 'kind', '’', 've', 'a', 'girl', '##ie', 'briefcase', '.', '{speaker_3}', ':', 'who', 'cares', '?', 'he', 'works', 'in', 'a', 'museum', '!', '[SEP]', '{entity_1}', '[SEP]', '{entity_2}', '[SEP]'] [101, 1, 1024, 4931, 1010, 2011, 2151, 3382, 2106, 2593, 1997, 4060, 7910, 11, 2005, 2115, 3595, 4203, 1010, 1520, 3426, 1045, 10587, 3119, 2005, 2014, 1012, 2, 1024, 1045, 3856, 2014, 999, 2821, 4067, 2643, 2017, 2215, 2014, 999, 1051, 11631, 999, 1, 1024, 10166, 999, 2339, 2079, 2017, 2215, 2000, 2131, 9436, 1997, 2014, 2061, 6649, 1029, 2, 1024, 2138, 2016, 15800, 2296, 5592, 2016, 2412, 4152, 1010, 2009, 1521, 1055, 2066, 5263, 2000, 2131, 2014, 2242, 2016, 7777, 1012, 2272, 2006, 1010, 2292, 1521, 1055, 3119, 999, 1, 1024, 2821, 2008, 1521, 1055, 2025, 2995, 999, 2008, 1521, 1055, 2025, 2995, 999, 1045, 2288, 2014, 2008, 13383, 1998, 2016, 3866, 2009, 999, 1045, 3342, 2129, 2172, 2016, 2001, 6933, 1996, 2154, 2043, 2008, 2502, 3899, 2743, 2125, 2007, 2009, 1529, 2821, 1010, 2045, 2001, 2053, 2502, 3899, 1012, 2035, 2157, 2023, 19237, 999, 1045, 2525, 2288, 2014, 2023, 21793, 1010, 1998, 1045, 2018, 12, 2404, 2006, 2009, 1529, 2014, 20381, 1529, 2, 1024, 2821, 2232, 1012, 3, 1024, 2092, 1010, 2672, 2017, 2071, 2507, 2000, 8307, 2842, 1012, 1051, 11631, 1010, 2066, 5811, 21500, 3917, 1012, 1, 1024, 6728, 1010, 1061, 1005, 2113, 2054, 2295, 1010, 2009, 1521, 1055, 2785, 1521, 2310, 1037, 2611, 2666, 21793, 1012, 3, 1024, 2040, 14977, 1029, 2002, 2573, 1999, 1037, 2688, 999, 102, 11, 102, 12, 102] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1] [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 12, 12, 12, 12, 12, 12, 12, 12, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 11, 0, 12, 0] [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 0, 12, 0, 13, 0] 512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['[CLS]',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'hey',\n",
       "   ',',\n",
       "   'by',\n",
       "   'any',\n",
       "   'chance',\n",
       "   'did',\n",
       "   'either',\n",
       "   'of',\n",
       "   'pick',\n",
       "   'uh',\n",
       "   '{entity_1}',\n",
       "   'for',\n",
       "   'your',\n",
       "   'secret',\n",
       "   'santa',\n",
       "   ',',\n",
       "   '‘',\n",
       "   'cause',\n",
       "   'i',\n",
       "   'wanna',\n",
       "   'trade',\n",
       "   'for',\n",
       "   'her',\n",
       "   '.',\n",
       "   '{speaker_2}',\n",
       "   ':',\n",
       "   'i',\n",
       "   'picked',\n",
       "   'her',\n",
       "   '!',\n",
       "   'oh',\n",
       "   'thank',\n",
       "   'god',\n",
       "   'you',\n",
       "   'want',\n",
       "   'her',\n",
       "   '!',\n",
       "   'o',\n",
       "   '##oh',\n",
       "   '!',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'wow',\n",
       "   '!',\n",
       "   'why',\n",
       "   'do',\n",
       "   'you',\n",
       "   'want',\n",
       "   'to',\n",
       "   'get',\n",
       "   'rid',\n",
       "   'of',\n",
       "   'her',\n",
       "   'so',\n",
       "   'badly',\n",
       "   '?',\n",
       "   '{speaker_2}',\n",
       "   ':',\n",
       "   'because',\n",
       "   'she',\n",
       "   'exchanges',\n",
       "   'every',\n",
       "   'gift',\n",
       "   'she',\n",
       "   'ever',\n",
       "   'gets',\n",
       "   ',',\n",
       "   'it',\n",
       "   '’',\n",
       "   's',\n",
       "   'like',\n",
       "   'impossible',\n",
       "   'to',\n",
       "   'get',\n",
       "   'her',\n",
       "   'something',\n",
       "   'she',\n",
       "   'likes',\n",
       "   '.',\n",
       "   'come',\n",
       "   'on',\n",
       "   ',',\n",
       "   'let',\n",
       "   '’',\n",
       "   's',\n",
       "   'trade',\n",
       "   '!',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'oh',\n",
       "   'that',\n",
       "   '’',\n",
       "   's',\n",
       "   'not',\n",
       "   'true',\n",
       "   '!',\n",
       "   'that',\n",
       "   '’',\n",
       "   's',\n",
       "   'not',\n",
       "   'true',\n",
       "   '!',\n",
       "   'i',\n",
       "   'got',\n",
       "   'her',\n",
       "   'that',\n",
       "   'backpack',\n",
       "   'and',\n",
       "   'she',\n",
       "   'loved',\n",
       "   'it',\n",
       "   '!',\n",
       "   'i',\n",
       "   'remember',\n",
       "   'how',\n",
       "   'much',\n",
       "   'she',\n",
       "   'was',\n",
       "   'crying',\n",
       "   'the',\n",
       "   'day',\n",
       "   'when',\n",
       "   'that',\n",
       "   'big',\n",
       "   'dog',\n",
       "   'ran',\n",
       "   'off',\n",
       "   'with',\n",
       "   'it',\n",
       "   '…',\n",
       "   'oh',\n",
       "   ',',\n",
       "   'there',\n",
       "   'was',\n",
       "   'no',\n",
       "   'big',\n",
       "   'dog',\n",
       "   '.',\n",
       "   'all',\n",
       "   'right',\n",
       "   'this',\n",
       "   'sucks',\n",
       "   '!',\n",
       "   'i',\n",
       "   'already',\n",
       "   'got',\n",
       "   'her',\n",
       "   'this',\n",
       "   'briefcase',\n",
       "   ',',\n",
       "   'and',\n",
       "   'i',\n",
       "   'had',\n",
       "   '{entity_2}',\n",
       "   'put',\n",
       "   'on',\n",
       "   'it',\n",
       "   '…',\n",
       "   'her',\n",
       "   'initials',\n",
       "   '…',\n",
       "   '{speaker_2}',\n",
       "   ':',\n",
       "   'oh',\n",
       "   '##h',\n",
       "   '.',\n",
       "   '{speaker_3}',\n",
       "   ':',\n",
       "   'well',\n",
       "   ',',\n",
       "   'maybe',\n",
       "   'you',\n",
       "   'could',\n",
       "   'give',\n",
       "   'to',\n",
       "   'somebody',\n",
       "   'else',\n",
       "   '.',\n",
       "   'o',\n",
       "   '##oh',\n",
       "   ',',\n",
       "   'like',\n",
       "   'ross',\n",
       "   'gel',\n",
       "   '##ler',\n",
       "   '.',\n",
       "   '{speaker_1}',\n",
       "   ':',\n",
       "   'op',\n",
       "   ',',\n",
       "   'y',\n",
       "   \"'\",\n",
       "   'know',\n",
       "   'what',\n",
       "   'though',\n",
       "   ',',\n",
       "   'it',\n",
       "   '’',\n",
       "   's',\n",
       "   'kind',\n",
       "   '’',\n",
       "   've',\n",
       "   'a',\n",
       "   'girl',\n",
       "   '##ie',\n",
       "   'briefcase',\n",
       "   '.',\n",
       "   '{speaker_3}',\n",
       "   ':',\n",
       "   'who',\n",
       "   'cares',\n",
       "   '?',\n",
       "   'he',\n",
       "   'works',\n",
       "   'in',\n",
       "   'a',\n",
       "   'museum',\n",
       "   '!',\n",
       "   '[SEP]',\n",
       "   '{entity_1}',\n",
       "   '[SEP]',\n",
       "   '{entity_2}',\n",
       "   '[SEP]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]',\n",
       "   '[PAD]']],\n",
       " array([[  101,     1,  1024,  4931,  1010,  2011,  2151,  3382,  2106,\n",
       "          2593,  1997,  4060,  7910,    11,  2005,  2115,  3595,  4203,\n",
       "          1010,  1520,  3426,  1045, 10587,  3119,  2005,  2014,  1012,\n",
       "             2,  1024,  1045,  3856,  2014,   999,  2821,  4067,  2643,\n",
       "          2017,  2215,  2014,   999,  1051, 11631,   999,     1,  1024,\n",
       "         10166,   999,  2339,  2079,  2017,  2215,  2000,  2131,  9436,\n",
       "          1997,  2014,  2061,  6649,  1029,     2,  1024,  2138,  2016,\n",
       "         15800,  2296,  5592,  2016,  2412,  4152,  1010,  2009,  1521,\n",
       "          1055,  2066,  5263,  2000,  2131,  2014,  2242,  2016,  7777,\n",
       "          1012,  2272,  2006,  1010,  2292,  1521,  1055,  3119,   999,\n",
       "             1,  1024,  2821,  2008,  1521,  1055,  2025,  2995,   999,\n",
       "          2008,  1521,  1055,  2025,  2995,   999,  1045,  2288,  2014,\n",
       "          2008, 13383,  1998,  2016,  3866,  2009,   999,  1045,  3342,\n",
       "          2129,  2172,  2016,  2001,  6933,  1996,  2154,  2043,  2008,\n",
       "          2502,  3899,  2743,  2125,  2007,  2009,  1529,  2821,  1010,\n",
       "          2045,  2001,  2053,  2502,  3899,  1012,  2035,  2157,  2023,\n",
       "         19237,   999,  1045,  2525,  2288,  2014,  2023, 21793,  1010,\n",
       "          1998,  1045,  2018,    12,  2404,  2006,  2009,  1529,  2014,\n",
       "         20381,  1529,     2,  1024,  2821,  2232,  1012,     3,  1024,\n",
       "          2092,  1010,  2672,  2017,  2071,  2507,  2000,  8307,  2842,\n",
       "          1012,  1051, 11631,  1010,  2066,  5811, 21500,  3917,  1012,\n",
       "             1,  1024,  6728,  1010,  1061,  1005,  2113,  2054,  2295,\n",
       "          1010,  2009,  1521,  1055,  2785,  1521,  2310,  1037,  2611,\n",
       "          2666, 21793,  1012,     3,  1024,  2040, 14977,  1029,  2002,\n",
       "          2573,  1999,  1037,  2688,   999,   102,    11,   102,    12,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]]),\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]]),\n",
       " array([[ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  0, 11,  0,\n",
       "         12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,\n",
       "          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,\n",
       "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
       "          5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
       "          7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,\n",
       "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,  0, 12,  0,\n",
       "         13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]),\n",
       " array([[[ True, False, False, ..., False, False, False],\n",
       "         [False,  True,  True, ..., False, False, False],\n",
       "         [False,  True,  True, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ...,  True, False, False],\n",
       "         [False, False, False, ..., False,  True, False],\n",
       "         [False, False, False, ..., False, False,  True]]]),\n",
       " [Graph(num_nodes={'node': 14},\n",
       "        num_edges={('node', 'dialog', 'node'): 22, ('node', 'entity', 'node'): 8, ('node', 'speaker', 'node'): 20},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tucore_gcn_transformers.tucore_gcn_bert_pipeline import create_model_inputs\n",
    "create_model_inputs(\n",
    "\tspeaker_tokenizer.tokenize(dataset_dict['train'][0]['dialog']),\n",
    "\tspeaker_tokenizer.tokenize(dataset_dict['train'][0]['relation']['entity_1']),\n",
    "\tspeaker_tokenizer.tokenize(dataset_dict['train'][0]['relation']['entity_2']),\n",
    "\tspeaker_tokenizer,\n",
    "\tdataset_dict['train'][0], True, 36, 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
