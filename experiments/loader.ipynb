{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TUCOREGCN_BertForSequenceClassification(\n",
       "  (tucoregcn_bert): TUCOREGCN_Bert(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (speaker_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (turnAttention): MultiHeadAttention(\n",
       "      (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (GCN_layers): ModuleList(\n",
       "      (0-1): 2 x RelGraphConvLayer(\n",
       "        (activation): ReLU()\n",
       "        (conv): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (speaker): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (dialog): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (entity): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.6, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (LSTM_layers): ModuleList(\n",
       "      (0-1): 2 x TurnLevelLSTM(\n",
       "        (lstm): LSTM(768, 768, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "        (bilstm2hiddnesize): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=6912, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from models.BERT.tucoregcn_bert_pytorch import TUCOREGCN_BertForSequenceClassification, TUCOREGCN_BertConfig\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tucore_gcn_bert = TUCOREGCN_BertForSequenceClassification(TUCOREGCN_BertConfig.from_json_file(\"../models/BERT/tucoregcn_bert_mlc.json\"))\n",
    "tucore_gcn_bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TUCOREGCN_BertForSequenceClassification(\n",
       "  (tucoregcn_bert): TUCOREGCN_Bert(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (speaker_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (turnAttention): MultiHeadAttention(\n",
       "      (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=False)\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (GCN_layers): ModuleList(\n",
       "      (0-1): 2 x RelGraphConvLayer(\n",
       "        (activation): ReLU()\n",
       "        (conv): HeteroGraphConv(\n",
       "          (mods): ModuleDict(\n",
       "            (speaker): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (dialog): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "            (entity): GraphConv(in=768, out=768, normalization=right, activation=None)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.6, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (LSTM_layers): ModuleList(\n",
       "      (0-1): 2 x TurnLevelLSTM(\n",
       "        (lstm): LSTM(768, 768, num_layers=2, dropout=0.2, bidirectional=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "        (bilstm2hiddnesize): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=6912, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tucore_gcn_bert.load_state_dict(torch.load(\"../TUCOREGCN_BERT_DialogRE/tucoregcn_pytorch_model.pt\", map_location=\"cuda\"))\n",
    "tucore_gcn_bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../datasets/DialogRE/dev.json.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/DialogRE/dev.json/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TUCOREGCNDataset, TUCOREGCNDataloader\n\u001b[1;32m----> 2\u001b[0m dev_set \u001b[38;5;241m=\u001b[39m \u001b[43mTUCOREGCNDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/DialogRE/dev.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../datasets/DialogRE/dev_BERT.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBERT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dev_loader \u001b[38;5;241m=\u001b[39m TUCOREGCNDataloader(dataset\u001b[38;5;241m=\u001b[39mdev_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, relation_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m      4\u001b[0m idx, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(dev_loader))\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\data.py:608\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, src_file, save_file, max_seq_length, tokenizer, n_class, encoder_type)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ids[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(head)] \u001b[38;5;241m==\u001b[39m head:\n\u001b[0;32m    606\u001b[0m         entity_edges_infor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mention_id[i])\n\u001b[1;32m--> 608\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_ids) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(tail)):\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ids[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(tail)] \u001b[38;5;241m==\u001b[39m tail:\n\u001b[0;32m    610\u001b[0m         entity_edges_infor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mention_id[i])\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\data.py:112\u001b[0m, in \u001b[0;36mbertsProcessor.__init__\u001b[1;34m(self, src_file, n_class, for_f1c)\u001b[0m\n\u001b[0;32m    110\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc_file\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/dev.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/test.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    113\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sid \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m for_f1c:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/DialogRE/dev.json/train.json'"
     ]
    }
   ],
   "source": [
    "from data import TUCOREGCNDataset, TUCOREGCNDataloader\n",
    "dev_set = TUCOREGCNDataset(src_file=\"../datasets/DialogRE\", save_file=\"../datasets/DialogRE/dev_BERT.pkl\", max_seq_length=512, tokenizer=tokenizer, n_class=36, encoder_type='BERT')\n",
    "dev_loader = TUCOREGCNDataloader(dataset=dev_set, batch_size=2, shuffle=False, relation_num=36, max_length=512)\n",
    "idx, batch = next(enumerate(dev_loader))\n",
    "entry_idx = 0\n",
    "input_ids = batch[\"input_ids\"].to(\"cuda:0\")\n",
    "segment_ids = batch[\"segment_ids\"].to(\"cuda:0\")\n",
    "input_mask = batch[\"input_masks\"].to(\"cuda:0\")\n",
    "speaker_ids = batch[\"speaker_ids\"].to(\"cuda:0\")\n",
    "graphs = batch[\"graphs\"]\n",
    "mention_id = batch[\"mention_ids\"].to(\"cuda:0\")\n",
    "turn_mask = batch[\"turn_masks\"].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../datasets/DialogRE/dev.json.\n",
      "load preprocessed data from ../datasets/DialogRE/dev_BERT.pkl.\n",
      "{'input_ids': tensor([[ 101,    3, 1024,  ...,  102,    3,  102],\n",
      "        [ 101, 5882, 1015,  ...,  102, 4005,  102]], device='cuda:0'), 'token_type_ids': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'speaker_ids': tensor([[ 0, 12, 12,  ...,  0, 12,  0],\n",
      "        [ 0,  1,  1,  ...,  0,  0,  0]], device='cuda:0'), 'graphs': [Graph(num_nodes={'node': 23},\n",
      "      num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 24, ('node', 'speaker', 'node'): 114},\n",
      "      metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]), Graph(num_nodes={'node': 23},\n",
      "      num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 10, ('node', 'speaker', 'node'): 114},\n",
      "      metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')])], 'mention_ids': tensor([[ 0,  1,  1,  ...,  0, 22,  0],\n",
      "        [ 0,  1,  1,  ...,  0, 22,  0]], device='cuda:0'), 'turn_mask': tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 1]]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_output': tensor([[ 0.2171,  0.0617,  0.5196,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3829, -0.1901,  0.7677,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "        device='cuda:0', grad_fn=<StackBackward0>),\n",
       " 'graphs': [Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 24, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')]),\n",
       "  Graph(num_nodes={'node': 23},\n",
       "        num_edges={('node', 'dialog', 'node'): 40, ('node', 'entity', 'node'): 10, ('node', 'speaker', 'node'): 114},\n",
       "        metagraph=[('node', 'node', 'dialog'), ('node', 'node', 'entity'), ('node', 'node', 'speaker')])],\n",
       " 'sequence_outputs': tensor([[[ 0.7605, -0.3738, -0.0229,  ...,  0.6189, -0.8695, -1.0398],\n",
       "          [-0.0275,  0.0611,  0.7089,  ...,  1.0653, -0.9105, -1.2445],\n",
       "          [-0.3923, -1.0438,  0.3354,  ...,  0.7163, -1.0769, -1.2173],\n",
       "          ...,\n",
       "          [ 0.9691, -0.4780, -0.7932,  ...,  0.2546, -1.4696, -0.9530],\n",
       "          [ 0.1230, -0.1877,  1.1641,  ...,  1.4087, -1.3019,  0.4329],\n",
       "          [ 0.9829, -0.4103, -0.7405,  ...,  0.5810, -1.6483, -1.0805]],\n",
       " \n",
       "         [[-0.3435, -0.7502,  0.2840,  ...,  0.8162, -0.4711, -0.6724],\n",
       "          [-0.3765, -0.7730,  1.0154,  ...,  1.0790, -0.1834, -1.0129],\n",
       "          [-0.1795, -0.6872,  0.4648,  ...,  0.3295,  0.0695, -2.2957],\n",
       "          ...,\n",
       "          [ 1.1984, -1.4502, -0.6550,  ...,  1.0083, -0.8096, -0.5975],\n",
       "          [ 1.1865, -0.9476, -1.2909,  ...,  0.1884, -1.4526,  0.4428],\n",
       "          [ 1.0281, -0.6501, -0.4321,  ...,  0.8238, -1.5897, -0.6220]]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>),\n",
       " 'pooled_outputs': tensor([[ 0.2171,  0.0617,  0.5196,  ..., -0.7943,  0.1522, -0.5206],\n",
       "         [ 0.3829, -0.1901,  0.7677,  ..., -0.6700,  0.5264, -0.7113]],\n",
       "        device='cuda:0', grad_fn=<TanhBackward0>),\n",
       " 'attn': tensor([[[[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1116, 0.1144,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1081, 0.1134,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.1185,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1199, 0.1268,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1351, 0.1297,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1269, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.1295,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1242, 0.1285,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1372, 0.1261,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1290, 0.1266,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1210, 0.1148,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1268, 0.1199,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]]],\n",
       " \n",
       " \n",
       "         [[[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1123, 0.1095,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1114, 0.1055,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0993, 0.0970,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1016, 0.1027,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1000, 0.1109,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0990, 0.1075,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0938, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1027, 0.1064,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1079, 0.1264,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1097, 0.1151,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]],\n",
       " \n",
       "          [[1.1111, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1145, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.1206, 0.1126,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 1.1111, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.1111, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1111]]]],\n",
       "        device='cuda:0', grad_fn=<NativeDropoutBackward0>)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tucore_gcn_bert(\n",
    "\tinput_ids,\n",
    "\tsegment_ids,\n",
    "\tinput_mask,\n",
    "\tspeaker_ids,\n",
    "\tgraphs,\n",
    "\tmention_id,\n",
    "\tNone,\n",
    "\tturn_mask\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "from torch import Tensor\n",
    "\n",
    "class ConversationalTextClassification(Pipeline):\n",
    "    def _sanitize_parameters(self,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs, maybe_arg=2):\n",
    "        model_input = Tensor(inputs[\"input_ids\"])\n",
    "        return {\"model_input\": model_input}\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        # model_inputs == {\"model_input\": model_input}\n",
    "        outputs = self.model(**model_inputs)\n",
    "        # Maybe {\"logits\": Tensor(...)}\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        best_class = model_outputs[\"logits\"].softmax(-1)\n",
    "        return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'TUCOREGCN_BertForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  3185,  2003, 19424,  2135,  2204,   999,   102]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'speaker_ids': None, 'graphs': None, 'mention_ids': None, 'turn_mask': None}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mtucore_gcn_bert, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThis movie is disgustingly good !\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m     )\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\models\\BERT\\tucoregcn_bert_pytorch.py:1739\u001b[0m, in \u001b[0;36mTUCOREGCN_BertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, speaker_ids, graphs, mention_ids, labels, turn_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1729\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1736\u001b[0m     return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1737\u001b[0m )\n\u001b[1;32m-> 1739\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtucoregcn_bert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmention_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmention_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mturn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1747\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_ret:\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\models\\BERT\\tucoregcn_bert_pytorch.py:1570\u001b[0m, in \u001b[0;36mTUCOREGCN_Bert.forward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, speaker_ids, graphs, mention_ids, turn_mask)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28mprint\u001b[39m({\n\u001b[0;32m   1559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_ids,\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: token_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturn_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: turn_mask\n\u001b[0;32m   1566\u001b[0m })\n\u001b[0;32m   1567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;124;03mEncoder Module\u001b[39;00m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1576\u001b[0m sequence_outputs, pooled_outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1577\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state,\n\u001b[0;32m   1578\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mpooler_output,\n\u001b[0;32m   1579\u001b[0m )\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;124;03mTurn Attention Module\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\models\\BERT\\tucoregcn_bert_pytorch.py:1204\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, speaker_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1204\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeaker_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeaker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1212\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1213\u001b[0m     embedding_output,\n\u001b[0;32m   1214\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1223\u001b[0m )\n\u001b[0;32m   1224\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\models\\BERT\\tucoregcn_bert_pytorch.py:409\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, speaker_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    406\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m    407\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m--> 409\u001b[0m speaker_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m speaker_embeddings\n\u001b[0;32m    412\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\affect\\TUCORE-GCN\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n",
    "\n",
    "PIPELINE_REGISTRY.register_pipeline(\n",
    "    \"new-task\",\n",
    "    pipeline_class=MyPipeline,\n",
    "    pt_model=AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=tucore_gcn_bert, tokenizer=tokenizer, device=\"cuda:0\")\n",
    "\n",
    "classifier(\"This movie is disgustingly good !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tucoregcn_bert.bert.embeddings.word_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.position_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.token_type_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.speaker_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.LayerNorm.weight\n",
      "tucoregcn_bert.bert.embeddings.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.pooler.dense.weight\n",
      "tucoregcn_bert.bert.pooler.dense.bias\n",
      "tucoregcn_bert.turnAttention.w_qs.weight\n",
      "tucoregcn_bert.turnAttention.w_ks.weight\n",
      "tucoregcn_bert.turnAttention.w_vs.weight\n",
      "tucoregcn_bert.turnAttention.fc.weight\n",
      "tucoregcn_bert.turnAttention.layer_norm.weight\n",
      "tucoregcn_bert.turnAttention.layer_norm.bias\n",
      "tucoregcn_bert.GCN_layers.0.weight\n",
      "tucoregcn_bert.GCN_layers.0.h_bias\n",
      "tucoregcn_bert.GCN_layers.0.loop_weight\n",
      "tucoregcn_bert.GCN_layers.1.weight\n",
      "tucoregcn_bert.GCN_layers.1.h_bias\n",
      "tucoregcn_bert.GCN_layers.1.loop_weight\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.weight\n",
      "tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.bias\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.weight\n",
      "tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(list(tucore_gcn_bert.state_dict().keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "sequence_outputs = output[\"sequence_outputs\"]\n",
    "pooled_outputs = output[\"pooled_outputs\"]\n",
    "mention_ids = batch[\"mention_ids\"].to(\"cuda:0\")\n",
    "graphs = batch[\"graphs\"]\n",
    "#initialize some variables\n",
    "features = None\n",
    "num_batch_turn = []\n",
    "slen = input_ids.size(1)\n",
    "# Iterate over all inputs to be processed\n",
    "for i in range(len(graphs)):\n",
    "\tsequence_output = sequence_outputs[i]\n",
    "\tmention_id = mention_ids[i]\n",
    "\tpooled_output = pooled_outputs[i]\n",
    "\t# Find the last turn (in the case of tucoregcn, it is the masked speaker dictionary)\n",
    "\tmention_num = torch.max(mention_id)\n",
    "\t# Create a mention matrix idx of mention_num*slen\n",
    "\tnum_batch_turn.append(mention_num + 1)\n",
    "\tmention_index = (\n",
    "\t\t(torch.arange(mention_num) + 1).unsqueeze(1).expand(-1, slen)\n",
    "\t)\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tmention_index = mention_index.cuda()\n",
    "\t# Create a mentions matrix of slen*mention_num\n",
    "\tmentions = mention_id.unsqueeze(0).expand(mention_num, -1)\n",
    "\t# Generate truth matrix of each speaker's dialogue over the entire conversation\n",
    "\tselect_metrix = (mention_index == mentions).float()\n",
    "\t# Factor into the one-hot encoding, the total number of words in each speaker's dialogue\n",
    "\tword_total_numbers = (\n",
    "\t\ttorch.sum(select_metrix, dim=-1).unsqueeze(-1).expand(-1, slen)\n",
    "\t)\n",
    "\tselect_metrix = torch.where(\n",
    "\t\tword_total_numbers > 0,\n",
    "\t\tselect_metrix / word_total_numbers,\n",
    "\t\tselect_metrix,\n",
    "\t)\n",
    "\t# Apply one hot encoding to sequence_output to selectively obtain features\n",
    "\tx = torch.mm(select_metrix, sequence_output)\n",
    "\tx = torch.cat((pooled_output.unsqueeze(0), x), dim=0)\n",
    "\t# Iteratively concatenate features from all sequence_outputs\n",
    "\tif features is None:\n",
    "\t\tfeatures = x\n",
    "\telse:\n",
    "\t\tfeatures = torch.cat((features, x), dim=0)\n",
    "# Batch dgl graphs into 1 graph for efficient computation\n",
    "graph_big = dgl.batch(graphs)\n",
    "output_features = [features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(23, device='cuda:0'), tensor(23, device='cuda:0')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batch_turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tucore_gcn_bert.tucoregcn_bert.LSTM_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0296, -0.1093, -0.0949,  ...,  0.0403, -0.0775,  0.0609],\n",
       "        [ 0.0269, -0.1400, -0.0430,  ...,  0.0400, -0.0286,  0.0603],\n",
       "        [ 0.0338, -0.0955, -0.0860,  ...,  0.0678, -0.0762,  0.0849],\n",
       "        ...,\n",
       "        [ 0.0447, -0.0806, -0.0882,  ...,  0.0112, -0.0611,  0.0586],\n",
       "        [-0.0022, -0.0971, -0.0838,  ...,  0.0282, -0.0546,  0.0250],\n",
       "        [ 0.0282, -0.0570, -0.0888,  ...,  0.0342, -0.0482,  0.0617]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = []\n",
    "new_features.append(features[0])\n",
    "lstm_out = lstm(features[0 + 1 : 0 + idx - 2].unsqueeze(0))\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 4.5792e-01, -1.1729e-02,  3.2297e-01,  ..., -3.7483e-01,\n",
       "           4.0892e-01, -7.1791e-01],\n",
       "         [-4.3282e-01, -1.8977e-01,  7.0841e-01,  ...,  7.7599e-01,\n",
       "          -5.2889e-01, -1.2678e+00],\n",
       "         [-1.0421e+00, -5.9411e-01,  1.3200e+00,  ...,  2.7433e-01,\n",
       "          -4.1637e-01, -1.2198e+00],\n",
       "         ...,\n",
       "         [ 2.4836e-01, -7.2986e-01,  1.8437e-01,  ...,  6.4670e-01,\n",
       "          -1.1878e+00, -2.2512e-01],\n",
       "         [ 1.4898e-01, -6.1494e-01, -5.7474e-01,  ...,  1.6153e+00,\n",
       "          -2.0723e+00, -3.3880e-01],\n",
       "         [ 1.2348e+00, -4.7497e-01, -5.3483e-01,  ..., -1.4764e-03,\n",
       "          -1.1713e+00, -2.1761e-01]], device='cuda:0', grad_fn=<CatBackward0>)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'list' is an illegal expression for augmented assignment (2151216791.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[97], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [4,7,8]+=[2]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'list' is an illegal expression for augmented assignment\n"
     ]
    }
   ],
   "source": [
    "[4,7,8]+=[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "sequence_output = output[\"sequence_outputs\"][0]\n",
    "pooled_output = output[\"pooled_outputs\"][0]\n",
    "mention_id = batch[\"mention_ids\"].to(\"cuda:0\")[0]\n",
    "\n",
    "#initialize some variables\n",
    "slen = input_ids.size(1)\n",
    "# Find the last turn (in the case of tucoregcn, it is the masked speaker dictionary)\n",
    "mention_num = torch.max(mention_id)\n",
    "# Create a mention matrix idx of mention_num*slen\n",
    "num_batch_turn = mention_num + 1\n",
    "mention_index = (\n",
    "\t(torch.arange(mention_num) + 1).unsqueeze(1).expand(-1, slen)\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "\tmention_index = mention_index.cuda()\n",
    "# Create a mentions matrix of slen*mention_num\n",
    "mentions = mention_id.unsqueeze(0).expand(mention_num, -1)\n",
    "# Generate 1 hot encoding of each speaker's dialogue\n",
    "select_metrix = (mention_index == mentions).float()\n",
    "# Factor into the one-hot encoding, the total number of words in each speaker's dialogue\n",
    "word_total_numbers = (\n",
    "\ttorch.sum(select_metrix, dim=-1).unsqueeze(-1).expand(-1, slen)\n",
    ")\n",
    "select_metrix = torch.where(\n",
    "\tword_total_numbers > 0,\n",
    "\tselect_metrix / word_total_numbers,\n",
    "\tselect_metrix,\n",
    ")\n",
    "# Apply one hot encoding to sequence_output to selectively obtain features\n",
    "features = torch.mm(select_metrix, sequence_output)\n",
    "features = torch.cat((pooled_output.unsqueeze(0), features), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val, ind = torch.max(torch.LongTensor([[1,2,3],[1,2,4]]),dim=1)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6, 6, 6, 6, 6, 6, 6],\n",
       "        [7, 7, 7, 7, 7, 7, 7, 7],\n",
       "        [8, 8, 8, 8, 8, 8, 8, 8]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2500, 0.2500,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(5) + 1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.LongTensor([6,7,8])\n",
    "result = torch.arange(0, torch.max(temp)+1).expand(len(temp), -1)\n",
    "result#>temp.expand(torch.max(temp)+1,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8]],\n",
       "\n",
       "        [[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8]],\n",
       "\n",
       "        [[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result>torch.LongTensor([6,7,8]).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1,  ...,  1,  1,  1],\n",
       "        [ 2,  2,  2,  ...,  2,  2,  2],\n",
       "        [ 3,  3,  3,  ...,  3,  3,  3],\n",
       "        ...,\n",
       "        [20, 20, 20,  ..., 20, 20, 20],\n",
       "        [21, 21, 21,  ..., 21, 21, 21],\n",
       "        [22, 22, 22,  ..., 22, 22, 22]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"mention_ids\"].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "arange() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (Number end, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, *, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, Number step, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m mention_nums, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(mention_ids,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m num_batch_turns \u001b[38;5;241m=\u001b[39m mention_nums \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m mention_index \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 12\u001b[0m \t(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmention_nums\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, slen)\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m mention_index\n",
      "\u001b[1;31mTypeError\u001b[0m: arange() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:\n * (Number end, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, *, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, Number step, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "sequence_outputs = output[\"sequence_outputs\"]\n",
    "pooled_outputs = output[\"pooled_outputs\"]\n",
    "graphs = batch[\"graphs\"]\n",
    "mention_ids = batch[\"mention_ids\"].to(\"cuda:0\")\n",
    "mention_ids\n",
    "#initialize some variables\n",
    "slen = input_ids.size(1)\n",
    "# Find the last turn (in the case of tucoregcn, it is the masked speaker dictionary)\n",
    "mention_nums, _ = torch.max(mention_ids,dim=1)\n",
    "num_batch_turns = mention_nums + 1\n",
    "'''\n",
    "mention_index = (\n",
    "\t(torch.arange(mention_nums,dim=1) + 1).unsqueeze(1).expand(-1, slen)\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "\tmention_index = mention_index.cuda()'''\n",
    "mentions = mention_ids.unsqueeze(1).expand(-1, mention_num, -1)\n",
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        ...,\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_id.unsqueeze(0).expand(mention_num, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        ...,\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0],\n",
       "        [ 0,  1,  1,  ...,  0, 22,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_ids.unsqueeze(1).expand(-1, mention_num, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  4.,  4.,  ...,  4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.,  ...,  5.,  5.,  5.],\n",
       "        [12., 12., 12.,  ..., 12., 12., 12.],\n",
       "        ...,\n",
       "        [75., 75., 75.,  ..., 75., 75., 75.],\n",
       "        [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((mention_index==mentions).float(), dim=-1).unsqueeze(-1).expand(-1, slen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.2000, 0.2000, 0.2000,\n",
       "        0.2000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_metrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mention_index==mentions).float()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2500, 0.2500,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 512])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(mention_num) + 1).unsqueeze(1).expand(-1, slen).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'hey',\n",
       " '!',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'hey',\n",
       " '.',\n",
       " 'speaker',\n",
       " '3',\n",
       " ':',\n",
       " 'hey',\n",
       " ',',\n",
       " 'man',\n",
       " '.',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'up',\n",
       " '?',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'maybe',\n",
       " 'you',\n",
       " 'can',\n",
       " 'tell',\n",
       " 'me',\n",
       " '.',\n",
       " 'my',\n",
       " 'agent',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'why',\n",
       " 'i',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'show',\n",
       " 'up',\n",
       " 'at',\n",
       " 'the',\n",
       " 'audition',\n",
       " 'i',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'i',\n",
       " 'had',\n",
       " 'today',\n",
       " '.',\n",
       " 'the',\n",
       " 'first',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'she',\n",
       " 'gets',\n",
       " 'me',\n",
       " 'in',\n",
       " 'weeks',\n",
       " '.',\n",
       " 'how',\n",
       " 'could',\n",
       " 'you',\n",
       " 'not',\n",
       " 'give',\n",
       " 'me',\n",
       " 'the',\n",
       " 'message',\n",
       " '?',\n",
       " '!',\n",
       " 'speaker',\n",
       " '3',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'tell',\n",
       " 'ya',\n",
       " 'i',\n",
       " 'do',\n",
       " 'enjoy',\n",
       " 'guilt',\n",
       " ',',\n",
       " 'but',\n",
       " ',',\n",
       " 'ah',\n",
       " ',',\n",
       " 'it',\n",
       " 'wasn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'me',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'yes',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " '!',\n",
       " 'it',\n",
       " 'was',\n",
       " 'him',\n",
       " '!',\n",
       " 'uh',\n",
       " 'huh',\n",
       " '!',\n",
       " 'okay',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'me',\n",
       " '!',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'how',\n",
       " 'is',\n",
       " 'it',\n",
       " 'you',\n",
       " '?',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'all',\n",
       " 'so',\n",
       " 'crazy',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " '.',\n",
       " 'i',\n",
       " 'mean',\n",
       " ',',\n",
       " 'chandler',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'closet',\n",
       " ',',\n",
       " 'counting',\n",
       " 'to',\n",
       " '10',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'up',\n",
       " 'to',\n",
       " '7',\n",
       " 'and',\n",
       " 'i',\n",
       " 'hadn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'found',\n",
       " 'a',\n",
       " 'place',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'yet',\n",
       " '.',\n",
       " 'i',\n",
       " '-',\n",
       " 'i',\n",
       " '-',\n",
       " 'i',\n",
       " 'meant',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " ',',\n",
       " 'and',\n",
       " 'i',\n",
       " 'wrote',\n",
       " 'it',\n",
       " 'all',\n",
       " 'down',\n",
       " 'on',\n",
       " 'my',\n",
       " 'hand',\n",
       " '.',\n",
       " 'see',\n",
       " ',',\n",
       " 'all',\n",
       " 'of',\n",
       " 'it',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'yep',\n",
       " ',',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'my',\n",
       " 'audition',\n",
       " '.',\n",
       " 'speaker',\n",
       " '4',\n",
       " ':',\n",
       " 'see',\n",
       " ',',\n",
       " 'now',\n",
       " 'this',\n",
       " 'is',\n",
       " 'why',\n",
       " 'i',\n",
       " 'keep',\n",
       " 'note',\n",
       " '##pad',\n",
       " '##s',\n",
       " 'everywhere',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'yep',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " \"'\",\n",
       " 's',\n",
       " 'why',\n",
       " 'we',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'invite',\n",
       " 'you',\n",
       " 'to',\n",
       " 'play',\n",
       " '.',\n",
       " 'speaker',\n",
       " '5',\n",
       " ':',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'great',\n",
       " 'tragedy',\n",
       " 'here',\n",
       " '?',\n",
       " 'you',\n",
       " 'go',\n",
       " 'get',\n",
       " 'yourself',\n",
       " 'another',\n",
       " 'appointment',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'well',\n",
       " ',',\n",
       " 'este',\n",
       " '##lle',\n",
       " 'tried',\n",
       " ',',\n",
       " 'you',\n",
       " 'know',\n",
       " '.',\n",
       " 'the',\n",
       " 'casting',\n",
       " 'director',\n",
       " 'told',\n",
       " 'her',\n",
       " 'that',\n",
       " 'i',\n",
       " 'missed',\n",
       " 'my',\n",
       " 'chance',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'that',\n",
       " 'is',\n",
       " 'unfair',\n",
       " '.',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'call',\n",
       " 'her',\n",
       " 'and',\n",
       " 'tell',\n",
       " 'her',\n",
       " 'it',\n",
       " 'was',\n",
       " 'totally',\n",
       " 'my',\n",
       " 'fault',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'ph',\n",
       " '##ee',\n",
       " '##bs',\n",
       " ',',\n",
       " 'you',\n",
       " 'can',\n",
       " \"'\",\n",
       " 't',\n",
       " 'do',\n",
       " 'that',\n",
       " '.',\n",
       " 'the',\n",
       " 'casting',\n",
       " 'director',\n",
       " 'doesn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'friends',\n",
       " ',',\n",
       " 'she',\n",
       " 'only',\n",
       " 'talks',\n",
       " 'to',\n",
       " 'agents',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'what',\n",
       " 'a',\n",
       " 'sad',\n",
       " 'little',\n",
       " 'life',\n",
       " 'she',\n",
       " 'must',\n",
       " 'lead',\n",
       " '.',\n",
       " 'okay',\n",
       " ',',\n",
       " 'o',\n",
       " '##oh',\n",
       " '.',\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'what',\n",
       " ',',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " 'no',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'i',\n",
       " 'know',\n",
       " ',',\n",
       " 'i',\n",
       " 'know',\n",
       " ',',\n",
       " 'o',\n",
       " '##oh',\n",
       " '.',\n",
       " \"'\",\n",
       " 'hi',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'kate',\n",
       " '##lynn',\n",
       " ',',\n",
       " 'from',\n",
       " 'phoebe',\n",
       " 'buff',\n",
       " '##ay',\n",
       " \"'\",\n",
       " 's',\n",
       " 'office',\n",
       " '.',\n",
       " 'um',\n",
       " ',',\n",
       " 'is',\n",
       " 'um',\n",
       " ',',\n",
       " 'ann',\n",
       " 'there',\n",
       " 'for',\n",
       " 'phoebe',\n",
       " ',',\n",
       " 'she',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'know',\n",
       " 'what',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'about',\n",
       " '.',\n",
       " \"'\",\n",
       " 'speaker',\n",
       " '1',\n",
       " ':',\n",
       " 'hang',\n",
       " 'up',\n",
       " ',',\n",
       " 'hang',\n",
       " 'up',\n",
       " '.',\n",
       " 'speaker',\n",
       " '2',\n",
       " ':',\n",
       " \"'\",\n",
       " 'annie',\n",
       " '!',\n",
       " 'hi',\n",
       " '.',\n",
       " 'listen',\n",
       " 'we',\n",
       " 'got',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'joey',\n",
       " 'tri',\n",
       " '##bb',\n",
       " '##iani',\n",
       " ',',\n",
       " 'apparently',\n",
       " 'he',\n",
       " 'missed',\n",
       " 'his',\n",
       " 'audition',\n",
       " '.',\n",
       " 'who',\n",
       " 'did',\n",
       " 'you',\n",
       " 'speak',\n",
       " 'to',\n",
       " 'in',\n",
       " 'my',\n",
       " 'office',\n",
       " '?',\n",
       " 'este',\n",
       " '##lle',\n",
       " ',',\n",
       " 'no',\n",
       " ',',\n",
       " 'i',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'know',\n",
       " 'what',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'her',\n",
       " '.',\n",
       " 'no',\n",
       " '.',\n",
       " 'all',\n",
       " 'right',\n",
       " ',',\n",
       " 'so',\n",
       " 'your',\n",
       " 'husband',\n",
       " 'leaves',\n",
       " 'and',\n",
       " 'burns',\n",
       " 'down',\n",
       " 'the',\n",
       " '[SEP]',\n",
       " 'este',\n",
       " '##lle',\n",
       " '[SEP]',\n",
       " 'agent',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(input_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] speaker 1 : hey! speaker 2 : hey. speaker 3 : hey, man. what ' s up? speaker 1 : maybe you can tell me. my agent would like to know why i didn ' t show up at the audition i didn ' t know i had today. the first good thing she gets me in weeks. how could you not give me the message?! speaker 3 : well, i ' ll tell ya i do enjoy guilt, but, ah, it wasn ' t me. speaker 2 : yes, it was! it was him! uh huh! okay, it was me! speaker 1 : how is it you? speaker 2 : well, it was just, it was all so crazy, you know. i mean, chandler was in the closet, counting to 10, and he was up to 7 and i hadn ' t found a place to hide yet. i - i - i meant to tell you, and i wrote it all down on my hand. see, all of it. speaker 1 : yep, that ' s my audition. speaker 4 : see, now this is why i keep notepads everywhere. speaker 2 : yep, and that ' s why we don ' t invite you to play. speaker 5 : what is the great tragedy here? you go get yourself another appointment. speaker 1 : well, estelle tried, you know. the casting director told her that i missed my chance. speaker 2 : that is unfair. i ' ll call her and tell her it was totally my fault. speaker 1 : pheebs, you can ' t do that. the casting director doesn ' t talk to friends, she only talks to agents. speaker 2 : what a sad little life she must lead. okay, ooh. speaker 1 : what, what are you doing? what are you doing? speaker 2 : no, no, no, i know, i know, ooh. ' hi, this is katelynn, from phoebe buffay ' s office. um, is um, ann there for phoebe, she ' ll know what it ' s about. ' speaker 1 : hang up, hang up. speaker 2 : ' annie! hi. listen we got a problem with joey tribbiani, apparently he missed his audition. who did you speak to in my office? estelle, no, i don ' t know what i ' m going to do with her. no. all right, so your husband leaves and burns down the [SEP] estelle [SEP] agent [SEP]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 1,  ..., 0, 0, 0],\n",
       "        [0, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
       "         7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20,  0, 21, 21,  0, 22,  0], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"../TUCOREGCN_BERT_DialogRE/tucoregcn_pytorch_model.pt\", map_location=\"cuda\")\n",
    "for key in list(state_dict.keys()):\n",
    "    state_dict[key.replace(\"tucoregcn_bert.turnAttention.fc.weight\", \"tucoregcn_bert.turnAttention.out_lin.weight\")] = state_dict.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tucoregcn_bert.bert.embeddings.word_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.position_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.token_type_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.speaker_embeddings.weight\n",
      "tucoregcn_bert.bert.embeddings.LayerNorm.weight\n",
      "tucoregcn_bert.bert.embeddings.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.query.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.query.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.key.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.key.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.value.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.self.value.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.intermediate.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.dense.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.dense.bias\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "tucoregcn_bert.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "tucoregcn_bert.bert.pooler.dense.weight\n",
      "tucoregcn_bert.bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n",
      "tucoregcn_bert.turnAttention.w_qs.weight\n",
      "tucoregcn_bert.turnAttention.w_ks.weight\n",
      "tucoregcn_bert.turnAttention.w_vs.weight\n",
      "tucoregcn_bert.turnAttention.out_lin.weight\n",
      "tucoregcn_bert.turnAttention.layer_norm.weight\n",
      "tucoregcn_bert.turnAttention.layer_norm.bias\n",
      "tucoregcn_bert.GCN_layers.0.weight\n",
      "tucoregcn_bert.GCN_layers.0.h_bias\n",
      "tucoregcn_bert.GCN_layers.0.loop_weight\n",
      "tucoregcn_bert.GCN_layers.1.weight\n",
      "tucoregcn_bert.GCN_layers.1.h_bias\n",
      "tucoregcn_bert.GCN_layers.1.loop_weight\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.weight_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.lstm.bias_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.weight\n",
      "tucoregcn_bert.LSTM_layers.0.bilstm2hiddnesize.bias\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l0_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.weight_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_ih_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.lstm.bias_hh_l1_reverse\n",
      "tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.weight\n",
      "tucoregcn_bert.LSTM_layers.1.bilstm2hiddnesize.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(list(state_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict, \"../TUCOREGCN_BERT_DialogRE/tucoregcn_pytorch_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
