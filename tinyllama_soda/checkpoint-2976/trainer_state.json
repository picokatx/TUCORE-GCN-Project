{
  "best_metric": 0.9002012014389038,
  "best_model_checkpoint": "tinyllama_soda\\checkpoint-2976",
  "epoch": 0.39959718026183283,
  "eval_steps": 744,
  "global_step": 2976,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 7.522111415863037,
      "learning_rate": 1e-05,
      "loss": 4.0348,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.806849479675293,
      "learning_rate": 1e-05,
      "loss": 4.3281,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.738473892211914,
      "learning_rate": 1e-05,
      "loss": 3.6978,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.8731608390808105,
      "learning_rate": 1e-05,
      "loss": 3.274,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.493792533874512,
      "learning_rate": 1e-05,
      "loss": 3.7412,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.47231674194336,
      "learning_rate": 1e-05,
      "loss": 3.7613,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.837925910949707,
      "learning_rate": 1e-05,
      "loss": 3.9696,
      "step": 28
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.213177680969238,
      "learning_rate": 1e-05,
      "loss": 3.2288,
      "step": 32
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.926395416259766,
      "learning_rate": 1e-05,
      "loss": 3.3022,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.443218231201172,
      "learning_rate": 1e-05,
      "loss": 3.2314,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.678180694580078,
      "learning_rate": 1e-05,
      "loss": 3.7132,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.755683898925781,
      "learning_rate": 1e-05,
      "loss": 2.7869,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.090785026550293,
      "learning_rate": 1e-05,
      "loss": 2.8362,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.890439987182617,
      "learning_rate": 1e-05,
      "loss": 2.8793,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.606904029846191,
      "learning_rate": 1e-05,
      "loss": 2.4806,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.933317184448242,
      "learning_rate": 1e-05,
      "loss": 2.5504,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.958732604980469,
      "learning_rate": 1e-05,
      "loss": 2.4339,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 15.506087303161621,
      "learning_rate": 1e-05,
      "loss": 2.5375,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.203010559082031,
      "learning_rate": 1e-05,
      "loss": 2.3494,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 10.89745807647705,
      "learning_rate": 1e-05,
      "loss": 2.3346,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.983019828796387,
      "learning_rate": 1e-05,
      "loss": 2.2463,
      "step": 84
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.561113357543945,
      "learning_rate": 1e-05,
      "loss": 2.1934,
      "step": 88
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.240488052368164,
      "learning_rate": 1e-05,
      "loss": 1.9851,
      "step": 92
    },
    {
      "epoch": 0.01,
      "grad_norm": 9.705252647399902,
      "learning_rate": 1e-05,
      "loss": 1.8688,
      "step": 96
    },
    {
      "epoch": 0.01,
      "grad_norm": 11.499401092529297,
      "learning_rate": 1e-05,
      "loss": 1.6718,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 13.135469436645508,
      "learning_rate": 1e-05,
      "loss": 1.9732,
      "step": 104
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.558104515075684,
      "learning_rate": 1e-05,
      "loss": 2.0221,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.230857849121094,
      "learning_rate": 1e-05,
      "loss": 1.8707,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.715306282043457,
      "learning_rate": 1e-05,
      "loss": 2.0534,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.176383972167969,
      "learning_rate": 1e-05,
      "loss": 1.6522,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.454811096191406,
      "learning_rate": 1e-05,
      "loss": 1.9933,
      "step": 124
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.887982368469238,
      "learning_rate": 1e-05,
      "loss": 1.6124,
      "step": 128
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.272896766662598,
      "learning_rate": 1e-05,
      "loss": 1.8016,
      "step": 132
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.477303504943848,
      "learning_rate": 1e-05,
      "loss": 1.713,
      "step": 136
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.554425239562988,
      "learning_rate": 1e-05,
      "loss": 1.732,
      "step": 140
    },
    {
      "epoch": 0.02,
      "grad_norm": 12.389101028442383,
      "learning_rate": 1e-05,
      "loss": 1.7595,
      "step": 144
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.033088684082031,
      "learning_rate": 1e-05,
      "loss": 1.8612,
      "step": 148
    },
    {
      "epoch": 0.02,
      "grad_norm": 11.54805850982666,
      "learning_rate": 1e-05,
      "loss": 1.7353,
      "step": 152
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.440729141235352,
      "learning_rate": 1e-05,
      "loss": 1.7933,
      "step": 156
    },
    {
      "epoch": 0.02,
      "grad_norm": 7.611379623413086,
      "learning_rate": 1e-05,
      "loss": 1.6067,
      "step": 160
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.493854522705078,
      "learning_rate": 1e-05,
      "loss": 1.9149,
      "step": 164
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.9624662399292,
      "learning_rate": 1e-05,
      "loss": 1.92,
      "step": 168
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.704304695129395,
      "learning_rate": 1e-05,
      "loss": 1.7601,
      "step": 172
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.800848960876465,
      "learning_rate": 1e-05,
      "loss": 1.8981,
      "step": 176
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.52968692779541,
      "learning_rate": 1e-05,
      "loss": 1.7069,
      "step": 180
    },
    {
      "epoch": 0.02,
      "grad_norm": 10.650940895080566,
      "learning_rate": 1e-05,
      "loss": 1.8324,
      "step": 184
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.87471866607666,
      "learning_rate": 1e-05,
      "loss": 1.6738,
      "step": 188
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.741256713867188,
      "learning_rate": 1e-05,
      "loss": 1.6489,
      "step": 192
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.218297004699707,
      "learning_rate": 1e-05,
      "loss": 1.5823,
      "step": 196
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.882713317871094,
      "learning_rate": 1e-05,
      "loss": 1.8756,
      "step": 200
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.7398099899292,
      "learning_rate": 1e-05,
      "loss": 1.5979,
      "step": 204
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.639904022216797,
      "learning_rate": 1e-05,
      "loss": 1.8076,
      "step": 208
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.317473411560059,
      "learning_rate": 1e-05,
      "loss": 1.6251,
      "step": 212
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.751389503479004,
      "learning_rate": 1e-05,
      "loss": 1.7782,
      "step": 216
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.267524719238281,
      "learning_rate": 1e-05,
      "loss": 1.6283,
      "step": 220
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.399371147155762,
      "learning_rate": 1e-05,
      "loss": 1.6783,
      "step": 224
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.259839057922363,
      "learning_rate": 1e-05,
      "loss": 1.8014,
      "step": 228
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.767462730407715,
      "learning_rate": 1e-05,
      "loss": 1.6216,
      "step": 232
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.680685997009277,
      "learning_rate": 1e-05,
      "loss": 1.81,
      "step": 236
    },
    {
      "epoch": 0.03,
      "grad_norm": 9.32553482055664,
      "learning_rate": 1e-05,
      "loss": 1.7058,
      "step": 240
    },
    {
      "epoch": 0.03,
      "grad_norm": 11.279414176940918,
      "learning_rate": 1e-05,
      "loss": 1.6433,
      "step": 244
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.925535202026367,
      "learning_rate": 1e-05,
      "loss": 1.4981,
      "step": 248
    },
    {
      "epoch": 0.03,
      "grad_norm": 12.74463939666748,
      "learning_rate": 1e-05,
      "loss": 1.639,
      "step": 252
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.934518814086914,
      "learning_rate": 1e-05,
      "loss": 1.5136,
      "step": 256
    },
    {
      "epoch": 0.03,
      "grad_norm": 10.062673568725586,
      "learning_rate": 1e-05,
      "loss": 1.7758,
      "step": 260
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.485481262207031,
      "learning_rate": 1e-05,
      "loss": 1.5838,
      "step": 264
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.638239860534668,
      "learning_rate": 1e-05,
      "loss": 1.828,
      "step": 268
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.778985023498535,
      "learning_rate": 1e-05,
      "loss": 1.5762,
      "step": 272
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.685330390930176,
      "learning_rate": 1e-05,
      "loss": 1.6349,
      "step": 276
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.813883781433105,
      "learning_rate": 1e-05,
      "loss": 1.6986,
      "step": 280
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.847978591918945,
      "learning_rate": 1e-05,
      "loss": 1.5946,
      "step": 284
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.751869201660156,
      "learning_rate": 1e-05,
      "loss": 1.5693,
      "step": 288
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.945816040039062,
      "learning_rate": 1e-05,
      "loss": 1.5864,
      "step": 292
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.288829803466797,
      "learning_rate": 1e-05,
      "loss": 1.5399,
      "step": 296
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.493386268615723,
      "learning_rate": 1e-05,
      "loss": 1.5948,
      "step": 300
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.620487213134766,
      "learning_rate": 1e-05,
      "loss": 1.563,
      "step": 304
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.77497673034668,
      "learning_rate": 1e-05,
      "loss": 1.4626,
      "step": 308
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.817082405090332,
      "learning_rate": 1e-05,
      "loss": 1.4536,
      "step": 312
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.101061820983887,
      "learning_rate": 1e-05,
      "loss": 1.6963,
      "step": 316
    },
    {
      "epoch": 0.04,
      "grad_norm": 12.273324012756348,
      "learning_rate": 1e-05,
      "loss": 1.7298,
      "step": 320
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.1192045211792,
      "learning_rate": 1e-05,
      "loss": 1.5927,
      "step": 324
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.366705894470215,
      "learning_rate": 1e-05,
      "loss": 1.4125,
      "step": 328
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.606515884399414,
      "learning_rate": 1e-05,
      "loss": 1.4428,
      "step": 332
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.122788429260254,
      "learning_rate": 1e-05,
      "loss": 1.5379,
      "step": 336
    },
    {
      "epoch": 0.05,
      "grad_norm": 15.211901664733887,
      "learning_rate": 1e-05,
      "loss": 1.655,
      "step": 340
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.13352108001709,
      "learning_rate": 1e-05,
      "loss": 1.6081,
      "step": 344
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.527039527893066,
      "learning_rate": 1e-05,
      "loss": 1.5088,
      "step": 348
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.925857543945312,
      "learning_rate": 1e-05,
      "loss": 1.5779,
      "step": 352
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.86357593536377,
      "learning_rate": 1e-05,
      "loss": 1.452,
      "step": 356
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.003329277038574,
      "learning_rate": 1e-05,
      "loss": 1.5119,
      "step": 360
    },
    {
      "epoch": 0.05,
      "grad_norm": 11.575711250305176,
      "learning_rate": 1e-05,
      "loss": 1.3209,
      "step": 364
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.119036674499512,
      "learning_rate": 1e-05,
      "loss": 1.5184,
      "step": 368
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.928287506103516,
      "learning_rate": 1e-05,
      "loss": 1.4219,
      "step": 372
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.14150619506836,
      "learning_rate": 1e-05,
      "loss": 1.5483,
      "step": 376
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.952404022216797,
      "learning_rate": 1e-05,
      "loss": 1.5437,
      "step": 380
    },
    {
      "epoch": 0.05,
      "grad_norm": 15.207257270812988,
      "learning_rate": 1e-05,
      "loss": 1.4647,
      "step": 384
    },
    {
      "epoch": 0.05,
      "grad_norm": 10.558192253112793,
      "learning_rate": 1e-05,
      "loss": 1.4879,
      "step": 388
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.51554012298584,
      "learning_rate": 1e-05,
      "loss": 1.4922,
      "step": 392
    },
    {
      "epoch": 0.05,
      "grad_norm": 14.34325885772705,
      "learning_rate": 1e-05,
      "loss": 1.5048,
      "step": 396
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.761780738830566,
      "learning_rate": 1e-05,
      "loss": 1.34,
      "step": 400
    },
    {
      "epoch": 0.05,
      "grad_norm": 12.22365951538086,
      "learning_rate": 1e-05,
      "loss": 1.3062,
      "step": 404
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.031410217285156,
      "learning_rate": 1e-05,
      "loss": 1.51,
      "step": 408
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.710559844970703,
      "learning_rate": 1e-05,
      "loss": 1.4386,
      "step": 412
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.35162353515625,
      "learning_rate": 1e-05,
      "loss": 1.2476,
      "step": 416
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.95244312286377,
      "learning_rate": 1e-05,
      "loss": 1.2574,
      "step": 420
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.019413948059082,
      "learning_rate": 1e-05,
      "loss": 1.3699,
      "step": 424
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.965314865112305,
      "learning_rate": 1e-05,
      "loss": 1.3589,
      "step": 428
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.933449745178223,
      "learning_rate": 1e-05,
      "loss": 1.2835,
      "step": 432
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.869382858276367,
      "learning_rate": 1e-05,
      "loss": 1.4914,
      "step": 436
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.200284004211426,
      "learning_rate": 1e-05,
      "loss": 1.3488,
      "step": 440
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.892135620117188,
      "learning_rate": 1e-05,
      "loss": 1.2622,
      "step": 444
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.870593070983887,
      "learning_rate": 1e-05,
      "loss": 1.3463,
      "step": 448
    },
    {
      "epoch": 0.06,
      "grad_norm": 20.60326385498047,
      "learning_rate": 1e-05,
      "loss": 1.4536,
      "step": 452
    },
    {
      "epoch": 0.06,
      "grad_norm": 19.696121215820312,
      "learning_rate": 1e-05,
      "loss": 1.4727,
      "step": 456
    },
    {
      "epoch": 0.06,
      "grad_norm": 12.048771858215332,
      "learning_rate": 1e-05,
      "loss": 1.1194,
      "step": 460
    },
    {
      "epoch": 0.06,
      "grad_norm": 10.723337173461914,
      "learning_rate": 1e-05,
      "loss": 1.278,
      "step": 464
    },
    {
      "epoch": 0.06,
      "grad_norm": 14.61669921875,
      "learning_rate": 1e-05,
      "loss": 1.2874,
      "step": 468
    },
    {
      "epoch": 0.06,
      "grad_norm": 17.843774795532227,
      "learning_rate": 1e-05,
      "loss": 1.473,
      "step": 472
    },
    {
      "epoch": 0.06,
      "grad_norm": 11.97594928741455,
      "learning_rate": 1e-05,
      "loss": 1.3402,
      "step": 476
    },
    {
      "epoch": 0.06,
      "grad_norm": 16.94882583618164,
      "learning_rate": 1e-05,
      "loss": 1.348,
      "step": 480
    },
    {
      "epoch": 0.06,
      "grad_norm": 13.37057876586914,
      "learning_rate": 1e-05,
      "loss": 1.4009,
      "step": 484
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.97559642791748,
      "learning_rate": 1e-05,
      "loss": 1.2567,
      "step": 488
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.692577362060547,
      "learning_rate": 1e-05,
      "loss": 1.3178,
      "step": 492
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.757729530334473,
      "learning_rate": 1e-05,
      "loss": 1.2685,
      "step": 496
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.342216491699219,
      "learning_rate": 1e-05,
      "loss": 1.1723,
      "step": 500
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.328269004821777,
      "learning_rate": 1e-05,
      "loss": 1.3646,
      "step": 504
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.79373836517334,
      "learning_rate": 1e-05,
      "loss": 1.411,
      "step": 508
    },
    {
      "epoch": 0.07,
      "grad_norm": 16.844547271728516,
      "learning_rate": 1e-05,
      "loss": 1.3953,
      "step": 512
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.610848426818848,
      "learning_rate": 1e-05,
      "loss": 1.2117,
      "step": 516
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.903069496154785,
      "learning_rate": 1e-05,
      "loss": 1.3293,
      "step": 520
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.726725578308105,
      "learning_rate": 1e-05,
      "loss": 1.1742,
      "step": 524
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.536333084106445,
      "learning_rate": 1e-05,
      "loss": 1.2029,
      "step": 528
    },
    {
      "epoch": 0.07,
      "grad_norm": 12.294252395629883,
      "learning_rate": 1e-05,
      "loss": 1.4808,
      "step": 532
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.004573822021484,
      "learning_rate": 1e-05,
      "loss": 1.4174,
      "step": 536
    },
    {
      "epoch": 0.07,
      "grad_norm": 14.090398788452148,
      "learning_rate": 1e-05,
      "loss": 1.294,
      "step": 540
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.258224487304688,
      "learning_rate": 1e-05,
      "loss": 1.2102,
      "step": 544
    },
    {
      "epoch": 0.07,
      "grad_norm": 17.42641830444336,
      "learning_rate": 1e-05,
      "loss": 1.1167,
      "step": 548
    },
    {
      "epoch": 0.07,
      "grad_norm": 16.85353660583496,
      "learning_rate": 1e-05,
      "loss": 1.1929,
      "step": 552
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.749800682067871,
      "learning_rate": 1e-05,
      "loss": 1.2497,
      "step": 556
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.505334854125977,
      "learning_rate": 1e-05,
      "loss": 1.469,
      "step": 560
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.23172378540039,
      "learning_rate": 1e-05,
      "loss": 1.1327,
      "step": 564
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.605585098266602,
      "learning_rate": 1e-05,
      "loss": 1.4354,
      "step": 568
    },
    {
      "epoch": 0.08,
      "grad_norm": 11.5380277633667,
      "learning_rate": 1e-05,
      "loss": 1.0257,
      "step": 572
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.312134742736816,
      "learning_rate": 1e-05,
      "loss": 1.1472,
      "step": 576
    },
    {
      "epoch": 0.08,
      "grad_norm": 14.064811706542969,
      "learning_rate": 1e-05,
      "loss": 1.4137,
      "step": 580
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.059823989868164,
      "learning_rate": 1e-05,
      "loss": 1.3214,
      "step": 584
    },
    {
      "epoch": 0.08,
      "grad_norm": 25.275758743286133,
      "learning_rate": 1e-05,
      "loss": 1.2589,
      "step": 588
    },
    {
      "epoch": 0.08,
      "grad_norm": 13.294084548950195,
      "learning_rate": 1e-05,
      "loss": 1.3314,
      "step": 592
    },
    {
      "epoch": 0.08,
      "grad_norm": 19.253398895263672,
      "learning_rate": 1e-05,
      "loss": 1.312,
      "step": 596
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.5036678314209,
      "learning_rate": 1e-05,
      "loss": 1.1084,
      "step": 600
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.321338653564453,
      "learning_rate": 1e-05,
      "loss": 0.9577,
      "step": 604
    },
    {
      "epoch": 0.08,
      "grad_norm": 16.680200576782227,
      "learning_rate": 1e-05,
      "loss": 1.0812,
      "step": 608
    },
    {
      "epoch": 0.08,
      "grad_norm": 21.233810424804688,
      "learning_rate": 1e-05,
      "loss": 1.1466,
      "step": 612
    },
    {
      "epoch": 0.08,
      "grad_norm": 15.175568580627441,
      "learning_rate": 1e-05,
      "loss": 1.1733,
      "step": 616
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.851606369018555,
      "learning_rate": 1e-05,
      "loss": 1.2351,
      "step": 620
    },
    {
      "epoch": 0.08,
      "grad_norm": 15.037969589233398,
      "learning_rate": 1e-05,
      "loss": 1.2582,
      "step": 624
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.80508804321289,
      "learning_rate": 1e-05,
      "loss": 1.2167,
      "step": 628
    },
    {
      "epoch": 0.08,
      "grad_norm": 19.68128776550293,
      "learning_rate": 1e-05,
      "loss": 1.1846,
      "step": 632
    },
    {
      "epoch": 0.09,
      "grad_norm": 17.1820125579834,
      "learning_rate": 1e-05,
      "loss": 1.1146,
      "step": 636
    },
    {
      "epoch": 0.09,
      "grad_norm": 22.71976089477539,
      "learning_rate": 1e-05,
      "loss": 1.1102,
      "step": 640
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.898469924926758,
      "learning_rate": 1e-05,
      "loss": 1.1192,
      "step": 644
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.765642166137695,
      "learning_rate": 1e-05,
      "loss": 1.0929,
      "step": 648
    },
    {
      "epoch": 0.09,
      "grad_norm": 16.48575210571289,
      "learning_rate": 1e-05,
      "loss": 1.2444,
      "step": 652
    },
    {
      "epoch": 0.09,
      "grad_norm": 18.059978485107422,
      "learning_rate": 1e-05,
      "loss": 1.0225,
      "step": 656
    },
    {
      "epoch": 0.09,
      "grad_norm": 21.686691284179688,
      "learning_rate": 1e-05,
      "loss": 1.2368,
      "step": 660
    },
    {
      "epoch": 0.09,
      "grad_norm": 16.555057525634766,
      "learning_rate": 1e-05,
      "loss": 1.1306,
      "step": 664
    },
    {
      "epoch": 0.09,
      "grad_norm": 40.51722717285156,
      "learning_rate": 1e-05,
      "loss": 1.5264,
      "step": 668
    },
    {
      "epoch": 0.09,
      "grad_norm": 17.98067283630371,
      "learning_rate": 1e-05,
      "loss": 1.1681,
      "step": 672
    },
    {
      "epoch": 0.09,
      "grad_norm": 25.871517181396484,
      "learning_rate": 1e-05,
      "loss": 1.3084,
      "step": 676
    },
    {
      "epoch": 0.09,
      "grad_norm": 19.082683563232422,
      "learning_rate": 1e-05,
      "loss": 1.1115,
      "step": 680
    },
    {
      "epoch": 0.09,
      "grad_norm": 20.417760848999023,
      "learning_rate": 1e-05,
      "loss": 1.0175,
      "step": 684
    },
    {
      "epoch": 0.09,
      "grad_norm": 16.571781158447266,
      "learning_rate": 1e-05,
      "loss": 0.9302,
      "step": 688
    },
    {
      "epoch": 0.09,
      "grad_norm": 23.175029754638672,
      "learning_rate": 1e-05,
      "loss": 1.3172,
      "step": 692
    },
    {
      "epoch": 0.09,
      "grad_norm": 20.773962020874023,
      "learning_rate": 1e-05,
      "loss": 1.1037,
      "step": 696
    },
    {
      "epoch": 0.09,
      "grad_norm": 19.291976928710938,
      "learning_rate": 1e-05,
      "loss": 1.2112,
      "step": 700
    },
    {
      "epoch": 0.09,
      "grad_norm": 15.130987167358398,
      "learning_rate": 1e-05,
      "loss": 1.249,
      "step": 704
    },
    {
      "epoch": 0.1,
      "grad_norm": 17.30316925048828,
      "learning_rate": 1e-05,
      "loss": 1.2621,
      "step": 708
    },
    {
      "epoch": 0.1,
      "grad_norm": 17.648052215576172,
      "learning_rate": 1e-05,
      "loss": 1.1349,
      "step": 712
    },
    {
      "epoch": 0.1,
      "grad_norm": 21.865745544433594,
      "learning_rate": 1e-05,
      "loss": 0.9834,
      "step": 716
    },
    {
      "epoch": 0.1,
      "grad_norm": 21.098758697509766,
      "learning_rate": 1e-05,
      "loss": 1.0854,
      "step": 720
    },
    {
      "epoch": 0.1,
      "grad_norm": 16.056243896484375,
      "learning_rate": 1e-05,
      "loss": 1.2112,
      "step": 724
    },
    {
      "epoch": 0.1,
      "grad_norm": 21.419692993164062,
      "learning_rate": 1e-05,
      "loss": 1.2343,
      "step": 728
    },
    {
      "epoch": 0.1,
      "grad_norm": 18.104318618774414,
      "learning_rate": 1e-05,
      "loss": 1.0307,
      "step": 732
    },
    {
      "epoch": 0.1,
      "grad_norm": 22.579008102416992,
      "learning_rate": 1e-05,
      "loss": 1.3169,
      "step": 736
    },
    {
      "epoch": 0.1,
      "grad_norm": 21.75552749633789,
      "learning_rate": 1e-05,
      "loss": 1.0736,
      "step": 740
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.42217254638672,
      "learning_rate": 1e-05,
      "loss": 1.1918,
      "step": 744
    },
    {
      "epoch": 0.1,
      "eval_accuracy": 0.5830032892528697,
      "eval_f1": 0.5575515438373005,
      "eval_loss": 1.1349217891693115,
      "eval_precision": 0.555932616456373,
      "eval_recall": 0.5830032892528697,
      "eval_runtime": 1703.7286,
      "eval_samples_per_second": 8.744,
      "eval_steps_per_second": 1.093,
      "step": 744
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.51240348815918,
      "learning_rate": 1e-05,
      "loss": 1.0896,
      "step": 748
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.605669021606445,
      "learning_rate": 1e-05,
      "loss": 1.0981,
      "step": 752
    },
    {
      "epoch": 0.1,
      "grad_norm": 29.590694427490234,
      "learning_rate": 1e-05,
      "loss": 1.2727,
      "step": 756
    },
    {
      "epoch": 0.1,
      "grad_norm": 18.306303024291992,
      "learning_rate": 1e-05,
      "loss": 1.0968,
      "step": 760
    },
    {
      "epoch": 0.1,
      "grad_norm": 18.52627182006836,
      "learning_rate": 1e-05,
      "loss": 1.2829,
      "step": 764
    },
    {
      "epoch": 0.1,
      "grad_norm": 17.067983627319336,
      "learning_rate": 1e-05,
      "loss": 1.1679,
      "step": 768
    },
    {
      "epoch": 0.1,
      "grad_norm": 19.979488372802734,
      "learning_rate": 1e-05,
      "loss": 1.1803,
      "step": 772
    },
    {
      "epoch": 0.1,
      "grad_norm": 24.266551971435547,
      "learning_rate": 1e-05,
      "loss": 1.2056,
      "step": 776
    },
    {
      "epoch": 0.1,
      "grad_norm": 27.516727447509766,
      "learning_rate": 1e-05,
      "loss": 1.1552,
      "step": 780
    },
    {
      "epoch": 0.11,
      "grad_norm": 23.817169189453125,
      "learning_rate": 1e-05,
      "loss": 1.0661,
      "step": 784
    },
    {
      "epoch": 0.11,
      "grad_norm": 11.992378234863281,
      "learning_rate": 1e-05,
      "loss": 1.1502,
      "step": 788
    },
    {
      "epoch": 0.11,
      "grad_norm": 23.033273696899414,
      "learning_rate": 1e-05,
      "loss": 1.1195,
      "step": 792
    },
    {
      "epoch": 0.11,
      "grad_norm": 15.686424255371094,
      "learning_rate": 1e-05,
      "loss": 1.1446,
      "step": 796
    },
    {
      "epoch": 0.11,
      "grad_norm": 20.513526916503906,
      "learning_rate": 1e-05,
      "loss": 1.2261,
      "step": 800
    },
    {
      "epoch": 0.11,
      "grad_norm": 20.989809036254883,
      "learning_rate": 1e-05,
      "loss": 1.086,
      "step": 804
    },
    {
      "epoch": 0.11,
      "grad_norm": 27.029544830322266,
      "learning_rate": 1e-05,
      "loss": 1.3364,
      "step": 808
    },
    {
      "epoch": 0.11,
      "grad_norm": 15.828264236450195,
      "learning_rate": 1e-05,
      "loss": 0.8909,
      "step": 812
    },
    {
      "epoch": 0.11,
      "grad_norm": 23.160207748413086,
      "learning_rate": 1e-05,
      "loss": 1.1079,
      "step": 816
    },
    {
      "epoch": 0.11,
      "grad_norm": 22.01580047607422,
      "learning_rate": 1e-05,
      "loss": 1.24,
      "step": 820
    },
    {
      "epoch": 0.11,
      "grad_norm": 20.612146377563477,
      "learning_rate": 1e-05,
      "loss": 1.2068,
      "step": 824
    },
    {
      "epoch": 0.11,
      "grad_norm": 18.64454460144043,
      "learning_rate": 1e-05,
      "loss": 1.0896,
      "step": 828
    },
    {
      "epoch": 0.11,
      "grad_norm": 14.037605285644531,
      "learning_rate": 1e-05,
      "loss": 1.0827,
      "step": 832
    },
    {
      "epoch": 0.11,
      "grad_norm": 27.161653518676758,
      "learning_rate": 1e-05,
      "loss": 1.2905,
      "step": 836
    },
    {
      "epoch": 0.11,
      "grad_norm": 23.758373260498047,
      "learning_rate": 1e-05,
      "loss": 1.1688,
      "step": 840
    },
    {
      "epoch": 0.11,
      "grad_norm": 19.22093391418457,
      "learning_rate": 1e-05,
      "loss": 0.989,
      "step": 844
    },
    {
      "epoch": 0.11,
      "grad_norm": 17.13825225830078,
      "learning_rate": 1e-05,
      "loss": 0.9754,
      "step": 848
    },
    {
      "epoch": 0.11,
      "grad_norm": 25.24506378173828,
      "learning_rate": 1e-05,
      "loss": 1.3466,
      "step": 852
    },
    {
      "epoch": 0.11,
      "grad_norm": 25.996143341064453,
      "learning_rate": 1e-05,
      "loss": 1.03,
      "step": 856
    },
    {
      "epoch": 0.12,
      "grad_norm": 19.085079193115234,
      "learning_rate": 1e-05,
      "loss": 1.1723,
      "step": 860
    },
    {
      "epoch": 0.12,
      "grad_norm": 20.193279266357422,
      "learning_rate": 1e-05,
      "loss": 1.0495,
      "step": 864
    },
    {
      "epoch": 0.12,
      "grad_norm": 25.382492065429688,
      "learning_rate": 1e-05,
      "loss": 1.3406,
      "step": 868
    },
    {
      "epoch": 0.12,
      "grad_norm": 22.1256160736084,
      "learning_rate": 1e-05,
      "loss": 1.1601,
      "step": 872
    },
    {
      "epoch": 0.12,
      "grad_norm": 22.245956420898438,
      "learning_rate": 1e-05,
      "loss": 1.1555,
      "step": 876
    },
    {
      "epoch": 0.12,
      "grad_norm": 17.052677154541016,
      "learning_rate": 1e-05,
      "loss": 1.0891,
      "step": 880
    },
    {
      "epoch": 0.12,
      "grad_norm": 20.015920639038086,
      "learning_rate": 1e-05,
      "loss": 1.0969,
      "step": 884
    },
    {
      "epoch": 0.12,
      "grad_norm": 13.789408683776855,
      "learning_rate": 1e-05,
      "loss": 1.1253,
      "step": 888
    },
    {
      "epoch": 0.12,
      "grad_norm": 22.401470184326172,
      "learning_rate": 1e-05,
      "loss": 1.013,
      "step": 892
    },
    {
      "epoch": 0.12,
      "grad_norm": 21.160030364990234,
      "learning_rate": 1e-05,
      "loss": 1.0941,
      "step": 896
    },
    {
      "epoch": 0.12,
      "grad_norm": 30.17458152770996,
      "learning_rate": 1e-05,
      "loss": 0.9685,
      "step": 900
    },
    {
      "epoch": 0.12,
      "grad_norm": 18.830263137817383,
      "learning_rate": 1e-05,
      "loss": 1.2957,
      "step": 904
    },
    {
      "epoch": 0.12,
      "grad_norm": 15.859519004821777,
      "learning_rate": 1e-05,
      "loss": 1.0332,
      "step": 908
    },
    {
      "epoch": 0.12,
      "grad_norm": 22.08500099182129,
      "learning_rate": 1e-05,
      "loss": 1.1533,
      "step": 912
    },
    {
      "epoch": 0.12,
      "grad_norm": 21.524869918823242,
      "learning_rate": 1e-05,
      "loss": 0.9535,
      "step": 916
    },
    {
      "epoch": 0.12,
      "grad_norm": 17.221656799316406,
      "learning_rate": 1e-05,
      "loss": 0.9327,
      "step": 920
    },
    {
      "epoch": 0.12,
      "grad_norm": 15.874305725097656,
      "learning_rate": 1e-05,
      "loss": 0.9889,
      "step": 924
    },
    {
      "epoch": 0.12,
      "grad_norm": 19.259159088134766,
      "learning_rate": 1e-05,
      "loss": 1.0881,
      "step": 928
    },
    {
      "epoch": 0.13,
      "grad_norm": 14.35271167755127,
      "learning_rate": 1e-05,
      "loss": 1.1661,
      "step": 932
    },
    {
      "epoch": 0.13,
      "grad_norm": 22.162368774414062,
      "learning_rate": 1e-05,
      "loss": 1.3379,
      "step": 936
    },
    {
      "epoch": 0.13,
      "grad_norm": 19.791181564331055,
      "learning_rate": 1e-05,
      "loss": 1.0124,
      "step": 940
    },
    {
      "epoch": 0.13,
      "grad_norm": 20.37532615661621,
      "learning_rate": 1e-05,
      "loss": 1.1995,
      "step": 944
    },
    {
      "epoch": 0.13,
      "grad_norm": 24.026233673095703,
      "learning_rate": 1e-05,
      "loss": 1.0641,
      "step": 948
    },
    {
      "epoch": 0.13,
      "grad_norm": 18.961711883544922,
      "learning_rate": 1e-05,
      "loss": 1.0117,
      "step": 952
    },
    {
      "epoch": 0.13,
      "grad_norm": 32.141021728515625,
      "learning_rate": 1e-05,
      "loss": 1.1684,
      "step": 956
    },
    {
      "epoch": 0.13,
      "grad_norm": 13.611471176147461,
      "learning_rate": 1e-05,
      "loss": 0.9368,
      "step": 960
    },
    {
      "epoch": 0.13,
      "grad_norm": 21.209434509277344,
      "learning_rate": 1e-05,
      "loss": 1.3176,
      "step": 964
    },
    {
      "epoch": 0.13,
      "grad_norm": 16.742095947265625,
      "learning_rate": 1e-05,
      "loss": 0.8641,
      "step": 968
    },
    {
      "epoch": 0.13,
      "grad_norm": 25.600994110107422,
      "learning_rate": 1e-05,
      "loss": 1.0256,
      "step": 972
    },
    {
      "epoch": 0.13,
      "grad_norm": 28.507272720336914,
      "learning_rate": 1e-05,
      "loss": 0.9598,
      "step": 976
    },
    {
      "epoch": 0.13,
      "grad_norm": 30.306133270263672,
      "learning_rate": 1e-05,
      "loss": 1.249,
      "step": 980
    },
    {
      "epoch": 0.13,
      "grad_norm": 22.40034294128418,
      "learning_rate": 1e-05,
      "loss": 1.2162,
      "step": 984
    },
    {
      "epoch": 0.13,
      "grad_norm": 27.371427536010742,
      "learning_rate": 1e-05,
      "loss": 1.0498,
      "step": 988
    },
    {
      "epoch": 0.13,
      "grad_norm": 21.89085578918457,
      "learning_rate": 1e-05,
      "loss": 0.8738,
      "step": 992
    },
    {
      "epoch": 0.13,
      "grad_norm": 16.137487411499023,
      "learning_rate": 1e-05,
      "loss": 1.0319,
      "step": 996
    },
    {
      "epoch": 0.13,
      "grad_norm": 20.793142318725586,
      "learning_rate": 1e-05,
      "loss": 1.134,
      "step": 1000
    },
    {
      "epoch": 0.13,
      "grad_norm": 22.281648635864258,
      "learning_rate": 1e-05,
      "loss": 1.1725,
      "step": 1004
    },
    {
      "epoch": 0.14,
      "grad_norm": 16.74483299255371,
      "learning_rate": 1e-05,
      "loss": 1.0193,
      "step": 1008
    },
    {
      "epoch": 0.14,
      "grad_norm": 25.52030372619629,
      "learning_rate": 1e-05,
      "loss": 1.1161,
      "step": 1012
    },
    {
      "epoch": 0.14,
      "grad_norm": 17.93597412109375,
      "learning_rate": 1e-05,
      "loss": 1.0157,
      "step": 1016
    },
    {
      "epoch": 0.14,
      "grad_norm": 27.956371307373047,
      "learning_rate": 1e-05,
      "loss": 1.0231,
      "step": 1020
    },
    {
      "epoch": 0.14,
      "grad_norm": 18.72889518737793,
      "learning_rate": 1e-05,
      "loss": 1.0604,
      "step": 1024
    },
    {
      "epoch": 0.14,
      "grad_norm": 16.169279098510742,
      "learning_rate": 1e-05,
      "loss": 1.1741,
      "step": 1028
    },
    {
      "epoch": 0.14,
      "grad_norm": 16.95634651184082,
      "learning_rate": 1e-05,
      "loss": 1.2089,
      "step": 1032
    },
    {
      "epoch": 0.14,
      "grad_norm": 20.678865432739258,
      "learning_rate": 1e-05,
      "loss": 1.1197,
      "step": 1036
    },
    {
      "epoch": 0.14,
      "grad_norm": 21.533851623535156,
      "learning_rate": 1e-05,
      "loss": 1.2749,
      "step": 1040
    },
    {
      "epoch": 0.14,
      "grad_norm": 19.892356872558594,
      "learning_rate": 1e-05,
      "loss": 1.103,
      "step": 1044
    },
    {
      "epoch": 0.14,
      "grad_norm": 18.17080307006836,
      "learning_rate": 1e-05,
      "loss": 0.9091,
      "step": 1048
    },
    {
      "epoch": 0.14,
      "grad_norm": 22.859163284301758,
      "learning_rate": 1e-05,
      "loss": 1.2308,
      "step": 1052
    },
    {
      "epoch": 0.14,
      "grad_norm": 26.614486694335938,
      "learning_rate": 1e-05,
      "loss": 1.1986,
      "step": 1056
    },
    {
      "epoch": 0.14,
      "grad_norm": 18.440086364746094,
      "learning_rate": 1e-05,
      "loss": 1.0068,
      "step": 1060
    },
    {
      "epoch": 0.14,
      "grad_norm": 17.572628021240234,
      "learning_rate": 1e-05,
      "loss": 1.1169,
      "step": 1064
    },
    {
      "epoch": 0.14,
      "grad_norm": 14.665060043334961,
      "learning_rate": 1e-05,
      "loss": 0.8688,
      "step": 1068
    },
    {
      "epoch": 0.14,
      "grad_norm": 17.998559951782227,
      "learning_rate": 1e-05,
      "loss": 1.0664,
      "step": 1072
    },
    {
      "epoch": 0.14,
      "grad_norm": 22.781028747558594,
      "learning_rate": 1e-05,
      "loss": 1.278,
      "step": 1076
    },
    {
      "epoch": 0.15,
      "grad_norm": 18.496400833129883,
      "learning_rate": 1e-05,
      "loss": 1.133,
      "step": 1080
    },
    {
      "epoch": 0.15,
      "grad_norm": 22.770442962646484,
      "learning_rate": 1e-05,
      "loss": 1.0384,
      "step": 1084
    },
    {
      "epoch": 0.15,
      "grad_norm": 17.85660171508789,
      "learning_rate": 1e-05,
      "loss": 0.8152,
      "step": 1088
    },
    {
      "epoch": 0.15,
      "grad_norm": 19.389625549316406,
      "learning_rate": 1e-05,
      "loss": 1.0689,
      "step": 1092
    },
    {
      "epoch": 0.15,
      "grad_norm": 15.388474464416504,
      "learning_rate": 1e-05,
      "loss": 0.9803,
      "step": 1096
    },
    {
      "epoch": 0.15,
      "grad_norm": 20.480789184570312,
      "learning_rate": 1e-05,
      "loss": 0.8933,
      "step": 1100
    },
    {
      "epoch": 0.15,
      "grad_norm": 28.222936630249023,
      "learning_rate": 1e-05,
      "loss": 0.9032,
      "step": 1104
    },
    {
      "epoch": 0.15,
      "grad_norm": 18.994558334350586,
      "learning_rate": 1e-05,
      "loss": 1.0481,
      "step": 1108
    },
    {
      "epoch": 0.15,
      "grad_norm": 28.383895874023438,
      "learning_rate": 1e-05,
      "loss": 1.0665,
      "step": 1112
    },
    {
      "epoch": 0.15,
      "grad_norm": 20.0950870513916,
      "learning_rate": 1e-05,
      "loss": 1.0495,
      "step": 1116
    },
    {
      "epoch": 0.15,
      "grad_norm": 21.39897918701172,
      "learning_rate": 1e-05,
      "loss": 0.9783,
      "step": 1120
    },
    {
      "epoch": 0.15,
      "grad_norm": 26.36522674560547,
      "learning_rate": 1e-05,
      "loss": 1.0235,
      "step": 1124
    },
    {
      "epoch": 0.15,
      "grad_norm": 32.956722259521484,
      "learning_rate": 1e-05,
      "loss": 1.1571,
      "step": 1128
    },
    {
      "epoch": 0.15,
      "grad_norm": 27.404817581176758,
      "learning_rate": 1e-05,
      "loss": 1.1287,
      "step": 1132
    },
    {
      "epoch": 0.15,
      "grad_norm": 20.66819953918457,
      "learning_rate": 1e-05,
      "loss": 1.0461,
      "step": 1136
    },
    {
      "epoch": 0.15,
      "grad_norm": 25.999408721923828,
      "learning_rate": 1e-05,
      "loss": 0.9158,
      "step": 1140
    },
    {
      "epoch": 0.15,
      "grad_norm": 15.394207000732422,
      "learning_rate": 1e-05,
      "loss": 0.9888,
      "step": 1144
    },
    {
      "epoch": 0.15,
      "grad_norm": 32.81070327758789,
      "learning_rate": 1e-05,
      "loss": 1.0103,
      "step": 1148
    },
    {
      "epoch": 0.15,
      "grad_norm": 19.433975219726562,
      "learning_rate": 1e-05,
      "loss": 1.0261,
      "step": 1152
    },
    {
      "epoch": 0.16,
      "grad_norm": 26.882335662841797,
      "learning_rate": 1e-05,
      "loss": 1.0434,
      "step": 1156
    },
    {
      "epoch": 0.16,
      "grad_norm": 23.615028381347656,
      "learning_rate": 1e-05,
      "loss": 1.0989,
      "step": 1160
    },
    {
      "epoch": 0.16,
      "grad_norm": 17.798301696777344,
      "learning_rate": 1e-05,
      "loss": 1.0459,
      "step": 1164
    },
    {
      "epoch": 0.16,
      "grad_norm": 21.517902374267578,
      "learning_rate": 1e-05,
      "loss": 0.9834,
      "step": 1168
    },
    {
      "epoch": 0.16,
      "grad_norm": 18.51760482788086,
      "learning_rate": 1e-05,
      "loss": 1.2291,
      "step": 1172
    },
    {
      "epoch": 0.16,
      "grad_norm": 20.69686508178711,
      "learning_rate": 1e-05,
      "loss": 0.8261,
      "step": 1176
    },
    {
      "epoch": 0.16,
      "grad_norm": 18.597736358642578,
      "learning_rate": 1e-05,
      "loss": 0.887,
      "step": 1180
    },
    {
      "epoch": 0.16,
      "grad_norm": 22.207292556762695,
      "learning_rate": 1e-05,
      "loss": 1.0347,
      "step": 1184
    },
    {
      "epoch": 0.16,
      "grad_norm": 24.576387405395508,
      "learning_rate": 1e-05,
      "loss": 1.0568,
      "step": 1188
    },
    {
      "epoch": 0.16,
      "grad_norm": 24.60764503479004,
      "learning_rate": 1e-05,
      "loss": 1.1495,
      "step": 1192
    },
    {
      "epoch": 0.16,
      "grad_norm": 19.709333419799805,
      "learning_rate": 1e-05,
      "loss": 1.142,
      "step": 1196
    },
    {
      "epoch": 0.16,
      "grad_norm": 25.88845443725586,
      "learning_rate": 1e-05,
      "loss": 0.8241,
      "step": 1200
    },
    {
      "epoch": 0.16,
      "grad_norm": 16.16547966003418,
      "learning_rate": 1e-05,
      "loss": 0.8464,
      "step": 1204
    },
    {
      "epoch": 0.16,
      "grad_norm": 18.078176498413086,
      "learning_rate": 1e-05,
      "loss": 0.9696,
      "step": 1208
    },
    {
      "epoch": 0.16,
      "grad_norm": 18.514867782592773,
      "learning_rate": 1e-05,
      "loss": 0.9377,
      "step": 1212
    },
    {
      "epoch": 0.16,
      "grad_norm": 28.187631607055664,
      "learning_rate": 1e-05,
      "loss": 1.3165,
      "step": 1216
    },
    {
      "epoch": 0.16,
      "grad_norm": 16.10260581970215,
      "learning_rate": 1e-05,
      "loss": 0.8476,
      "step": 1220
    },
    {
      "epoch": 0.16,
      "grad_norm": 22.290220260620117,
      "learning_rate": 1e-05,
      "loss": 1.1599,
      "step": 1224
    },
    {
      "epoch": 0.16,
      "grad_norm": 21.71116828918457,
      "learning_rate": 1e-05,
      "loss": 1.0083,
      "step": 1228
    },
    {
      "epoch": 0.17,
      "grad_norm": 22.7668399810791,
      "learning_rate": 1e-05,
      "loss": 1.1149,
      "step": 1232
    },
    {
      "epoch": 0.17,
      "grad_norm": 17.705135345458984,
      "learning_rate": 1e-05,
      "loss": 1.0899,
      "step": 1236
    },
    {
      "epoch": 0.17,
      "grad_norm": 21.8007869720459,
      "learning_rate": 1e-05,
      "loss": 0.978,
      "step": 1240
    },
    {
      "epoch": 0.17,
      "grad_norm": 22.926210403442383,
      "learning_rate": 1e-05,
      "loss": 1.0281,
      "step": 1244
    },
    {
      "epoch": 0.17,
      "grad_norm": 20.82128143310547,
      "learning_rate": 1e-05,
      "loss": 0.9619,
      "step": 1248
    },
    {
      "epoch": 0.17,
      "grad_norm": 21.52095603942871,
      "learning_rate": 1e-05,
      "loss": 0.9852,
      "step": 1252
    },
    {
      "epoch": 0.17,
      "grad_norm": 20.31349754333496,
      "learning_rate": 1e-05,
      "loss": 0.9032,
      "step": 1256
    },
    {
      "epoch": 0.17,
      "grad_norm": 17.02394676208496,
      "learning_rate": 1e-05,
      "loss": 0.905,
      "step": 1260
    },
    {
      "epoch": 0.17,
      "grad_norm": 20.784881591796875,
      "learning_rate": 1e-05,
      "loss": 1.0244,
      "step": 1264
    },
    {
      "epoch": 0.17,
      "grad_norm": 25.528013229370117,
      "learning_rate": 1e-05,
      "loss": 1.1541,
      "step": 1268
    },
    {
      "epoch": 0.17,
      "grad_norm": 20.18809700012207,
      "learning_rate": 1e-05,
      "loss": 1.1672,
      "step": 1272
    },
    {
      "epoch": 0.17,
      "grad_norm": 16.15116310119629,
      "learning_rate": 1e-05,
      "loss": 0.987,
      "step": 1276
    },
    {
      "epoch": 0.17,
      "grad_norm": 17.89437484741211,
      "learning_rate": 1e-05,
      "loss": 1.0787,
      "step": 1280
    },
    {
      "epoch": 0.17,
      "grad_norm": 22.024934768676758,
      "learning_rate": 1e-05,
      "loss": 0.8344,
      "step": 1284
    },
    {
      "epoch": 0.17,
      "grad_norm": 18.602169036865234,
      "learning_rate": 1e-05,
      "loss": 1.1538,
      "step": 1288
    },
    {
      "epoch": 0.17,
      "grad_norm": 15.168402671813965,
      "learning_rate": 1e-05,
      "loss": 0.9825,
      "step": 1292
    },
    {
      "epoch": 0.17,
      "grad_norm": 15.25327205657959,
      "learning_rate": 1e-05,
      "loss": 0.8063,
      "step": 1296
    },
    {
      "epoch": 0.17,
      "grad_norm": 18.256202697753906,
      "learning_rate": 1e-05,
      "loss": 1.1081,
      "step": 1300
    },
    {
      "epoch": 0.18,
      "grad_norm": 20.237245559692383,
      "learning_rate": 1e-05,
      "loss": 1.0776,
      "step": 1304
    },
    {
      "epoch": 0.18,
      "grad_norm": 20.23288917541504,
      "learning_rate": 1e-05,
      "loss": 0.8927,
      "step": 1308
    },
    {
      "epoch": 0.18,
      "grad_norm": 20.456344604492188,
      "learning_rate": 1e-05,
      "loss": 1.0254,
      "step": 1312
    },
    {
      "epoch": 0.18,
      "grad_norm": 12.627403259277344,
      "learning_rate": 1e-05,
      "loss": 0.9897,
      "step": 1316
    },
    {
      "epoch": 0.18,
      "grad_norm": 25.290206909179688,
      "learning_rate": 1e-05,
      "loss": 0.9737,
      "step": 1320
    },
    {
      "epoch": 0.18,
      "grad_norm": 18.379356384277344,
      "learning_rate": 1e-05,
      "loss": 0.6342,
      "step": 1324
    },
    {
      "epoch": 0.18,
      "grad_norm": 27.60464859008789,
      "learning_rate": 1e-05,
      "loss": 1.21,
      "step": 1328
    },
    {
      "epoch": 0.18,
      "grad_norm": 21.988798141479492,
      "learning_rate": 1e-05,
      "loss": 0.9867,
      "step": 1332
    },
    {
      "epoch": 0.18,
      "grad_norm": 18.399913787841797,
      "learning_rate": 1e-05,
      "loss": 0.9103,
      "step": 1336
    },
    {
      "epoch": 0.18,
      "grad_norm": 17.856666564941406,
      "learning_rate": 1e-05,
      "loss": 0.933,
      "step": 1340
    },
    {
      "epoch": 0.18,
      "grad_norm": 29.240161895751953,
      "learning_rate": 1e-05,
      "loss": 1.2994,
      "step": 1344
    },
    {
      "epoch": 0.18,
      "grad_norm": 21.94029998779297,
      "learning_rate": 1e-05,
      "loss": 1.0594,
      "step": 1348
    },
    {
      "epoch": 0.18,
      "grad_norm": 22.944103240966797,
      "learning_rate": 1e-05,
      "loss": 0.9615,
      "step": 1352
    },
    {
      "epoch": 0.18,
      "grad_norm": 15.500303268432617,
      "learning_rate": 1e-05,
      "loss": 0.8696,
      "step": 1356
    },
    {
      "epoch": 0.18,
      "grad_norm": 19.420085906982422,
      "learning_rate": 1e-05,
      "loss": 1.0127,
      "step": 1360
    },
    {
      "epoch": 0.18,
      "grad_norm": 33.55403137207031,
      "learning_rate": 1e-05,
      "loss": 1.0399,
      "step": 1364
    },
    {
      "epoch": 0.18,
      "grad_norm": 16.798709869384766,
      "learning_rate": 1e-05,
      "loss": 1.2093,
      "step": 1368
    },
    {
      "epoch": 0.18,
      "grad_norm": 28.14599609375,
      "learning_rate": 1e-05,
      "loss": 0.8252,
      "step": 1372
    },
    {
      "epoch": 0.18,
      "grad_norm": 18.056001663208008,
      "learning_rate": 1e-05,
      "loss": 1.1107,
      "step": 1376
    },
    {
      "epoch": 0.19,
      "grad_norm": 18.772920608520508,
      "learning_rate": 1e-05,
      "loss": 0.8149,
      "step": 1380
    },
    {
      "epoch": 0.19,
      "grad_norm": 30.61265754699707,
      "learning_rate": 1e-05,
      "loss": 0.8943,
      "step": 1384
    },
    {
      "epoch": 0.19,
      "grad_norm": 22.935930252075195,
      "learning_rate": 1e-05,
      "loss": 0.9596,
      "step": 1388
    },
    {
      "epoch": 0.19,
      "grad_norm": 23.910293579101562,
      "learning_rate": 1e-05,
      "loss": 1.2379,
      "step": 1392
    },
    {
      "epoch": 0.19,
      "grad_norm": 21.147846221923828,
      "learning_rate": 1e-05,
      "loss": 0.9436,
      "step": 1396
    },
    {
      "epoch": 0.19,
      "grad_norm": 23.48929214477539,
      "learning_rate": 1e-05,
      "loss": 1.0219,
      "step": 1400
    },
    {
      "epoch": 0.19,
      "grad_norm": 27.349401473999023,
      "learning_rate": 1e-05,
      "loss": 0.9436,
      "step": 1404
    },
    {
      "epoch": 0.19,
      "grad_norm": 19.580591201782227,
      "learning_rate": 1e-05,
      "loss": 0.9875,
      "step": 1408
    },
    {
      "epoch": 0.19,
      "grad_norm": 17.121780395507812,
      "learning_rate": 1e-05,
      "loss": 0.7324,
      "step": 1412
    },
    {
      "epoch": 0.19,
      "grad_norm": 18.698511123657227,
      "learning_rate": 1e-05,
      "loss": 1.1309,
      "step": 1416
    },
    {
      "epoch": 0.19,
      "grad_norm": 20.454607009887695,
      "learning_rate": 1e-05,
      "loss": 1.0207,
      "step": 1420
    },
    {
      "epoch": 0.19,
      "grad_norm": 16.989917755126953,
      "learning_rate": 1e-05,
      "loss": 0.792,
      "step": 1424
    },
    {
      "epoch": 0.19,
      "grad_norm": 23.952777862548828,
      "learning_rate": 1e-05,
      "loss": 0.8142,
      "step": 1428
    },
    {
      "epoch": 0.19,
      "grad_norm": 28.564327239990234,
      "learning_rate": 1e-05,
      "loss": 1.0192,
      "step": 1432
    },
    {
      "epoch": 0.19,
      "grad_norm": 23.98495101928711,
      "learning_rate": 1e-05,
      "loss": 1.1916,
      "step": 1436
    },
    {
      "epoch": 0.19,
      "grad_norm": 19.14228057861328,
      "learning_rate": 1e-05,
      "loss": 0.8869,
      "step": 1440
    },
    {
      "epoch": 0.19,
      "grad_norm": 26.0870304107666,
      "learning_rate": 1e-05,
      "loss": 1.022,
      "step": 1444
    },
    {
      "epoch": 0.19,
      "grad_norm": 23.476486206054688,
      "learning_rate": 1e-05,
      "loss": 1.013,
      "step": 1448
    },
    {
      "epoch": 0.19,
      "grad_norm": 19.388561248779297,
      "learning_rate": 1e-05,
      "loss": 0.8193,
      "step": 1452
    },
    {
      "epoch": 0.2,
      "grad_norm": 36.7020378112793,
      "learning_rate": 1e-05,
      "loss": 1.0507,
      "step": 1456
    },
    {
      "epoch": 0.2,
      "grad_norm": 18.534345626831055,
      "learning_rate": 1e-05,
      "loss": 1.029,
      "step": 1460
    },
    {
      "epoch": 0.2,
      "grad_norm": 24.12605094909668,
      "learning_rate": 1e-05,
      "loss": 1.1343,
      "step": 1464
    },
    {
      "epoch": 0.2,
      "grad_norm": 21.593416213989258,
      "learning_rate": 1e-05,
      "loss": 0.7974,
      "step": 1468
    },
    {
      "epoch": 0.2,
      "grad_norm": 21.722013473510742,
      "learning_rate": 1e-05,
      "loss": 0.8006,
      "step": 1472
    },
    {
      "epoch": 0.2,
      "grad_norm": 23.167821884155273,
      "learning_rate": 1e-05,
      "loss": 0.961,
      "step": 1476
    },
    {
      "epoch": 0.2,
      "grad_norm": 15.78747272491455,
      "learning_rate": 1e-05,
      "loss": 0.9226,
      "step": 1480
    },
    {
      "epoch": 0.2,
      "grad_norm": 16.530284881591797,
      "learning_rate": 1e-05,
      "loss": 0.8231,
      "step": 1484
    },
    {
      "epoch": 0.2,
      "grad_norm": 22.79851531982422,
      "learning_rate": 1e-05,
      "loss": 1.1181,
      "step": 1488
    },
    {
      "epoch": 0.2,
      "eval_accuracy": 0.6373095254078003,
      "eval_f1": 0.6280464894718052,
      "eval_loss": 0.9917081594467163,
      "eval_precision": 0.6371089879710783,
      "eval_recall": 0.6373095254078003,
      "eval_runtime": 1691.1361,
      "eval_samples_per_second": 8.809,
      "eval_steps_per_second": 1.102,
      "step": 1488
    },
    {
      "epoch": 0.2,
      "grad_norm": 25.126588821411133,
      "learning_rate": 1e-05,
      "loss": 1.016,
      "step": 1492
    },
    {
      "epoch": 0.2,
      "grad_norm": 16.629859924316406,
      "learning_rate": 1e-05,
      "loss": 1.0677,
      "step": 1496
    },
    {
      "epoch": 0.2,
      "grad_norm": 23.582857131958008,
      "learning_rate": 1e-05,
      "loss": 1.212,
      "step": 1500
    },
    {
      "epoch": 0.2,
      "grad_norm": 32.82191467285156,
      "learning_rate": 1e-05,
      "loss": 0.9022,
      "step": 1504
    },
    {
      "epoch": 0.2,
      "grad_norm": 26.192142486572266,
      "learning_rate": 1e-05,
      "loss": 1.0452,
      "step": 1508
    },
    {
      "epoch": 0.2,
      "grad_norm": 24.80997085571289,
      "learning_rate": 1e-05,
      "loss": 1.0773,
      "step": 1512
    },
    {
      "epoch": 0.2,
      "grad_norm": 19.970605850219727,
      "learning_rate": 1e-05,
      "loss": 1.0139,
      "step": 1516
    },
    {
      "epoch": 0.2,
      "grad_norm": 23.80835723876953,
      "learning_rate": 1e-05,
      "loss": 0.9656,
      "step": 1520
    },
    {
      "epoch": 0.2,
      "grad_norm": 26.998411178588867,
      "learning_rate": 1e-05,
      "loss": 0.9447,
      "step": 1524
    },
    {
      "epoch": 0.21,
      "grad_norm": 21.35707664489746,
      "learning_rate": 1e-05,
      "loss": 0.9243,
      "step": 1528
    },
    {
      "epoch": 0.21,
      "grad_norm": 22.942026138305664,
      "learning_rate": 1e-05,
      "loss": 0.9511,
      "step": 1532
    },
    {
      "epoch": 0.21,
      "grad_norm": 24.84079360961914,
      "learning_rate": 1e-05,
      "loss": 1.0257,
      "step": 1536
    },
    {
      "epoch": 0.21,
      "grad_norm": 19.167720794677734,
      "learning_rate": 1e-05,
      "loss": 0.9225,
      "step": 1540
    },
    {
      "epoch": 0.21,
      "grad_norm": 24.286279678344727,
      "learning_rate": 1e-05,
      "loss": 1.0139,
      "step": 1544
    },
    {
      "epoch": 0.21,
      "grad_norm": 22.00897979736328,
      "learning_rate": 1e-05,
      "loss": 0.9035,
      "step": 1548
    },
    {
      "epoch": 0.21,
      "grad_norm": 21.79175567626953,
      "learning_rate": 1e-05,
      "loss": 0.8323,
      "step": 1552
    },
    {
      "epoch": 0.21,
      "grad_norm": 20.429302215576172,
      "learning_rate": 1e-05,
      "loss": 0.8588,
      "step": 1556
    },
    {
      "epoch": 0.21,
      "grad_norm": 32.423866271972656,
      "learning_rate": 1e-05,
      "loss": 1.0496,
      "step": 1560
    },
    {
      "epoch": 0.21,
      "grad_norm": 16.71613883972168,
      "learning_rate": 1e-05,
      "loss": 0.7792,
      "step": 1564
    },
    {
      "epoch": 0.21,
      "grad_norm": 18.703784942626953,
      "learning_rate": 1e-05,
      "loss": 0.9199,
      "step": 1568
    },
    {
      "epoch": 0.21,
      "grad_norm": 29.073871612548828,
      "learning_rate": 1e-05,
      "loss": 1.2608,
      "step": 1572
    },
    {
      "epoch": 0.21,
      "grad_norm": 24.304059982299805,
      "learning_rate": 1e-05,
      "loss": 1.0691,
      "step": 1576
    },
    {
      "epoch": 0.21,
      "grad_norm": 33.12821578979492,
      "learning_rate": 1e-05,
      "loss": 1.0116,
      "step": 1580
    },
    {
      "epoch": 0.21,
      "grad_norm": 23.634016036987305,
      "learning_rate": 1e-05,
      "loss": 0.7974,
      "step": 1584
    },
    {
      "epoch": 0.21,
      "grad_norm": 25.000980377197266,
      "learning_rate": 1e-05,
      "loss": 0.9999,
      "step": 1588
    },
    {
      "epoch": 0.21,
      "grad_norm": 21.291601181030273,
      "learning_rate": 1e-05,
      "loss": 1.0121,
      "step": 1592
    },
    {
      "epoch": 0.21,
      "grad_norm": 19.109914779663086,
      "learning_rate": 1e-05,
      "loss": 0.9877,
      "step": 1596
    },
    {
      "epoch": 0.21,
      "grad_norm": 17.34812355041504,
      "learning_rate": 1e-05,
      "loss": 0.9694,
      "step": 1600
    },
    {
      "epoch": 0.22,
      "grad_norm": 19.059783935546875,
      "learning_rate": 1e-05,
      "loss": 1.0644,
      "step": 1604
    },
    {
      "epoch": 0.22,
      "grad_norm": 23.322097778320312,
      "learning_rate": 1e-05,
      "loss": 0.8388,
      "step": 1608
    },
    {
      "epoch": 0.22,
      "grad_norm": 18.786720275878906,
      "learning_rate": 1e-05,
      "loss": 0.964,
      "step": 1612
    },
    {
      "epoch": 0.22,
      "grad_norm": 21.567365646362305,
      "learning_rate": 1e-05,
      "loss": 0.7684,
      "step": 1616
    },
    {
      "epoch": 0.22,
      "grad_norm": 30.68625259399414,
      "learning_rate": 1e-05,
      "loss": 1.0626,
      "step": 1620
    },
    {
      "epoch": 0.22,
      "grad_norm": 21.927453994750977,
      "learning_rate": 1e-05,
      "loss": 0.9377,
      "step": 1624
    },
    {
      "epoch": 0.22,
      "grad_norm": 15.661518096923828,
      "learning_rate": 1e-05,
      "loss": 0.8688,
      "step": 1628
    },
    {
      "epoch": 0.22,
      "grad_norm": 21.491199493408203,
      "learning_rate": 1e-05,
      "loss": 1.0336,
      "step": 1632
    },
    {
      "epoch": 0.22,
      "grad_norm": 20.494739532470703,
      "learning_rate": 1e-05,
      "loss": 0.9897,
      "step": 1636
    },
    {
      "epoch": 0.22,
      "grad_norm": 20.258358001708984,
      "learning_rate": 1e-05,
      "loss": 0.8366,
      "step": 1640
    },
    {
      "epoch": 0.22,
      "grad_norm": 24.706857681274414,
      "learning_rate": 1e-05,
      "loss": 0.9427,
      "step": 1644
    },
    {
      "epoch": 0.22,
      "grad_norm": 22.8629207611084,
      "learning_rate": 1e-05,
      "loss": 1.238,
      "step": 1648
    },
    {
      "epoch": 0.22,
      "grad_norm": 16.90089988708496,
      "learning_rate": 1e-05,
      "loss": 0.857,
      "step": 1652
    },
    {
      "epoch": 0.22,
      "grad_norm": 29.43878173828125,
      "learning_rate": 1e-05,
      "loss": 1.0423,
      "step": 1656
    },
    {
      "epoch": 0.22,
      "grad_norm": 22.256988525390625,
      "learning_rate": 1e-05,
      "loss": 0.9936,
      "step": 1660
    },
    {
      "epoch": 0.22,
      "grad_norm": 30.903968811035156,
      "learning_rate": 1e-05,
      "loss": 1.0804,
      "step": 1664
    },
    {
      "epoch": 0.22,
      "grad_norm": 17.84244155883789,
      "learning_rate": 1e-05,
      "loss": 0.9177,
      "step": 1668
    },
    {
      "epoch": 0.22,
      "grad_norm": 22.7952823638916,
      "learning_rate": 1e-05,
      "loss": 1.0234,
      "step": 1672
    },
    {
      "epoch": 0.23,
      "grad_norm": 17.45400047302246,
      "learning_rate": 1e-05,
      "loss": 1.0632,
      "step": 1676
    },
    {
      "epoch": 0.23,
      "grad_norm": 21.261903762817383,
      "learning_rate": 1e-05,
      "loss": 0.9524,
      "step": 1680
    },
    {
      "epoch": 0.23,
      "grad_norm": 9.847095489501953,
      "learning_rate": 1e-05,
      "loss": 0.6211,
      "step": 1684
    },
    {
      "epoch": 0.23,
      "grad_norm": 20.221046447753906,
      "learning_rate": 1e-05,
      "loss": 1.008,
      "step": 1688
    },
    {
      "epoch": 0.23,
      "grad_norm": 19.962804794311523,
      "learning_rate": 1e-05,
      "loss": 1.0758,
      "step": 1692
    },
    {
      "epoch": 0.23,
      "grad_norm": 36.13107681274414,
      "learning_rate": 1e-05,
      "loss": 0.7945,
      "step": 1696
    },
    {
      "epoch": 0.23,
      "grad_norm": 20.167028427124023,
      "learning_rate": 1e-05,
      "loss": 0.8958,
      "step": 1700
    },
    {
      "epoch": 0.23,
      "grad_norm": 17.506343841552734,
      "learning_rate": 1e-05,
      "loss": 0.9279,
      "step": 1704
    },
    {
      "epoch": 0.23,
      "grad_norm": 13.885844230651855,
      "learning_rate": 1e-05,
      "loss": 0.901,
      "step": 1708
    },
    {
      "epoch": 0.23,
      "grad_norm": 22.750843048095703,
      "learning_rate": 1e-05,
      "loss": 0.9718,
      "step": 1712
    },
    {
      "epoch": 0.23,
      "grad_norm": 21.165246963500977,
      "learning_rate": 1e-05,
      "loss": 0.9841,
      "step": 1716
    },
    {
      "epoch": 0.23,
      "grad_norm": 24.713455200195312,
      "learning_rate": 1e-05,
      "loss": 1.0962,
      "step": 1720
    },
    {
      "epoch": 0.23,
      "grad_norm": 19.634525299072266,
      "learning_rate": 1e-05,
      "loss": 0.9471,
      "step": 1724
    },
    {
      "epoch": 0.23,
      "grad_norm": 34.06599044799805,
      "learning_rate": 1e-05,
      "loss": 0.8725,
      "step": 1728
    },
    {
      "epoch": 0.23,
      "grad_norm": 31.84423828125,
      "learning_rate": 1e-05,
      "loss": 1.2944,
      "step": 1732
    },
    {
      "epoch": 0.23,
      "grad_norm": 23.970413208007812,
      "learning_rate": 1e-05,
      "loss": 1.0164,
      "step": 1736
    },
    {
      "epoch": 0.23,
      "grad_norm": 19.446372985839844,
      "learning_rate": 1e-05,
      "loss": 0.975,
      "step": 1740
    },
    {
      "epoch": 0.23,
      "grad_norm": 24.04671859741211,
      "learning_rate": 1e-05,
      "loss": 1.052,
      "step": 1744
    },
    {
      "epoch": 0.23,
      "grad_norm": 16.813302993774414,
      "learning_rate": 1e-05,
      "loss": 0.7032,
      "step": 1748
    },
    {
      "epoch": 0.24,
      "grad_norm": 17.280208587646484,
      "learning_rate": 1e-05,
      "loss": 0.9848,
      "step": 1752
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.83881950378418,
      "learning_rate": 1e-05,
      "loss": 0.8474,
      "step": 1756
    },
    {
      "epoch": 0.24,
      "grad_norm": 19.841073989868164,
      "learning_rate": 1e-05,
      "loss": 1.0545,
      "step": 1760
    },
    {
      "epoch": 0.24,
      "grad_norm": 17.607919692993164,
      "learning_rate": 1e-05,
      "loss": 0.842,
      "step": 1764
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.109554290771484,
      "learning_rate": 1e-05,
      "loss": 0.8362,
      "step": 1768
    },
    {
      "epoch": 0.24,
      "grad_norm": 21.023761749267578,
      "learning_rate": 1e-05,
      "loss": 0.873,
      "step": 1772
    },
    {
      "epoch": 0.24,
      "grad_norm": 23.73086929321289,
      "learning_rate": 1e-05,
      "loss": 0.9369,
      "step": 1776
    },
    {
      "epoch": 0.24,
      "grad_norm": 21.947978973388672,
      "learning_rate": 1e-05,
      "loss": 1.1088,
      "step": 1780
    },
    {
      "epoch": 0.24,
      "grad_norm": 19.437747955322266,
      "learning_rate": 1e-05,
      "loss": 0.9289,
      "step": 1784
    },
    {
      "epoch": 0.24,
      "grad_norm": 14.161412239074707,
      "learning_rate": 1e-05,
      "loss": 0.8504,
      "step": 1788
    },
    {
      "epoch": 0.24,
      "grad_norm": 32.49002456665039,
      "learning_rate": 1e-05,
      "loss": 0.7976,
      "step": 1792
    },
    {
      "epoch": 0.24,
      "grad_norm": 24.459672927856445,
      "learning_rate": 1e-05,
      "loss": 1.3541,
      "step": 1796
    },
    {
      "epoch": 0.24,
      "grad_norm": 24.36571502685547,
      "learning_rate": 1e-05,
      "loss": 0.8534,
      "step": 1800
    },
    {
      "epoch": 0.24,
      "grad_norm": 13.163900375366211,
      "learning_rate": 1e-05,
      "loss": 0.7132,
      "step": 1804
    },
    {
      "epoch": 0.24,
      "grad_norm": 20.72809410095215,
      "learning_rate": 1e-05,
      "loss": 0.9965,
      "step": 1808
    },
    {
      "epoch": 0.24,
      "grad_norm": 19.337865829467773,
      "learning_rate": 1e-05,
      "loss": 0.8861,
      "step": 1812
    },
    {
      "epoch": 0.24,
      "grad_norm": 21.264503479003906,
      "learning_rate": 1e-05,
      "loss": 0.8352,
      "step": 1816
    },
    {
      "epoch": 0.24,
      "grad_norm": 28.32067108154297,
      "learning_rate": 1e-05,
      "loss": 0.9842,
      "step": 1820
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.27020835876465,
      "learning_rate": 1e-05,
      "loss": 0.9634,
      "step": 1824
    },
    {
      "epoch": 0.25,
      "grad_norm": 25.583881378173828,
      "learning_rate": 1e-05,
      "loss": 0.8344,
      "step": 1828
    },
    {
      "epoch": 0.25,
      "grad_norm": 18.372596740722656,
      "learning_rate": 1e-05,
      "loss": 0.864,
      "step": 1832
    },
    {
      "epoch": 0.25,
      "grad_norm": 17.217098236083984,
      "learning_rate": 1e-05,
      "loss": 0.9891,
      "step": 1836
    },
    {
      "epoch": 0.25,
      "grad_norm": 22.59331703186035,
      "learning_rate": 1e-05,
      "loss": 0.9738,
      "step": 1840
    },
    {
      "epoch": 0.25,
      "grad_norm": 19.222530364990234,
      "learning_rate": 1e-05,
      "loss": 0.864,
      "step": 1844
    },
    {
      "epoch": 0.25,
      "grad_norm": 20.146516799926758,
      "learning_rate": 1e-05,
      "loss": 1.0128,
      "step": 1848
    },
    {
      "epoch": 0.25,
      "grad_norm": 23.660310745239258,
      "learning_rate": 1e-05,
      "loss": 1.0927,
      "step": 1852
    },
    {
      "epoch": 0.25,
      "grad_norm": 19.2653865814209,
      "learning_rate": 1e-05,
      "loss": 0.8998,
      "step": 1856
    },
    {
      "epoch": 0.25,
      "grad_norm": 23.503032684326172,
      "learning_rate": 1e-05,
      "loss": 1.0958,
      "step": 1860
    },
    {
      "epoch": 0.25,
      "grad_norm": 18.256351470947266,
      "learning_rate": 1e-05,
      "loss": 0.825,
      "step": 1864
    },
    {
      "epoch": 0.25,
      "grad_norm": 28.924400329589844,
      "learning_rate": 1e-05,
      "loss": 1.1124,
      "step": 1868
    },
    {
      "epoch": 0.25,
      "grad_norm": 20.832115173339844,
      "learning_rate": 1e-05,
      "loss": 1.0108,
      "step": 1872
    },
    {
      "epoch": 0.25,
      "grad_norm": 26.002426147460938,
      "learning_rate": 1e-05,
      "loss": 0.8252,
      "step": 1876
    },
    {
      "epoch": 0.25,
      "grad_norm": 29.005783081054688,
      "learning_rate": 1e-05,
      "loss": 0.9745,
      "step": 1880
    },
    {
      "epoch": 0.25,
      "grad_norm": 30.472637176513672,
      "learning_rate": 1e-05,
      "loss": 1.0008,
      "step": 1884
    },
    {
      "epoch": 0.25,
      "grad_norm": 15.739377975463867,
      "learning_rate": 1e-05,
      "loss": 0.9044,
      "step": 1888
    },
    {
      "epoch": 0.25,
      "grad_norm": 22.587398529052734,
      "learning_rate": 1e-05,
      "loss": 0.9194,
      "step": 1892
    },
    {
      "epoch": 0.25,
      "grad_norm": 23.536209106445312,
      "learning_rate": 1e-05,
      "loss": 0.8445,
      "step": 1896
    },
    {
      "epoch": 0.26,
      "grad_norm": 23.21121597290039,
      "learning_rate": 1e-05,
      "loss": 0.9053,
      "step": 1900
    },
    {
      "epoch": 0.26,
      "grad_norm": 19.59584617614746,
      "learning_rate": 1e-05,
      "loss": 0.9265,
      "step": 1904
    },
    {
      "epoch": 0.26,
      "grad_norm": 25.719982147216797,
      "learning_rate": 1e-05,
      "loss": 0.8587,
      "step": 1908
    },
    {
      "epoch": 0.26,
      "grad_norm": 21.35885238647461,
      "learning_rate": 1e-05,
      "loss": 1.065,
      "step": 1912
    },
    {
      "epoch": 0.26,
      "grad_norm": 14.365291595458984,
      "learning_rate": 1e-05,
      "loss": 1.1441,
      "step": 1916
    },
    {
      "epoch": 0.26,
      "grad_norm": 16.311790466308594,
      "learning_rate": 1e-05,
      "loss": 0.9551,
      "step": 1920
    },
    {
      "epoch": 0.26,
      "grad_norm": 18.266708374023438,
      "learning_rate": 1e-05,
      "loss": 0.9435,
      "step": 1924
    },
    {
      "epoch": 0.26,
      "grad_norm": 21.220428466796875,
      "learning_rate": 1e-05,
      "loss": 0.9422,
      "step": 1928
    },
    {
      "epoch": 0.26,
      "grad_norm": 18.23360824584961,
      "learning_rate": 1e-05,
      "loss": 1.0892,
      "step": 1932
    },
    {
      "epoch": 0.26,
      "grad_norm": 19.684919357299805,
      "learning_rate": 1e-05,
      "loss": 0.9782,
      "step": 1936
    },
    {
      "epoch": 0.26,
      "grad_norm": 14.06842041015625,
      "learning_rate": 1e-05,
      "loss": 0.9295,
      "step": 1940
    },
    {
      "epoch": 0.26,
      "grad_norm": 17.796789169311523,
      "learning_rate": 1e-05,
      "loss": 0.9828,
      "step": 1944
    },
    {
      "epoch": 0.26,
      "grad_norm": 26.137916564941406,
      "learning_rate": 1e-05,
      "loss": 1.4082,
      "step": 1948
    },
    {
      "epoch": 0.26,
      "grad_norm": 17.146038055419922,
      "learning_rate": 1e-05,
      "loss": 0.7264,
      "step": 1952
    },
    {
      "epoch": 0.26,
      "grad_norm": 20.731731414794922,
      "learning_rate": 1e-05,
      "loss": 0.8615,
      "step": 1956
    },
    {
      "epoch": 0.26,
      "grad_norm": 14.59730052947998,
      "learning_rate": 1e-05,
      "loss": 0.6527,
      "step": 1960
    },
    {
      "epoch": 0.26,
      "grad_norm": 21.434389114379883,
      "learning_rate": 1e-05,
      "loss": 1.0258,
      "step": 1964
    },
    {
      "epoch": 0.26,
      "grad_norm": 17.24410057067871,
      "learning_rate": 1e-05,
      "loss": 0.9515,
      "step": 1968
    },
    {
      "epoch": 0.26,
      "grad_norm": 16.066190719604492,
      "learning_rate": 1e-05,
      "loss": 1.0629,
      "step": 1972
    },
    {
      "epoch": 0.27,
      "grad_norm": 16.820720672607422,
      "learning_rate": 1e-05,
      "loss": 0.9497,
      "step": 1976
    },
    {
      "epoch": 0.27,
      "grad_norm": 24.08562660217285,
      "learning_rate": 1e-05,
      "loss": 0.9532,
      "step": 1980
    },
    {
      "epoch": 0.27,
      "grad_norm": 23.801929473876953,
      "learning_rate": 1e-05,
      "loss": 1.1569,
      "step": 1984
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.97475814819336,
      "learning_rate": 1e-05,
      "loss": 1.149,
      "step": 1988
    },
    {
      "epoch": 0.27,
      "grad_norm": 24.847463607788086,
      "learning_rate": 1e-05,
      "loss": 0.8942,
      "step": 1992
    },
    {
      "epoch": 0.27,
      "grad_norm": 24.576852798461914,
      "learning_rate": 1e-05,
      "loss": 1.1851,
      "step": 1996
    },
    {
      "epoch": 0.27,
      "grad_norm": 23.452560424804688,
      "learning_rate": 1e-05,
      "loss": 0.9754,
      "step": 2000
    },
    {
      "epoch": 0.27,
      "grad_norm": 33.814544677734375,
      "learning_rate": 1e-05,
      "loss": 1.1787,
      "step": 2004
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.34027099609375,
      "learning_rate": 1e-05,
      "loss": 1.1246,
      "step": 2008
    },
    {
      "epoch": 0.27,
      "grad_norm": 19.703126907348633,
      "learning_rate": 1e-05,
      "loss": 1.0031,
      "step": 2012
    },
    {
      "epoch": 0.27,
      "grad_norm": 21.315168380737305,
      "learning_rate": 1e-05,
      "loss": 0.7877,
      "step": 2016
    },
    {
      "epoch": 0.27,
      "grad_norm": 13.864025115966797,
      "learning_rate": 1e-05,
      "loss": 0.9282,
      "step": 2020
    },
    {
      "epoch": 0.27,
      "grad_norm": 25.128664016723633,
      "learning_rate": 1e-05,
      "loss": 1.0212,
      "step": 2024
    },
    {
      "epoch": 0.27,
      "grad_norm": 25.66289520263672,
      "learning_rate": 1e-05,
      "loss": 1.0384,
      "step": 2028
    },
    {
      "epoch": 0.27,
      "grad_norm": 15.932938575744629,
      "learning_rate": 1e-05,
      "loss": 1.0716,
      "step": 2032
    },
    {
      "epoch": 0.27,
      "grad_norm": 21.353546142578125,
      "learning_rate": 1e-05,
      "loss": 1.1414,
      "step": 2036
    },
    {
      "epoch": 0.27,
      "grad_norm": 20.19152069091797,
      "learning_rate": 1e-05,
      "loss": 0.8088,
      "step": 2040
    },
    {
      "epoch": 0.27,
      "grad_norm": 17.013553619384766,
      "learning_rate": 1e-05,
      "loss": 0.9345,
      "step": 2044
    },
    {
      "epoch": 0.27,
      "grad_norm": 16.817222595214844,
      "learning_rate": 1e-05,
      "loss": 1.0905,
      "step": 2048
    },
    {
      "epoch": 0.28,
      "grad_norm": 26.128841400146484,
      "learning_rate": 1e-05,
      "loss": 1.0712,
      "step": 2052
    },
    {
      "epoch": 0.28,
      "grad_norm": 18.076412200927734,
      "learning_rate": 1e-05,
      "loss": 0.9151,
      "step": 2056
    },
    {
      "epoch": 0.28,
      "grad_norm": 24.79118537902832,
      "learning_rate": 1e-05,
      "loss": 0.9176,
      "step": 2060
    },
    {
      "epoch": 0.28,
      "grad_norm": 21.0474796295166,
      "learning_rate": 1e-05,
      "loss": 0.911,
      "step": 2064
    },
    {
      "epoch": 0.28,
      "grad_norm": 17.76947593688965,
      "learning_rate": 1e-05,
      "loss": 0.9672,
      "step": 2068
    },
    {
      "epoch": 0.28,
      "grad_norm": 19.812007904052734,
      "learning_rate": 1e-05,
      "loss": 0.9274,
      "step": 2072
    },
    {
      "epoch": 0.28,
      "grad_norm": 21.93606185913086,
      "learning_rate": 1e-05,
      "loss": 1.0383,
      "step": 2076
    },
    {
      "epoch": 0.28,
      "grad_norm": 25.22828483581543,
      "learning_rate": 1e-05,
      "loss": 1.0546,
      "step": 2080
    },
    {
      "epoch": 0.28,
      "grad_norm": 27.723098754882812,
      "learning_rate": 1e-05,
      "loss": 1.2154,
      "step": 2084
    },
    {
      "epoch": 0.28,
      "grad_norm": 14.079179763793945,
      "learning_rate": 1e-05,
      "loss": 0.834,
      "step": 2088
    },
    {
      "epoch": 0.28,
      "grad_norm": 18.098257064819336,
      "learning_rate": 1e-05,
      "loss": 0.6557,
      "step": 2092
    },
    {
      "epoch": 0.28,
      "grad_norm": 12.013206481933594,
      "learning_rate": 1e-05,
      "loss": 0.9037,
      "step": 2096
    },
    {
      "epoch": 0.28,
      "grad_norm": 30.599227905273438,
      "learning_rate": 1e-05,
      "loss": 0.9214,
      "step": 2100
    },
    {
      "epoch": 0.28,
      "grad_norm": 22.988283157348633,
      "learning_rate": 1e-05,
      "loss": 0.8626,
      "step": 2104
    },
    {
      "epoch": 0.28,
      "grad_norm": 18.19049835205078,
      "learning_rate": 1e-05,
      "loss": 0.7279,
      "step": 2108
    },
    {
      "epoch": 0.28,
      "grad_norm": 27.084789276123047,
      "learning_rate": 1e-05,
      "loss": 0.9266,
      "step": 2112
    },
    {
      "epoch": 0.28,
      "grad_norm": 20.70099449157715,
      "learning_rate": 1e-05,
      "loss": 0.8801,
      "step": 2116
    },
    {
      "epoch": 0.28,
      "grad_norm": 21.982999801635742,
      "learning_rate": 1e-05,
      "loss": 0.9481,
      "step": 2120
    },
    {
      "epoch": 0.29,
      "grad_norm": 21.023347854614258,
      "learning_rate": 1e-05,
      "loss": 0.85,
      "step": 2124
    },
    {
      "epoch": 0.29,
      "grad_norm": 15.310572624206543,
      "learning_rate": 1e-05,
      "loss": 0.9721,
      "step": 2128
    },
    {
      "epoch": 0.29,
      "grad_norm": 18.789966583251953,
      "learning_rate": 1e-05,
      "loss": 0.7859,
      "step": 2132
    },
    {
      "epoch": 0.29,
      "grad_norm": 25.331432342529297,
      "learning_rate": 1e-05,
      "loss": 0.9226,
      "step": 2136
    },
    {
      "epoch": 0.29,
      "grad_norm": 20.674352645874023,
      "learning_rate": 1e-05,
      "loss": 0.9396,
      "step": 2140
    },
    {
      "epoch": 0.29,
      "grad_norm": 21.03912925720215,
      "learning_rate": 1e-05,
      "loss": 0.868,
      "step": 2144
    },
    {
      "epoch": 0.29,
      "grad_norm": 19.118640899658203,
      "learning_rate": 1e-05,
      "loss": 0.8981,
      "step": 2148
    },
    {
      "epoch": 0.29,
      "grad_norm": 15.998241424560547,
      "learning_rate": 1e-05,
      "loss": 0.7298,
      "step": 2152
    },
    {
      "epoch": 0.29,
      "grad_norm": 23.668861389160156,
      "learning_rate": 1e-05,
      "loss": 0.7506,
      "step": 2156
    },
    {
      "epoch": 0.29,
      "grad_norm": 26.69963264465332,
      "learning_rate": 1e-05,
      "loss": 0.7281,
      "step": 2160
    },
    {
      "epoch": 0.29,
      "grad_norm": 19.798032760620117,
      "learning_rate": 1e-05,
      "loss": 0.9527,
      "step": 2164
    },
    {
      "epoch": 0.29,
      "grad_norm": 15.241969108581543,
      "learning_rate": 1e-05,
      "loss": 1.0011,
      "step": 2168
    },
    {
      "epoch": 0.29,
      "grad_norm": 21.887439727783203,
      "learning_rate": 1e-05,
      "loss": 0.7676,
      "step": 2172
    },
    {
      "epoch": 0.29,
      "grad_norm": 30.54047966003418,
      "learning_rate": 1e-05,
      "loss": 0.8423,
      "step": 2176
    },
    {
      "epoch": 0.29,
      "grad_norm": 29.026180267333984,
      "learning_rate": 1e-05,
      "loss": 1.045,
      "step": 2180
    },
    {
      "epoch": 0.29,
      "grad_norm": 17.970603942871094,
      "learning_rate": 1e-05,
      "loss": 0.9087,
      "step": 2184
    },
    {
      "epoch": 0.29,
      "grad_norm": 21.20473861694336,
      "learning_rate": 1e-05,
      "loss": 0.8709,
      "step": 2188
    },
    {
      "epoch": 0.29,
      "grad_norm": 20.031269073486328,
      "learning_rate": 1e-05,
      "loss": 1.0017,
      "step": 2192
    },
    {
      "epoch": 0.29,
      "grad_norm": 25.17888641357422,
      "learning_rate": 1e-05,
      "loss": 0.9131,
      "step": 2196
    },
    {
      "epoch": 0.3,
      "grad_norm": 20.244009017944336,
      "learning_rate": 1e-05,
      "loss": 1.0586,
      "step": 2200
    },
    {
      "epoch": 0.3,
      "grad_norm": 20.933963775634766,
      "learning_rate": 1e-05,
      "loss": 0.9596,
      "step": 2204
    },
    {
      "epoch": 0.3,
      "grad_norm": 13.155840873718262,
      "learning_rate": 1e-05,
      "loss": 0.7321,
      "step": 2208
    },
    {
      "epoch": 0.3,
      "grad_norm": 16.8696231842041,
      "learning_rate": 1e-05,
      "loss": 0.5731,
      "step": 2212
    },
    {
      "epoch": 0.3,
      "grad_norm": 17.156661987304688,
      "learning_rate": 1e-05,
      "loss": 0.8285,
      "step": 2216
    },
    {
      "epoch": 0.3,
      "grad_norm": 26.148160934448242,
      "learning_rate": 1e-05,
      "loss": 0.8763,
      "step": 2220
    },
    {
      "epoch": 0.3,
      "grad_norm": 19.766300201416016,
      "learning_rate": 1e-05,
      "loss": 0.8969,
      "step": 2224
    },
    {
      "epoch": 0.3,
      "grad_norm": 22.950651168823242,
      "learning_rate": 1e-05,
      "loss": 1.0277,
      "step": 2228
    },
    {
      "epoch": 0.3,
      "grad_norm": 20.673337936401367,
      "learning_rate": 1e-05,
      "loss": 1.0078,
      "step": 2232
    },
    {
      "epoch": 0.3,
      "eval_accuracy": 0.6631536550983419,
      "eval_f1": 0.6625094800787809,
      "eval_loss": 0.9257639646530151,
      "eval_precision": 0.665486837811067,
      "eval_recall": 0.6631536550983419,
      "eval_runtime": 1689.86,
      "eval_samples_per_second": 8.816,
      "eval_steps_per_second": 1.102,
      "step": 2232
    },
    {
      "epoch": 0.3,
      "grad_norm": 18.484342575073242,
      "learning_rate": 1e-05,
      "loss": 0.7385,
      "step": 2236
    },
    {
      "epoch": 0.3,
      "grad_norm": 23.60410499572754,
      "learning_rate": 1e-05,
      "loss": 1.0223,
      "step": 2240
    },
    {
      "epoch": 0.3,
      "grad_norm": 20.223176956176758,
      "learning_rate": 1e-05,
      "loss": 1.0659,
      "step": 2244
    },
    {
      "epoch": 0.3,
      "grad_norm": 38.133018493652344,
      "learning_rate": 1e-05,
      "loss": 1.1177,
      "step": 2248
    },
    {
      "epoch": 0.3,
      "grad_norm": 16.36490249633789,
      "learning_rate": 1e-05,
      "loss": 0.9873,
      "step": 2252
    },
    {
      "epoch": 0.3,
      "grad_norm": 24.964847564697266,
      "learning_rate": 1e-05,
      "loss": 0.9117,
      "step": 2256
    },
    {
      "epoch": 0.3,
      "grad_norm": 21.62067985534668,
      "learning_rate": 1e-05,
      "loss": 0.9906,
      "step": 2260
    },
    {
      "epoch": 0.3,
      "grad_norm": 25.179540634155273,
      "learning_rate": 1e-05,
      "loss": 0.9664,
      "step": 2264
    },
    {
      "epoch": 0.3,
      "grad_norm": 23.996971130371094,
      "learning_rate": 1e-05,
      "loss": 0.93,
      "step": 2268
    },
    {
      "epoch": 0.31,
      "grad_norm": 22.38333511352539,
      "learning_rate": 1e-05,
      "loss": 0.943,
      "step": 2272
    },
    {
      "epoch": 0.31,
      "grad_norm": 37.548309326171875,
      "learning_rate": 1e-05,
      "loss": 1.1286,
      "step": 2276
    },
    {
      "epoch": 0.31,
      "grad_norm": 22.442182540893555,
      "learning_rate": 1e-05,
      "loss": 0.6882,
      "step": 2280
    },
    {
      "epoch": 0.31,
      "grad_norm": 20.953449249267578,
      "learning_rate": 1e-05,
      "loss": 0.8074,
      "step": 2284
    },
    {
      "epoch": 0.31,
      "grad_norm": 28.50312614440918,
      "learning_rate": 1e-05,
      "loss": 1.038,
      "step": 2288
    },
    {
      "epoch": 0.31,
      "grad_norm": 20.432632446289062,
      "learning_rate": 1e-05,
      "loss": 0.9484,
      "step": 2292
    },
    {
      "epoch": 0.31,
      "grad_norm": 22.967937469482422,
      "learning_rate": 1e-05,
      "loss": 0.9594,
      "step": 2296
    },
    {
      "epoch": 0.31,
      "grad_norm": 18.217697143554688,
      "learning_rate": 1e-05,
      "loss": 1.1418,
      "step": 2300
    },
    {
      "epoch": 0.31,
      "grad_norm": 20.35382080078125,
      "learning_rate": 1e-05,
      "loss": 1.2083,
      "step": 2304
    },
    {
      "epoch": 0.31,
      "grad_norm": 20.528852462768555,
      "learning_rate": 1e-05,
      "loss": 0.9492,
      "step": 2308
    },
    {
      "epoch": 0.31,
      "grad_norm": 17.404512405395508,
      "learning_rate": 1e-05,
      "loss": 1.0076,
      "step": 2312
    },
    {
      "epoch": 0.31,
      "grad_norm": 19.151119232177734,
      "learning_rate": 1e-05,
      "loss": 1.0259,
      "step": 2316
    },
    {
      "epoch": 0.31,
      "grad_norm": 46.5679931640625,
      "learning_rate": 1e-05,
      "loss": 1.2405,
      "step": 2320
    },
    {
      "epoch": 0.31,
      "grad_norm": 23.921894073486328,
      "learning_rate": 1e-05,
      "loss": 0.9975,
      "step": 2324
    },
    {
      "epoch": 0.31,
      "grad_norm": 22.92255973815918,
      "learning_rate": 1e-05,
      "loss": 0.6326,
      "step": 2328
    },
    {
      "epoch": 0.31,
      "grad_norm": 15.119423866271973,
      "learning_rate": 1e-05,
      "loss": 0.8882,
      "step": 2332
    },
    {
      "epoch": 0.31,
      "grad_norm": 21.69342041015625,
      "learning_rate": 1e-05,
      "loss": 0.9797,
      "step": 2336
    },
    {
      "epoch": 0.31,
      "grad_norm": 22.618070602416992,
      "learning_rate": 1e-05,
      "loss": 0.8955,
      "step": 2340
    },
    {
      "epoch": 0.31,
      "grad_norm": 23.31702995300293,
      "learning_rate": 1e-05,
      "loss": 0.8032,
      "step": 2344
    },
    {
      "epoch": 0.32,
      "grad_norm": 18.998607635498047,
      "learning_rate": 1e-05,
      "loss": 0.8504,
      "step": 2348
    },
    {
      "epoch": 0.32,
      "grad_norm": 18.37929916381836,
      "learning_rate": 1e-05,
      "loss": 0.9643,
      "step": 2352
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.392017364501953,
      "learning_rate": 1e-05,
      "loss": 0.8157,
      "step": 2356
    },
    {
      "epoch": 0.32,
      "grad_norm": 22.469667434692383,
      "learning_rate": 1e-05,
      "loss": 0.9835,
      "step": 2360
    },
    {
      "epoch": 0.32,
      "grad_norm": 28.666284561157227,
      "learning_rate": 1e-05,
      "loss": 0.9059,
      "step": 2364
    },
    {
      "epoch": 0.32,
      "grad_norm": 20.971837997436523,
      "learning_rate": 1e-05,
      "loss": 0.8491,
      "step": 2368
    },
    {
      "epoch": 0.32,
      "grad_norm": 17.059232711791992,
      "learning_rate": 1e-05,
      "loss": 0.8285,
      "step": 2372
    },
    {
      "epoch": 0.32,
      "grad_norm": 20.76141929626465,
      "learning_rate": 1e-05,
      "loss": 0.7875,
      "step": 2376
    },
    {
      "epoch": 0.32,
      "grad_norm": 28.640199661254883,
      "learning_rate": 1e-05,
      "loss": 1.045,
      "step": 2380
    },
    {
      "epoch": 0.32,
      "grad_norm": 15.978851318359375,
      "learning_rate": 1e-05,
      "loss": 1.0258,
      "step": 2384
    },
    {
      "epoch": 0.32,
      "grad_norm": 14.10272216796875,
      "learning_rate": 1e-05,
      "loss": 1.0237,
      "step": 2388
    },
    {
      "epoch": 0.32,
      "grad_norm": 17.789194107055664,
      "learning_rate": 1e-05,
      "loss": 1.0971,
      "step": 2392
    },
    {
      "epoch": 0.32,
      "grad_norm": 18.804981231689453,
      "learning_rate": 1e-05,
      "loss": 0.8827,
      "step": 2396
    },
    {
      "epoch": 0.32,
      "grad_norm": 22.037128448486328,
      "learning_rate": 1e-05,
      "loss": 1.0162,
      "step": 2400
    },
    {
      "epoch": 0.32,
      "grad_norm": 23.715412139892578,
      "learning_rate": 1e-05,
      "loss": 0.8486,
      "step": 2404
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.910602569580078,
      "learning_rate": 1e-05,
      "loss": 0.7631,
      "step": 2408
    },
    {
      "epoch": 0.32,
      "grad_norm": 23.939382553100586,
      "learning_rate": 1e-05,
      "loss": 1.024,
      "step": 2412
    },
    {
      "epoch": 0.32,
      "grad_norm": 27.61549186706543,
      "learning_rate": 1e-05,
      "loss": 0.939,
      "step": 2416
    },
    {
      "epoch": 0.32,
      "grad_norm": 17.596630096435547,
      "learning_rate": 1e-05,
      "loss": 0.7859,
      "step": 2420
    },
    {
      "epoch": 0.33,
      "grad_norm": 15.922355651855469,
      "learning_rate": 1e-05,
      "loss": 0.9845,
      "step": 2424
    },
    {
      "epoch": 0.33,
      "grad_norm": 17.303733825683594,
      "learning_rate": 1e-05,
      "loss": 1.1297,
      "step": 2428
    },
    {
      "epoch": 0.33,
      "grad_norm": 14.225815773010254,
      "learning_rate": 1e-05,
      "loss": 0.7508,
      "step": 2432
    },
    {
      "epoch": 0.33,
      "grad_norm": 27.998144149780273,
      "learning_rate": 1e-05,
      "loss": 0.8167,
      "step": 2436
    },
    {
      "epoch": 0.33,
      "grad_norm": 34.216064453125,
      "learning_rate": 1e-05,
      "loss": 0.8975,
      "step": 2440
    },
    {
      "epoch": 0.33,
      "grad_norm": 21.875551223754883,
      "learning_rate": 1e-05,
      "loss": 1.1487,
      "step": 2444
    },
    {
      "epoch": 0.33,
      "grad_norm": 15.131558418273926,
      "learning_rate": 1e-05,
      "loss": 0.9712,
      "step": 2448
    },
    {
      "epoch": 0.33,
      "grad_norm": 19.73700523376465,
      "learning_rate": 1e-05,
      "loss": 0.8286,
      "step": 2452
    },
    {
      "epoch": 0.33,
      "grad_norm": 15.448335647583008,
      "learning_rate": 1e-05,
      "loss": 0.8473,
      "step": 2456
    },
    {
      "epoch": 0.33,
      "grad_norm": 23.812448501586914,
      "learning_rate": 1e-05,
      "loss": 1.1008,
      "step": 2460
    },
    {
      "epoch": 0.33,
      "grad_norm": 26.806886672973633,
      "learning_rate": 1e-05,
      "loss": 0.9121,
      "step": 2464
    },
    {
      "epoch": 0.33,
      "grad_norm": 13.962514877319336,
      "learning_rate": 1e-05,
      "loss": 0.8615,
      "step": 2468
    },
    {
      "epoch": 0.33,
      "grad_norm": 16.97904396057129,
      "learning_rate": 1e-05,
      "loss": 0.9633,
      "step": 2472
    },
    {
      "epoch": 0.33,
      "grad_norm": 14.851226806640625,
      "learning_rate": 1e-05,
      "loss": 0.8859,
      "step": 2476
    },
    {
      "epoch": 0.33,
      "grad_norm": 16.966821670532227,
      "learning_rate": 1e-05,
      "loss": 0.9683,
      "step": 2480
    },
    {
      "epoch": 0.33,
      "grad_norm": 19.8022403717041,
      "learning_rate": 1e-05,
      "loss": 0.8788,
      "step": 2484
    },
    {
      "epoch": 0.33,
      "grad_norm": 34.14936065673828,
      "learning_rate": 1e-05,
      "loss": 1.1655,
      "step": 2488
    },
    {
      "epoch": 0.33,
      "grad_norm": 13.721755027770996,
      "learning_rate": 1e-05,
      "loss": 0.7852,
      "step": 2492
    },
    {
      "epoch": 0.34,
      "grad_norm": 15.666915893554688,
      "learning_rate": 1e-05,
      "loss": 0.9546,
      "step": 2496
    },
    {
      "epoch": 0.34,
      "grad_norm": 21.12312889099121,
      "learning_rate": 1e-05,
      "loss": 0.94,
      "step": 2500
    },
    {
      "epoch": 0.34,
      "grad_norm": 18.006004333496094,
      "learning_rate": 1e-05,
      "loss": 0.829,
      "step": 2504
    },
    {
      "epoch": 0.34,
      "grad_norm": 19.777828216552734,
      "learning_rate": 1e-05,
      "loss": 1.0102,
      "step": 2508
    },
    {
      "epoch": 0.34,
      "grad_norm": 25.149526596069336,
      "learning_rate": 1e-05,
      "loss": 1.0168,
      "step": 2512
    },
    {
      "epoch": 0.34,
      "grad_norm": 17.47084617614746,
      "learning_rate": 1e-05,
      "loss": 0.9613,
      "step": 2516
    },
    {
      "epoch": 0.34,
      "grad_norm": 21.40131187438965,
      "learning_rate": 1e-05,
      "loss": 0.8733,
      "step": 2520
    },
    {
      "epoch": 0.34,
      "grad_norm": 20.6682071685791,
      "learning_rate": 1e-05,
      "loss": 0.8316,
      "step": 2524
    },
    {
      "epoch": 0.34,
      "grad_norm": 24.35207176208496,
      "learning_rate": 1e-05,
      "loss": 0.7549,
      "step": 2528
    },
    {
      "epoch": 0.34,
      "grad_norm": 17.64505958557129,
      "learning_rate": 1e-05,
      "loss": 0.8869,
      "step": 2532
    },
    {
      "epoch": 0.34,
      "grad_norm": 20.967571258544922,
      "learning_rate": 1e-05,
      "loss": 1.003,
      "step": 2536
    },
    {
      "epoch": 0.34,
      "grad_norm": 24.93334197998047,
      "learning_rate": 1e-05,
      "loss": 0.8489,
      "step": 2540
    },
    {
      "epoch": 0.34,
      "grad_norm": 16.17279624938965,
      "learning_rate": 1e-05,
      "loss": 1.1784,
      "step": 2544
    },
    {
      "epoch": 0.34,
      "grad_norm": 23.602685928344727,
      "learning_rate": 1e-05,
      "loss": 1.0803,
      "step": 2548
    },
    {
      "epoch": 0.34,
      "grad_norm": 20.87057876586914,
      "learning_rate": 1e-05,
      "loss": 0.7781,
      "step": 2552
    },
    {
      "epoch": 0.34,
      "grad_norm": 25.654621124267578,
      "learning_rate": 1e-05,
      "loss": 0.7442,
      "step": 2556
    },
    {
      "epoch": 0.34,
      "grad_norm": 20.926801681518555,
      "learning_rate": 1e-05,
      "loss": 1.0367,
      "step": 2560
    },
    {
      "epoch": 0.34,
      "grad_norm": 22.69764518737793,
      "learning_rate": 1e-05,
      "loss": 1.2409,
      "step": 2564
    },
    {
      "epoch": 0.34,
      "grad_norm": 20.130525588989258,
      "learning_rate": 1e-05,
      "loss": 1.0527,
      "step": 2568
    },
    {
      "epoch": 0.35,
      "grad_norm": 30.054027557373047,
      "learning_rate": 1e-05,
      "loss": 0.84,
      "step": 2572
    },
    {
      "epoch": 0.35,
      "grad_norm": 13.627511978149414,
      "learning_rate": 1e-05,
      "loss": 0.8618,
      "step": 2576
    },
    {
      "epoch": 0.35,
      "grad_norm": 34.1095085144043,
      "learning_rate": 1e-05,
      "loss": 1.197,
      "step": 2580
    },
    {
      "epoch": 0.35,
      "grad_norm": 19.546655654907227,
      "learning_rate": 1e-05,
      "loss": 1.0088,
      "step": 2584
    },
    {
      "epoch": 0.35,
      "grad_norm": 24.57735252380371,
      "learning_rate": 1e-05,
      "loss": 1.2323,
      "step": 2588
    },
    {
      "epoch": 0.35,
      "grad_norm": 21.37978172302246,
      "learning_rate": 1e-05,
      "loss": 0.8484,
      "step": 2592
    },
    {
      "epoch": 0.35,
      "grad_norm": 14.832451820373535,
      "learning_rate": 1e-05,
      "loss": 0.9443,
      "step": 2596
    },
    {
      "epoch": 0.35,
      "grad_norm": 24.305204391479492,
      "learning_rate": 1e-05,
      "loss": 0.8218,
      "step": 2600
    },
    {
      "epoch": 0.35,
      "grad_norm": 27.224605560302734,
      "learning_rate": 1e-05,
      "loss": 1.2712,
      "step": 2604
    },
    {
      "epoch": 0.35,
      "grad_norm": 22.869585037231445,
      "learning_rate": 1e-05,
      "loss": 1.101,
      "step": 2608
    },
    {
      "epoch": 0.35,
      "grad_norm": 18.039438247680664,
      "learning_rate": 1e-05,
      "loss": 0.8668,
      "step": 2612
    },
    {
      "epoch": 0.35,
      "grad_norm": 15.049752235412598,
      "learning_rate": 1e-05,
      "loss": 0.8641,
      "step": 2616
    },
    {
      "epoch": 0.35,
      "grad_norm": 26.56456756591797,
      "learning_rate": 1e-05,
      "loss": 0.9616,
      "step": 2620
    },
    {
      "epoch": 0.35,
      "grad_norm": 21.889699935913086,
      "learning_rate": 1e-05,
      "loss": 1.0557,
      "step": 2624
    },
    {
      "epoch": 0.35,
      "grad_norm": 18.005634307861328,
      "learning_rate": 1e-05,
      "loss": 0.9085,
      "step": 2628
    },
    {
      "epoch": 0.35,
      "grad_norm": 15.222882270812988,
      "learning_rate": 1e-05,
      "loss": 0.666,
      "step": 2632
    },
    {
      "epoch": 0.35,
      "grad_norm": 18.929880142211914,
      "learning_rate": 1e-05,
      "loss": 0.812,
      "step": 2636
    },
    {
      "epoch": 0.35,
      "grad_norm": 20.254419326782227,
      "learning_rate": 1e-05,
      "loss": 1.012,
      "step": 2640
    },
    {
      "epoch": 0.36,
      "grad_norm": 28.447107315063477,
      "learning_rate": 1e-05,
      "loss": 1.0776,
      "step": 2644
    },
    {
      "epoch": 0.36,
      "grad_norm": 16.877470016479492,
      "learning_rate": 1e-05,
      "loss": 0.6993,
      "step": 2648
    },
    {
      "epoch": 0.36,
      "grad_norm": 21.787717819213867,
      "learning_rate": 1e-05,
      "loss": 1.1258,
      "step": 2652
    },
    {
      "epoch": 0.36,
      "grad_norm": 13.508976936340332,
      "learning_rate": 1e-05,
      "loss": 0.9283,
      "step": 2656
    },
    {
      "epoch": 0.36,
      "grad_norm": 23.508543014526367,
      "learning_rate": 1e-05,
      "loss": 0.9257,
      "step": 2660
    },
    {
      "epoch": 0.36,
      "grad_norm": 16.22412109375,
      "learning_rate": 1e-05,
      "loss": 0.8134,
      "step": 2664
    },
    {
      "epoch": 0.36,
      "grad_norm": 26.084020614624023,
      "learning_rate": 1e-05,
      "loss": 1.0821,
      "step": 2668
    },
    {
      "epoch": 0.36,
      "grad_norm": 24.301692962646484,
      "learning_rate": 1e-05,
      "loss": 0.9047,
      "step": 2672
    },
    {
      "epoch": 0.36,
      "grad_norm": 27.616968154907227,
      "learning_rate": 1e-05,
      "loss": 0.7997,
      "step": 2676
    },
    {
      "epoch": 0.36,
      "grad_norm": 19.33796501159668,
      "learning_rate": 1e-05,
      "loss": 1.0022,
      "step": 2680
    },
    {
      "epoch": 0.36,
      "grad_norm": 24.462251663208008,
      "learning_rate": 1e-05,
      "loss": 0.9076,
      "step": 2684
    },
    {
      "epoch": 0.36,
      "grad_norm": 18.392126083374023,
      "learning_rate": 1e-05,
      "loss": 1.0493,
      "step": 2688
    },
    {
      "epoch": 0.36,
      "grad_norm": 20.246801376342773,
      "learning_rate": 1e-05,
      "loss": 0.838,
      "step": 2692
    },
    {
      "epoch": 0.36,
      "grad_norm": 20.05767250061035,
      "learning_rate": 1e-05,
      "loss": 1.0441,
      "step": 2696
    },
    {
      "epoch": 0.36,
      "grad_norm": 20.961017608642578,
      "learning_rate": 1e-05,
      "loss": 1.1324,
      "step": 2700
    },
    {
      "epoch": 0.36,
      "grad_norm": 17.025005340576172,
      "learning_rate": 1e-05,
      "loss": 0.9807,
      "step": 2704
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.251062393188477,
      "learning_rate": 1e-05,
      "loss": 0.8145,
      "step": 2708
    },
    {
      "epoch": 0.36,
      "grad_norm": 14.513505935668945,
      "learning_rate": 1e-05,
      "loss": 0.898,
      "step": 2712
    },
    {
      "epoch": 0.36,
      "grad_norm": 29.472326278686523,
      "learning_rate": 1e-05,
      "loss": 1.1856,
      "step": 2716
    },
    {
      "epoch": 0.37,
      "grad_norm": 20.637439727783203,
      "learning_rate": 1e-05,
      "loss": 0.9072,
      "step": 2720
    },
    {
      "epoch": 0.37,
      "grad_norm": 23.51711082458496,
      "learning_rate": 1e-05,
      "loss": 0.8274,
      "step": 2724
    },
    {
      "epoch": 0.37,
      "grad_norm": 22.20650863647461,
      "learning_rate": 1e-05,
      "loss": 0.7178,
      "step": 2728
    },
    {
      "epoch": 0.37,
      "grad_norm": 19.446611404418945,
      "learning_rate": 1e-05,
      "loss": 0.8214,
      "step": 2732
    },
    {
      "epoch": 0.37,
      "grad_norm": 12.783249855041504,
      "learning_rate": 1e-05,
      "loss": 0.6895,
      "step": 2736
    },
    {
      "epoch": 0.37,
      "grad_norm": 22.83881950378418,
      "learning_rate": 1e-05,
      "loss": 0.9482,
      "step": 2740
    },
    {
      "epoch": 0.37,
      "grad_norm": 29.381168365478516,
      "learning_rate": 1e-05,
      "loss": 1.1281,
      "step": 2744
    },
    {
      "epoch": 0.37,
      "grad_norm": 39.56114196777344,
      "learning_rate": 1e-05,
      "loss": 1.065,
      "step": 2748
    },
    {
      "epoch": 0.37,
      "grad_norm": 18.487281799316406,
      "learning_rate": 1e-05,
      "loss": 0.8485,
      "step": 2752
    },
    {
      "epoch": 0.37,
      "grad_norm": 30.584308624267578,
      "learning_rate": 1e-05,
      "loss": 0.8589,
      "step": 2756
    },
    {
      "epoch": 0.37,
      "grad_norm": 19.123916625976562,
      "learning_rate": 1e-05,
      "loss": 1.0162,
      "step": 2760
    },
    {
      "epoch": 0.37,
      "grad_norm": 21.76401138305664,
      "learning_rate": 1e-05,
      "loss": 1.004,
      "step": 2764
    },
    {
      "epoch": 0.37,
      "grad_norm": 20.184459686279297,
      "learning_rate": 1e-05,
      "loss": 0.8307,
      "step": 2768
    },
    {
      "epoch": 0.37,
      "grad_norm": 24.68450355529785,
      "learning_rate": 1e-05,
      "loss": 0.9071,
      "step": 2772
    },
    {
      "epoch": 0.37,
      "grad_norm": 16.66863250732422,
      "learning_rate": 1e-05,
      "loss": 0.8378,
      "step": 2776
    },
    {
      "epoch": 0.37,
      "grad_norm": 33.54316711425781,
      "learning_rate": 1e-05,
      "loss": 0.8831,
      "step": 2780
    },
    {
      "epoch": 0.37,
      "grad_norm": 18.84881591796875,
      "learning_rate": 1e-05,
      "loss": 0.6968,
      "step": 2784
    },
    {
      "epoch": 0.37,
      "grad_norm": 29.57833480834961,
      "learning_rate": 1e-05,
      "loss": 0.9777,
      "step": 2788
    },
    {
      "epoch": 0.37,
      "grad_norm": 20.294696807861328,
      "learning_rate": 1e-05,
      "loss": 0.7644,
      "step": 2792
    },
    {
      "epoch": 0.38,
      "grad_norm": 17.539796829223633,
      "learning_rate": 1e-05,
      "loss": 0.9061,
      "step": 2796
    },
    {
      "epoch": 0.38,
      "grad_norm": 26.47397232055664,
      "learning_rate": 1e-05,
      "loss": 0.727,
      "step": 2800
    },
    {
      "epoch": 0.38,
      "grad_norm": 18.340625762939453,
      "learning_rate": 1e-05,
      "loss": 0.8434,
      "step": 2804
    },
    {
      "epoch": 0.38,
      "grad_norm": 25.147842407226562,
      "learning_rate": 1e-05,
      "loss": 0.8421,
      "step": 2808
    },
    {
      "epoch": 0.38,
      "grad_norm": 20.067350387573242,
      "learning_rate": 1e-05,
      "loss": 0.9184,
      "step": 2812
    },
    {
      "epoch": 0.38,
      "grad_norm": 24.735010147094727,
      "learning_rate": 1e-05,
      "loss": 0.9172,
      "step": 2816
    },
    {
      "epoch": 0.38,
      "grad_norm": 26.040414810180664,
      "learning_rate": 1e-05,
      "loss": 0.8703,
      "step": 2820
    },
    {
      "epoch": 0.38,
      "grad_norm": 15.307506561279297,
      "learning_rate": 1e-05,
      "loss": 0.7752,
      "step": 2824
    },
    {
      "epoch": 0.38,
      "grad_norm": 25.58548927307129,
      "learning_rate": 1e-05,
      "loss": 1.2137,
      "step": 2828
    },
    {
      "epoch": 0.38,
      "grad_norm": 14.314270973205566,
      "learning_rate": 1e-05,
      "loss": 0.6685,
      "step": 2832
    },
    {
      "epoch": 0.38,
      "grad_norm": 19.528478622436523,
      "learning_rate": 1e-05,
      "loss": 0.8516,
      "step": 2836
    },
    {
      "epoch": 0.38,
      "grad_norm": 26.243009567260742,
      "learning_rate": 1e-05,
      "loss": 0.8343,
      "step": 2840
    },
    {
      "epoch": 0.38,
      "grad_norm": 22.35982322692871,
      "learning_rate": 1e-05,
      "loss": 0.7995,
      "step": 2844
    },
    {
      "epoch": 0.38,
      "grad_norm": 20.952369689941406,
      "learning_rate": 1e-05,
      "loss": 1.0252,
      "step": 2848
    },
    {
      "epoch": 0.38,
      "grad_norm": 19.41197395324707,
      "learning_rate": 1e-05,
      "loss": 0.9946,
      "step": 2852
    },
    {
      "epoch": 0.38,
      "grad_norm": 29.57225227355957,
      "learning_rate": 1e-05,
      "loss": 0.9863,
      "step": 2856
    },
    {
      "epoch": 0.38,
      "grad_norm": 19.675228118896484,
      "learning_rate": 1e-05,
      "loss": 0.8355,
      "step": 2860
    },
    {
      "epoch": 0.38,
      "grad_norm": 27.25497055053711,
      "learning_rate": 1e-05,
      "loss": 0.842,
      "step": 2864
    },
    {
      "epoch": 0.39,
      "grad_norm": 20.638572692871094,
      "learning_rate": 1e-05,
      "loss": 1.0094,
      "step": 2868
    },
    {
      "epoch": 0.39,
      "grad_norm": 21.700777053833008,
      "learning_rate": 1e-05,
      "loss": 0.8532,
      "step": 2872
    },
    {
      "epoch": 0.39,
      "grad_norm": 25.166736602783203,
      "learning_rate": 1e-05,
      "loss": 1.0108,
      "step": 2876
    },
    {
      "epoch": 0.39,
      "grad_norm": 16.93993377685547,
      "learning_rate": 1e-05,
      "loss": 0.5305,
      "step": 2880
    },
    {
      "epoch": 0.39,
      "grad_norm": 24.243072509765625,
      "learning_rate": 1e-05,
      "loss": 1.0488,
      "step": 2884
    },
    {
      "epoch": 0.39,
      "grad_norm": 26.934621810913086,
      "learning_rate": 1e-05,
      "loss": 0.9992,
      "step": 2888
    },
    {
      "epoch": 0.39,
      "grad_norm": 22.732641220092773,
      "learning_rate": 1e-05,
      "loss": 0.7562,
      "step": 2892
    },
    {
      "epoch": 0.39,
      "grad_norm": 12.844273567199707,
      "learning_rate": 1e-05,
      "loss": 0.6304,
      "step": 2896
    },
    {
      "epoch": 0.39,
      "grad_norm": 20.132505416870117,
      "learning_rate": 1e-05,
      "loss": 0.8075,
      "step": 2900
    },
    {
      "epoch": 0.39,
      "grad_norm": 13.778308868408203,
      "learning_rate": 1e-05,
      "loss": 0.8335,
      "step": 2904
    },
    {
      "epoch": 0.39,
      "grad_norm": 26.714012145996094,
      "learning_rate": 1e-05,
      "loss": 1.0109,
      "step": 2908
    },
    {
      "epoch": 0.39,
      "grad_norm": 18.442014694213867,
      "learning_rate": 1e-05,
      "loss": 0.9288,
      "step": 2912
    },
    {
      "epoch": 0.39,
      "grad_norm": 18.80977439880371,
      "learning_rate": 1e-05,
      "loss": 0.8608,
      "step": 2916
    },
    {
      "epoch": 0.39,
      "grad_norm": 16.180540084838867,
      "learning_rate": 1e-05,
      "loss": 0.8795,
      "step": 2920
    },
    {
      "epoch": 0.39,
      "grad_norm": 25.049531936645508,
      "learning_rate": 1e-05,
      "loss": 1.0458,
      "step": 2924
    },
    {
      "epoch": 0.39,
      "grad_norm": 23.363998413085938,
      "learning_rate": 1e-05,
      "loss": 1.0168,
      "step": 2928
    },
    {
      "epoch": 0.39,
      "grad_norm": 22.31805419921875,
      "learning_rate": 1e-05,
      "loss": 0.929,
      "step": 2932
    },
    {
      "epoch": 0.39,
      "grad_norm": 18.56275749206543,
      "learning_rate": 1e-05,
      "loss": 0.8689,
      "step": 2936
    },
    {
      "epoch": 0.39,
      "grad_norm": 24.43330955505371,
      "learning_rate": 1e-05,
      "loss": 0.9365,
      "step": 2940
    },
    {
      "epoch": 0.4,
      "grad_norm": 20.533849716186523,
      "learning_rate": 1e-05,
      "loss": 1.1088,
      "step": 2944
    },
    {
      "epoch": 0.4,
      "grad_norm": 21.4755859375,
      "learning_rate": 1e-05,
      "loss": 0.9372,
      "step": 2948
    },
    {
      "epoch": 0.4,
      "grad_norm": 35.53997039794922,
      "learning_rate": 1e-05,
      "loss": 0.8596,
      "step": 2952
    },
    {
      "epoch": 0.4,
      "grad_norm": 21.330799102783203,
      "learning_rate": 1e-05,
      "loss": 0.998,
      "step": 2956
    },
    {
      "epoch": 0.4,
      "grad_norm": 26.408525466918945,
      "learning_rate": 1e-05,
      "loss": 0.9077,
      "step": 2960
    },
    {
      "epoch": 0.4,
      "grad_norm": 15.560782432556152,
      "learning_rate": 1e-05,
      "loss": 0.8948,
      "step": 2964
    },
    {
      "epoch": 0.4,
      "grad_norm": 29.652132034301758,
      "learning_rate": 1e-05,
      "loss": 0.9914,
      "step": 2968
    },
    {
      "epoch": 0.4,
      "grad_norm": 26.994693756103516,
      "learning_rate": 1e-05,
      "loss": 0.9466,
      "step": 2972
    },
    {
      "epoch": 0.4,
      "grad_norm": 18.621267318725586,
      "learning_rate": 1e-05,
      "loss": 0.9389,
      "step": 2976
    },
    {
      "epoch": 0.4,
      "eval_accuracy": 0.6736255621937303,
      "eval_f1": 0.668422207248452,
      "eval_loss": 0.9002012014389038,
      "eval_precision": 0.6707498031050897,
      "eval_recall": 0.6736255621937303,
      "eval_runtime": 1708.9589,
      "eval_samples_per_second": 8.717,
      "eval_steps_per_second": 1.09,
      "step": 2976
    }
  ],
  "logging_steps": 4,
  "max_steps": 7447,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 744,
  "total_flos": 7482122000400384.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
